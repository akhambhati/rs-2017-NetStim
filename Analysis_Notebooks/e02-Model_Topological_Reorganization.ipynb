{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev1 toc-item\"><a href=\"#Load-meta-data\" data-toc-modified-id=\"Load-meta-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load meta data</a></div><div class=\"lev1 toc-item\"><a href=\"#Measure-Evoked-Topology\" data-toc-modified-id=\"Measure-Evoked-Topology-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Measure Evoked Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Define-network-measurements\" data-toc-modified-id=\"Define-network-measurements-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Define network measurements</a></div><div class=\"lev2 toc-item\"><a href=\"#Baseline-Topology\" data-toc-modified-id=\"Baseline-Topology-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Baseline Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Stim-Topology\" data-toc-modified-id=\"Stim-Topology-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Stim Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Pre-analysis-Data-Handling\" data-toc-modified-id=\"Pre-analysis-Data-Handling-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Pre-analysis Data Handling</a></div><div class=\"lev1 toc-item\"><a href=\"#Modulation-of-Network-Topology\" data-toc-modified-id=\"Modulation-of-Network-Topology-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modulation of Network Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Stimulation-to-Baseline\" data-toc-modified-id=\"Compare-Stimulation-to-Baseline-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Compare Stimulation to Baseline</a></div><div class=\"lev3 toc-item\"><a href=\"#Pre-Post-Coherence\" data-toc-modified-id=\"Pre-Post-Coherence-411\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Pre-Post Coherence</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-4111\"><span class=\"toc-item-num\">4.1.1.1&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Modes-of-Functional-Control\" data-toc-modified-id=\"Plot-Modes-of-Functional-Control-4112\"><span class=\"toc-item-num\">4.1.1.2&nbsp;&nbsp;</span>Plot Modes of Functional Control</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Stimulation-Energy\" data-toc-modified-id=\"Compare-Stimulation-Energy-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Compare Stimulation Energy</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Stimulation-Energy-Grid\" data-toc-modified-id=\"Plot-Stimulation-Energy-Grid-421\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Plot Stimulation Energy Grid</a></div><div class=\"lev3 toc-item\"><a href=\"#Pre-Post-Coherence\" data-toc-modified-id=\"Pre-Post-Coherence-422\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Pre-Post Coherence</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-4221\"><span class=\"toc-item-num\">4.2.2.1&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Stimulation-Location\" data-toc-modified-id=\"Compare-Stimulation-Location-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Compare Stimulation Location</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Stimulation-Locs-(MNI)\" data-toc-modified-id=\"Plot-Stimulation-Locs-(MNI)-431\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Plot Stimulation Locs (MNI)</a></div><div class=\"lev3 toc-item\"><a href=\"#Pre-Post-Coherence\" data-toc-modified-id=\"Pre-Post-Coherence-432\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Pre-Post Coherence</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-4321\"><span class=\"toc-item-num\">4.3.2.1&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Predictive-Distributions\" data-toc-modified-id=\"Plot-Predictive-Distributions-4322\"><span class=\"toc-item-num\">4.3.2.2&nbsp;&nbsp;</span>Plot Predictive Distributions</a></div><div class=\"lev4 toc-item\"><a href=\"#Get-Location-Distribution\" data-toc-modified-id=\"Get-Location-Distribution-4323\"><span class=\"toc-item-num\">4.3.2.3&nbsp;&nbsp;</span>Get Location Distribution</a></div><div class=\"lev1 toc-item\"><a href=\"#Structural-Topology\" data-toc-modified-id=\"Structural-Topology-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Structural Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Structural-Node-Strength-to-Baseline-Node-Strength\" data-toc-modified-id=\"Compare-Structural-Node-Strength-to-Baseline-Node-Strength-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Compare Structural Node Strength to Baseline Node Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-511\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Controllability-to-Memory-Classifier\" data-toc-modified-id=\"Compare-Controllability-to-Memory-Classifier-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Compare Controllability to Memory Classifier</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-521\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Controllability-to-Pre-Post-Coherence\" data-toc-modified-id=\"Compare-Controllability-to-Pre-Post-Coherence-53\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Compare Controllability to Pre-Post Coherence</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-531\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev1 toc-item\"><a href=\"#Artificial-Energy-Landscape\" data-toc-modified-id=\"Artificial-Energy-Landscape-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Artificial Energy Landscape</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "def write(txt):\n",
    "    sys.stdout.write(txt)\n",
    "    sys.stdout.flush()\n",
    "nb_stdout = sys.stdout    \n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import scipy.linalg as scialg\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import pickle as pkl\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import structural_control\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "\n",
    "#rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "#rcParams.update(rcParams)\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "matplotlib.rc(\"font\", family=\"Helvetica\")\n",
    "\n",
    "path_CoreData = '/Users/akhambhati/Remotes/CORE.PS_Stim'\n",
    "path_PeriphData = '/Users/akhambhati/Remotes/RSRCH.PS_Stim'\n",
    "path_AtlasData = '/Users/akhambhati/Remotes/CORE.MRI_Atlases'\n",
    "\n",
    "path_Data = {'Input_Meta': {},\n",
    "             'Input_Stim': {},\n",
    "             'Input_Baseline': {},\n",
    "             'Output': {},\n",
    "             'Figure': {}}\n",
    "path_Data['Input_Meta'] = path_PeriphData + '/e00-Multimodal_Mapping'\n",
    "path_Data['Input_Stim'] = path_PeriphData + '/e02-FuncNetw.CommonAverage.Stim'\n",
    "path_Data['Input_Baseline'] = path_PeriphData + '/e02-FuncNetw.CommonAverage.Baseline'\n",
    "path_Data['Output'] = path_PeriphData + '/e02-GlobalTopo.CommonAverage'\n",
    "path_Data['Output'] = path_PeriphData + '/e02-GlobalTopo.CommonAverage'\n",
    "path_Data['Figure'] = './Figures-e02-GlobalTopo.CommonAverage'\n",
    "\n",
    "for path_type in path_Data.keys():\n",
    "    path = path_Data[path_type]\n",
    "    if not os.path.exists(path_Data[path_type]):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)\n",
    "            \n",
    "from sklearn.externals.joblib import Memory\n",
    "memory = Memory(cachedir=path_Data['Output'], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_dict = {}\n",
    "\n",
    "meta_dict['subject_list'] = np.load('{}/Meta.Electrode_Loc.npz'.format(path_Data['Input_Meta']))['subj_list']\n",
    "meta_dict['electrode_loc'] = np.load('{}/Meta.Electrode_Loc.npz'.format(path_Data['Input_Meta']))['channel_info'][()]\n",
    "meta_dict['atlas_info'] = np.load('{}/Meta.Electrode_Loc.npz'.format(path_Data['Input_Meta']))['lausanne_label_mni'][()]\n",
    "meta_dict['struct_adj'] = np.load('{}/Meta.Electrode_Loc.npz'.format(path_Data['Input_Meta']))['structadj_dict'][()]\n",
    "meta_dict['memory_info'] = pd.read_pickle('{}/Meta.Memory_Info.pkl'.format(path_Data['Input_Meta']))\n",
    "meta_dict['baseline_info'] = pd.read_pickle('{}/Meta.Baseline_Info.pkl'.format(path_Data['Input_Meta']))\n",
    "meta_dict['stim_info'] = pd.read_pickle('{}/Meta.Stim_Info.pkl'.format(path_Data['Input_Meta']))\n",
    "meta_dict['behavior_info'] = pd.read_pickle('{}/Meta.Behavior_Info.pkl'.format(path_Data['Input_Meta']))\n",
    "meta_dict['LTC_info'] = ['inferiortemporal', 'middletemporal', 'superiortemporal',\n",
    "                         'temporalpole', 'parahippocampal', 'entorhinal', 'lingual',\n",
    "                         'fusiform','transversetemporal', 'bankssts']\n",
    "\n",
    "meta_dict['coherence_info'] = ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']\n",
    "meta_dict['coherence_freq'] = ['5-15 Hz', '15-25 Hz', '30-40 Hz', '95-105 Hz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Evoked Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cohens_d(dist1, dist2):\n",
    "    m1 = np.mean(dist1)\n",
    "    m2 = np.mean(dist2)\n",
    "    s12 = np.std(np.concatenate((dist1, dist2)).reshape(-1))\n",
    "    return (m1-m2)/s12\n",
    "\n",
    "\n",
    "def measure_cfg_str(adj):\n",
    "    cfg_vec = convert_adj_matr_to_cfg_matr(np.expand_dims(adj, axis=0))[0, :]\n",
    "    cfg_mean = np.mean(cfg_vec)\n",
    "    cfg_var = np.var(cfg_vec)\n",
    "    return cfg_mean, cfg_var\n",
    "\n",
    "\n",
    "def measure_node_str(adj):\n",
    "    node_str = np.nanmean(adj, axis=0)\n",
    "    node_str_z = (node_str - np.nanmean(node_str)) / np.nanstd(node_str)    \n",
    "    return node_str, node_str_z\n",
    "\n",
    "\n",
    "def measure_node_str_delta(adj_pre, adj_post, n_perm=1000):\n",
    "    cfg_pre = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre, axis=0))[0, :]\n",
    "    cfg_post = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post, axis=0))[0, :]\n",
    "    cfg_delta = cfg_post - cfg_pre\n",
    "    \n",
    "    # True delta node_str\n",
    "    node_str_delta = measure_node_str(convert_conn_vec_to_adj_matr(cfg_delta))[0]\n",
    "    \n",
    "    # Permutation test for delta node_str\n",
    "    node_str_delta_null = np.array([\n",
    "        measure_node_str(\n",
    "            convert_conn_vec_to_adj_matr(\n",
    "                np.random.permutation(cfg_delta)))[0]\n",
    "        for p_ii in xrange(n_perm)])\n",
    "    node_str_delta_pv = np.mean(np.abs(node_str_delta_null) > np.abs(node_str_delta), axis=0)\n",
    "    \n",
    "    return node_str_delta, node_str_delta_pv\n",
    "\n",
    "\n",
    "def measure_cfg_sim(adj_pre, adj_post):\n",
    "    cfg_pre = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre, axis=0))[0, :]\n",
    "    cfg_post = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post, axis=0))[0, :]\n",
    "    cfg_sim = np.corrcoef(cfg_pre, cfg_post)[0, 1]\n",
    "    return cfg_sim\n",
    "\n",
    "\n",
    "def measure_dist_node_corr(node_str_del, dist, stim_ix):\n",
    "    dist_to_stim = np.mean(dist[stim_ix, :], axis=0)\n",
    "    dist_to_stim = np.delete(dist_to_stim, stim_ix)\n",
    "    rv, pv = stats.pearsonr(dist_to_stim, node_str_del)\n",
    "    \n",
    "    return rv, pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fdf['adj'][()]['LIHG3_LIHG4'][500][2]['Post_Stim_1']['Beta']\n",
    "# Structure of baseline files\n",
    "\n",
    "def generate_globaltopo_baseline(proc_id):\n",
    "    print(proc_id)\n",
    "    meta_base = meta_dict['baseline_info'].ix[proc_id]\n",
    "\n",
    "    subj_id = meta_base['Subject_ID']\n",
    "    base_id = meta_base['Base_ID'] \n",
    "    path_input_base = path_Data['Input_Baseline']    \n",
    "    prev_n_win = 60\n",
    "    \n",
    "    write('{}-{}\\n'.format(subj_id, base_id))\n",
    "    \n",
    "    data_table = {'Subject_ID': [],\n",
    "                  'Base_ID': [],\n",
    "                  'Coherence_ID': [],\n",
    "                  'Stim_Anode': [],\n",
    "                  'Stim_Cathode': [],\n",
    "                  'Stim_Duration': [],\n",
    "                  \n",
    "                  'Pre_Cfg_Str_Mean': [],\n",
    "                  'Pre_Cfg_Str_Var': [],\n",
    "                  'Post1_Cfg_Str_Mean': [],\n",
    "                  'Post1_Cfg_Str_Var': [],\n",
    "                  'Post2_Cfg_Str_Mean': [],\n",
    "                  'Post2_Cfg_Str_Var': [],\n",
    "                  \n",
    "                  'Pre_Node_Str': [],\n",
    "                  'Pre_Node_Str_Z': [],                  \n",
    "                  'Post1_Node_Str': [],\n",
    "                  'Post1_Node_Str_Z': [],                  \n",
    "                  'Post2_Node_Str': [],\n",
    "                  'Post2_Node_Str_Z': [],                  \n",
    "                                    \n",
    "                  'Stim_Cfg_Sim1': [],\n",
    "                  'Stim_Cfg_Sim2': [],   \n",
    "                  \n",
    "                  'Mean_Adj': []}\n",
    "    \n",
    "    # Load \n",
    "    try:\n",
    "        df_base = np.load('{}/Adjacency.{}.Base_Event.{}.npz'.format(path_input_base, subj_id, base_id))\n",
    "    except IOError:\n",
    "        globaltopo_base = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "        return globaltopo_base\n",
    "    \n",
    "\n",
    "    for stim_pair_tag in df_base['adj'][()].keys():\n",
    "        for stim_duration in df_base['adj'][()][stim_pair_tag].keys():\n",
    "            for ep_ii, ep in enumerate(df_base['adj'][()][stim_pair_tag][stim_duration][-prev_n_win:]):\n",
    "                for coh_id in meta_dict['coherence_info']:\n",
    "\n",
    "                    try:\n",
    "                        adj_pre = ep['Pre_Stim'][coh_id]\n",
    "                    except:\n",
    "                        continue\n",
    "                    N, N = adj_pre.shape\n",
    "\n",
    "                    try:\n",
    "                        adj_post1 = ep['Post_Stim_1'][coh_id]\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        adj_post2 = ep['Post_Stim_2'][coh_id]\n",
    "                    except:\n",
    "                        adj_post2 = np.nan*np.zeros((N, N))\n",
    "\n",
    "                    # Add to Data Table                      \n",
    "                    data_table['Subject_ID'].append(subj_id)\n",
    "                    data_table['Base_ID'].append(ep_ii)\n",
    "                    data_table['Coherence_ID'].append(coh_id)\n",
    "                    data_table['Stim_Anode'].append(stim_pair_tag.split('_')[0])\n",
    "                    data_table['Stim_Cathode'].append(stim_pair_tag.split('_')[1])\n",
    "                    data_table['Stim_Duration'].append(stim_duration)\n",
    "\n",
    "                    data_table['Pre_Cfg_Str_Mean'].append(measure_cfg_str(adj_pre)[0])\n",
    "                    data_table['Pre_Cfg_Str_Var'].append(measure_cfg_str(adj_pre)[1])\n",
    "                    data_table['Post1_Cfg_Str_Mean'].append(measure_cfg_str(adj_post1)[0])\n",
    "                    data_table['Post1_Cfg_Str_Var'].append(measure_cfg_str(adj_post1)[1])\n",
    "                    data_table['Post2_Cfg_Str_Mean'].append(measure_cfg_str(adj_post2)[0])\n",
    "                    data_table['Post2_Cfg_Str_Var'].append(measure_cfg_str(adj_post2)[1])\n",
    "\n",
    "                    data_table['Pre_Node_Str'].append(measure_node_str(adj_pre)[0])\n",
    "                    data_table['Pre_Node_Str_Z'].append(measure_node_str(adj_pre)[1]) \n",
    "                    data_table['Post1_Node_Str'].append(measure_node_str(adj_post1)[0])\n",
    "                    data_table['Post1_Node_Str_Z'].append(measure_node_str(adj_post1)[1]) \n",
    "                    data_table['Post2_Node_Str'].append(measure_node_str(adj_post2)[0])\n",
    "                    data_table['Post2_Node_Str_Z'].append(measure_node_str(adj_post2)[1])                       \n",
    "\n",
    "                    cfg_sim = measure_cfg_sim(adj_pre, adj_post1)\n",
    "                    data_table['Stim_Cfg_Sim1'].append(cfg_sim)\n",
    "\n",
    "                    cfg_sim = measure_cfg_sim(adj_pre, adj_post2)\n",
    "                    data_table['Stim_Cfg_Sim2'].append(cfg_sim)\n",
    "\n",
    "                    data_table['Mean_Adj'].append(adj_pre)                        \n",
    "\n",
    "    globaltopo_base = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    return globaltopo_base\n",
    "\n",
    "################################\n",
    "output_path = '{}/GlobalTopo.Baseline.pkl'.format(path_Data['Output'])\n",
    "if not os.path.exists(output_path):\n",
    "    sys.stdout = open('{}/GlobalTopo.Baseline.ProcJob'.format(path_Data['Output']), 'w')    \n",
    "    write('Mapping jobs...\\n')\n",
    "    \n",
    "    args_list = range(len(meta_dict['baseline_info']))\n",
    "    #res = map(generate_globaltopo_baseline, args_list)\n",
    "    pool = Pool(7)\n",
    "    res = pool.map(generate_globaltopo_baseline, args_list)\n",
    "\n",
    "\n",
    "    write('\\nReducing jobs...\\n')\n",
    "    df_globaltopo_base = pd.concat(res, ignore_index=True)\n",
    "    df_globaltopo_base.to_pickle(output_path)\n",
    "    sys.stdout = nb_stdout\n",
    "else:\n",
    "    df_globaltopo_base = pd.read_pickle(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_globaltopo_stim(proc_id):\n",
    "    meta_stim = meta_dict['stim_info'].ix[proc_id]\n",
    "    \n",
    "    subj_id = meta_stim['Subject_ID']\n",
    "    event_id = meta_stim['Event_ID']    \n",
    "    path_input_stim = path_Data['Input_Stim']\n",
    "    \n",
    "    write('{}-{}\\n'.format(subj_id, event_id))    \n",
    "    \n",
    "    data_table = {'Subject_ID': [],\n",
    "                  'Event_ID': [],\n",
    "                  'Coherence_ID': [],\n",
    "                  \n",
    "                  'Pre_Cfg_Str_Mean': [],\n",
    "                  'Pre_Cfg_Str_Var': [],\n",
    "                  'Post1_Cfg_Str_Mean': [],\n",
    "                  'Post1_Cfg_Str_Var': [],\n",
    "                  'Post2_Cfg_Str_Mean': [],\n",
    "                  'Post2_Cfg_Str_Var': [],\n",
    "                  \n",
    "                  'Pre_Node_Str': [],\n",
    "                  'Pre_Node_Str_Z': [],                  \n",
    "                  'Post1_Node_Str': [],\n",
    "                  'Post1_Node_Str_Z': [],                  \n",
    "                  'Post2_Node_Str': [],\n",
    "                  'Post2_Node_Str_Z': [],                  \n",
    "                                                      \n",
    "                  'Stim_Cfg_Sim1': [],\n",
    "                  'Stim_Cfg_Sim2': []}\n",
    "    \n",
    "    # Load\n",
    "    try:\n",
    "        df_stim = np.load('{}/Adjacency.{}.Stim_Event.{}.npz'.format(path_input_stim, subj_id, event_id))\n",
    "    except IOError:\n",
    "        globaltopo_stim = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "        return globaltopo_stim\n",
    "    \n",
    "    for coh_id in meta_dict['coherence_info']:\n",
    "\n",
    "        try:\n",
    "            adj_pre = df_stim['adj'][()]['Pre_Stim'][coh_id]\n",
    "        except:\n",
    "            continue\n",
    "        N, N = adj_pre.shape\n",
    "\n",
    "        try:\n",
    "            adj_post1 = df_stim['adj'][()]['Post_Stim_1'][coh_id]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            adj_post2 = df_stim['adj'][()]['Post_Stim_2'][coh_id]\n",
    "        except:\n",
    "            adj_post2 = np.nan*np.zeros((N, N))\n",
    "\n",
    "        # Add to Data Table                      \n",
    "        data_table['Subject_ID'].append(subj_id)\n",
    "        data_table['Event_ID'].append(event_id)\n",
    "        data_table['Coherence_ID'].append(coh_id)\n",
    "\n",
    "        data_table['Pre_Cfg_Str_Mean'].append(measure_cfg_str(adj_pre)[0])\n",
    "        data_table['Pre_Cfg_Str_Var'].append(measure_cfg_str(adj_pre)[1])\n",
    "        data_table['Post1_Cfg_Str_Mean'].append(measure_cfg_str(adj_post1)[0])\n",
    "        data_table['Post1_Cfg_Str_Var'].append(measure_cfg_str(adj_post1)[1])\n",
    "        data_table['Post2_Cfg_Str_Mean'].append(measure_cfg_str(adj_post2)[0])\n",
    "        data_table['Post2_Cfg_Str_Var'].append(measure_cfg_str(adj_post2)[1])\n",
    "\n",
    "        data_table['Pre_Node_Str'].append(measure_node_str(adj_pre)[0])\n",
    "        data_table['Pre_Node_Str_Z'].append(measure_node_str(adj_pre)[1]) \n",
    "        data_table['Post1_Node_Str'].append(measure_node_str(adj_post1)[0])\n",
    "        data_table['Post1_Node_Str_Z'].append(measure_node_str(adj_post1)[1]) \n",
    "        data_table['Post2_Node_Str'].append(measure_node_str(adj_post2)[0])\n",
    "        data_table['Post2_Node_Str_Z'].append(measure_node_str(adj_post2)[1])\n",
    "\n",
    "        cfg_sim = measure_cfg_sim(adj_pre, adj_post1)\n",
    "        data_table['Stim_Cfg_Sim1'].append(cfg_sim)\n",
    "\n",
    "        cfg_sim = measure_cfg_sim(adj_pre, adj_post2)\n",
    "        data_table['Stim_Cfg_Sim2'].append(cfg_sim)                     \n",
    "            \n",
    "    globaltopo_stim = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    return globaltopo_stim\n",
    "\n",
    "################################\n",
    "output_path = '{}/GlobalTopo.Stimulation.pkl'.format(path_Data['Output'])\n",
    "if not os.path.exists(output_path):\n",
    "    sys.stdout = open('{}/GlobalTopo.Stimulation.ProcJob'.format(path_Data['Output']), 'w')\n",
    "    write('Mapping jobs...\\n')\n",
    "\n",
    "    args_list = range(len(meta_dict['stim_info']))\n",
    "    pool = Pool(7)\n",
    "    res = pool.map(generate_globaltopo_stim, args_list)\n",
    "    \n",
    "    write('\\nReducing jobs...\\n')\n",
    "    df_globaltopo_stim = pd.concat(res, ignore_index=True)\n",
    "    df_globaltopo_stim.to_pickle(output_path)\n",
    "    write('Done.\\n')\n",
    "    sys.stdout = nb_stdout\n",
    "else:\n",
    "    df_globaltopo_stim = pd.read_pickle(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-analysis Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First merge df_globaltopo_stim with meta_ps\n",
    "df_globaltopo_stim = pd.merge(meta_dict['stim_info'],\n",
    "                              df_globaltopo_stim,                              \n",
    "                              on=['Subject_ID', 'Event_ID'])\n",
    "\n",
    "# Second retain only stimulating types\n",
    "df_globaltopo_stim = df_globaltopo_stim.loc[df_globaltopo_stim.Stim_Type == 'stimulating']\n",
    "\n",
    "# Third discard PS0\n",
    "#df_globaltopo_stim = df_globaltopo_stim[df_globaltopo_stim['Experiment_ID'] != 'PS0']\n",
    "df_globaltopo_stim = df_globaltopo_stim[df_globaltopo_stim['Experiment_ID'].isin(['PS1', 'PS2', 'PS2.1'])]\n",
    "\n",
    "# Get common subjects\n",
    "common_subject_list = np.intersect1d(np.unique(df_globaltopo_base['Subject_ID']),\n",
    "                                     np.unique(df_globaltopo_stim['Subject_ID']))\n",
    "\n",
    "# Reduce the DFs for common subjects\n",
    "df_globaltopo_stim = df_globaltopo_stim.loc[df_globaltopo_stim.Subject_ID.isin(common_subject_list)]\n",
    "df_globaltopo_base = df_globaltopo_base.loc[df_globaltopo_base.Subject_ID.isin(common_subject_list)]\n",
    "\n",
    "# Make sure Base and Stim have common column names\n",
    "df_globaltopo_base = df_globaltopo_base.rename(\n",
    "    columns={'Stim_Duration': 'Stim_Dur'})\n",
    "print('Common Column Fields')\n",
    "common_cols = list(np.intersect1d(df_globaltopo_base.keys(),\n",
    "                                  df_globaltopo_stim.keys()))\n",
    "print(common_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulation of Network Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stimulation to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key = ['Subject_ID',\n",
    "                   'Stim_Anode',\n",
    "                   'Stim_Cathode',\n",
    "                   'Stim_Dur',\n",
    "                   'Coherence_ID']\n",
    "\n",
    "df_stim_sel = df_globaltopo_stim.groupby(unique_stim_key).indices\n",
    "df_base_sel = df_globaltopo_base.groupby(unique_stim_key).indices\n",
    "\n",
    "# Use Keys that overlap between stim and base\n",
    "df_base_key = df_base_sel.keys()\n",
    "df_stim_key = df_stim_sel.keys()\n",
    "df_base_key_set = np.array([set(k) for k in df_base_key])\n",
    "df_stim_key_set = np.array([set(k) for k in df_stim_key])\n",
    "\n",
    "df_base_common_key = []\n",
    "df_stim_common_key = []\n",
    "for b_k_ii, b_k in enumerate(df_base_key_set):\n",
    "    for s_k_ii, s_k in enumerate(df_stim_key_set):\n",
    "        if b_k == s_k:\n",
    "            df_base_common_key.append(df_base_key[b_k_ii])\n",
    "            df_stim_common_key.append(df_stim_key[s_k_ii])            \n",
    "            continue\n",
    "            \n",
    "df_luts = {'stim': {'common_key': df_stim_common_key,\n",
    "                    'df_ind': df_stim_sel,\n",
    "                    'df_topo': df_globaltopo_stim},\n",
    "           'base': {'common_key': df_base_common_key,\n",
    "                    'df_ind': df_base_sel,\n",
    "                    'df_topo': df_globaltopo_base}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Post Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@memory.cache\n",
    "def compute_prepost_coherence(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "        \n",
    "    # Initialize the measurement buckets (2 columns for post1/post2)\n",
    "    vals = {'Subject_ID': [],\n",
    "            'Coherence_ID': [],\n",
    "            'Stim_Type': [],\n",
    "            'Stim_Loc': [],\n",
    "            cfg_measure + '_Del_1': [],\n",
    "            cfg_measure + '_Del_2': []}\n",
    "    \n",
    "    # Condence the measurement across the common key criteria\n",
    "    for tp in df_luts.keys():\n",
    "        df_key = df_luts[tp]['common_key']\n",
    "        df_ind = df_luts[tp]['df_ind']        \n",
    "        df_topo = df_luts[tp]['df_topo']\n",
    "    \n",
    "        # Iterate over keys\n",
    "        for key_ii, key in enumerate(df_key):\n",
    "            df_sel = df_topo.iloc[df_ind[key]]\n",
    "\n",
    "            subj_id = df_sel['Subject_ID'].iloc[0]\n",
    "            coh_id = df_sel['Coherence_ID'].iloc[0]\n",
    "            stim_anode = df_sel['Stim_Anode'].iloc[0]\n",
    "            stim_cathode = df_sel['Stim_Cathode'].iloc[0]\n",
    "            \n",
    "            # Compute Measurement\n",
    "            if cfg_measure in ['Cfg_Str_Mean', 'Cfg_Str_Var']:\n",
    "                post1_vs_pre = (df_sel['Post1_' + cfg_measure] - df_sel['Pre_' + cfg_measure]).mean()\n",
    "                post2_vs_pre = (df_sel['Post2_' + cfg_measure] - df_sel['Pre_' + cfg_measure]).mean()\n",
    "            elif cfg_measure in ['Node_Str_Mean']:\n",
    "                post1_vs_pre = (df_sel['Post1_Node_Str'].apply(np.mean, axis=0) - df_sel['Pre_Node_Str'].apply(np.mean, axis=0)).mean()\n",
    "                post2_vs_pre = (df_sel['Post2_Node_Str'].apply(np.mean, axis=0) - df_sel['Pre_Node_Str'].apply(np.mean, axis=0)).mean()\n",
    "            elif cfg_measure in ['Node_Str_Var']:\n",
    "                post1_vs_pre = (df_sel['Post1_Node_Str'].apply(np.var, axis=0) - df_sel['Pre_Node_Str'].apply(np.var, axis=0)).mean()\n",
    "                post2_vs_pre = (df_sel['Post2_Node_Str'].apply(np.var, axis=0) - df_sel['Pre_Node_Str'].apply(np.var, axis=0)).mean()                \n",
    "            elif cfg_measure in ['Stim_Cfg_Sim']:\n",
    "                post1_vs_pre = ((df_sel[cfg_measure + '1'])).mean()\n",
    "                post2_vs_pre = ((df_sel[cfg_measure + '2'])).mean()\n",
    "            else:\n",
    "                raise ValueError('{} not a valid measurement'.format(cfg_measure))\n",
    "\n",
    "            # Add to the dictionary\n",
    "            vals['Subject_ID'].append(subj_id)\n",
    "            vals['Coherence_ID'].append(coh_id)\n",
    "            vals['Stim_Type'].append(tp)\n",
    "            vals['Stim_Loc'].append('_'.join(np.sort([stim_anode, stim_cathode])))\n",
    "            vals[cfg_measure + '_Del_1'].append(post1_vs_pre)\n",
    "            vals[cfg_measure + '_Del_2'].append(post2_vs_pre)            \n",
    "    \n",
    "    # Convert to pandas dataframe\n",
    "    df = pd.DataFrame(vals, columns=vals.keys())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'Delta Mean Coherence (Stim-Base)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},\n",
    "            'Node_Str_Mean':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'Delta Mean Node Strength (Stim-Base)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},            \n",
    "            'Cfg_Str_Var':           {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'Delta Var Coherence (Stim-Base)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},  \n",
    "            'Node_Str_Var':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'Delta Var Node Strength (Stim-Base)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},              \n",
    "            'Stim_Cfg_Sim':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'Edge Correlation (Stim-Base)',\n",
    "                                      'color': sns.xkcd_palette(['amber'])[0]}}  \n",
    "\n",
    "for meas in analysis.keys():\n",
    "    df = compute_prepost_coherence(meas)    \n",
    "    df = df.groupby(['Subject_ID', 'Stim_Loc', 'Coherence_ID', 'Stim_Type']).mean().reset_index()\n",
    "\n",
    "    # Generate plots and stats\n",
    "    for delay_prefix in ['_Del_1', '_Del_2']:\n",
    "        meas_full = meas + delay_prefix\n",
    "        \n",
    "        df[meas_full] = df.groupby(['Subject_ID', 'Stim_Loc', 'Coherence_ID'])[meas_full].diff()\n",
    "\n",
    "        # Get basic trends/stats\n",
    "        df_range_medn = df.dropna().groupby(['Coherence_ID', 'Stim_Type']).quantile(q=0.50).reset_index()\n",
    "        df_range_qnt1 = df.dropna().groupby(['Coherence_ID', 'Stim_Type']).quantile(q=0.25).reset_index()\n",
    "        df_range_qnt3 = df.dropna().groupby(['Coherence_ID', 'Stim_Type']).quantile(q=0.75).reset_index()\n",
    "        df_range_qnt0 = df.dropna().groupby(['Coherence_ID', 'Stim_Type']).quantile(q=0.05).reset_index()\n",
    "        df_range_qnt4 = df.dropna().groupby(['Coherence_ID', 'Stim_Type']).quantile(q=0.95).reset_index()        \n",
    "                    \n",
    "        # Seaborn params\n",
    "        plt.figure(figsize=(4,6), dpi=300)\n",
    "        ax = plt.subplot(111)        \n",
    "        sns_plot_params = {'x': 'Coherence_ID',\n",
    "                           'y': meas_full,\n",
    "                           'order': meta_dict['coherence_info'],\n",
    "                           'data': df,\n",
    "                           'color': analysis[meas]['color'],\n",
    "                           'ax': ax}\n",
    "\n",
    "        # Add Mean/Serr Bars\n",
    "        for c_ii, c_id in enumerate(meta_dict['coherence_info']):\n",
    "            medn = df_range_medn[df_range_medn['Coherence_ID'] == c_id][meas_full]\n",
    "            qnt1 = df_range_qnt1[df_range_qnt1['Coherence_ID'] == c_id][meas_full]\n",
    "            qnt3 = df_range_qnt3[df_range_qnt3['Coherence_ID'] == c_id][meas_full]            \n",
    "            ax.hlines(medn, c_ii-0.2, c_ii+0.2,\n",
    "                      color='k', linestyle='-', linewidth=2.0, zorder=100)\n",
    "            ax.hlines(qnt1, c_ii-0.3, c_ii+0.3,\n",
    "                      color='k', linestyle='--', linewidth=1.0, zorder=100)\n",
    "            ax.hlines(qnt3, c_ii-0.3, c_ii+0.3,\n",
    "                      color='k', linestyle='--', linewidth=1.0, zorder=100)    \n",
    "        ax.hlines(0.0, -0.5, len(meta_dict['coherence_info'])+0.5, linewidth=1.0, zorder=100)\n",
    "        \n",
    "        # Add a strip plot points            \n",
    "        ax = sns.stripplot(dodge=True,\n",
    "                           jitter=True,\n",
    "                           size=4,\n",
    "                           alpha=0.25,      \n",
    "                           **sns_plot_params)          \n",
    "        \n",
    "        # Prettify the plotting + add labels\n",
    "        ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "        ax.set_ylabel(analysis[meas]['ylabel'])   \n",
    "        ax.set_ylim([df_range_qnt0[meas_full].min(), df_range_qnt4[meas_full].max()])\n",
    "        ax.set_title(meas_full)\n",
    "        sns.despine(ax=ax)\n",
    "        #sns.set_context('paper')\n",
    "\n",
    "        plt.savefig('{}/Stim_Base.{}.Distrib.svg'.format(path_Data['Figure'], meas_full))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        # Stats\n",
    "        write(':: STATS ::\\n')\n",
    "        \n",
    "        df_A = df.dropna()\n",
    "        A_arr = []\n",
    "        for coh_id in meta_dict['coherence_info']:\n",
    "            A = df_A[df_A['Coherence_ID'] == coh_id][meas_full]\n",
    "            A_arr.append(A)            \n",
    "            \n",
    "            write('{}\\n'.format(coh_id))\n",
    "            write('    Shapiro   :: (Stim-Base) --> {}\\n'.format(stats.shapiro(A)))            \n",
    "            write('    Wilcoxon_{} :: (Stim-Base) --> {}\\n'.format(len(A)-1, stats.wilcoxon(A)))\n",
    "        write('Kruskal (Stim) :: F={}\\n'.format(stats.kruskal(*np.array(A_arr))))        \n",
    "        write('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Modes of Functional Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Node_Str_Mean':         {'label': 'Frequency Range'},\n",
    "            'Node_Str_Var':          {'label': 'Frequency Range'},\n",
    "            'Stim_Cfg_Sim':          {'label': 'Edge Correlation'}}\n",
    "\n",
    "# Generate a combined dataset\n",
    "df_AB = []\n",
    "for meas in analysis.keys():    \n",
    "    df = compute_prepost_coherence(meas)  \n",
    "    df = df.groupby(['Subject_ID', 'Stim_Loc']).mean().reset_index()    \n",
    "    df_AB.append(df)\n",
    "df_AB = pd.merge(pd.merge(df_AB[0], df_AB[1]), df_AB[2])\n",
    "\n",
    "pg = sns.pairplot(df_AB.dropna(), \n",
    "                  vars=['Node_Str_Var_Del_1',\n",
    "                        'Node_Str_Mean_Del_1',\n",
    "                        'Stim_Cfg_Sim_Del_1'],\n",
    "                  kind='reg')\n",
    "pg = pg.map_diag(plt.hist, edgecolor='k', color='k')\n",
    "pg = pg.map_offdiag(plt.scatter, edgecolor='k', color='k', s=10, alpha=0.25)\n",
    "\n",
    "plt.savefig('{}/Topo_Change_PairPlot.Distrib.svg'.format(path_Data['Figure']))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "for meas1 in analysis.keys():\n",
    "    for meas2 in analysis.keys():\n",
    "        if meas1 == meas2:\n",
    "            continue\n",
    "        print(meas1, meas2, len(df_AB.dropna()[meas1 + '_Del_1']))\n",
    "        print(stats.pearsonr(df_AB.dropna()[meas1 + '_Del_1'],\n",
    "                             df_AB.dropna()[meas2 + '_Del_1']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stimulation Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key = ['Subject_ID',\n",
    "                   'Stim_Anode',\n",
    "                   'Stim_Cathode',\n",
    "                   'Stim_Dur',\n",
    "                   'Stim_Freq',\n",
    "                   'Stim_Amp',\n",
    "                   'Coherence_ID']\n",
    "\n",
    "df_stim_sel = df_globaltopo_stim.groupby(unique_stim_key).indices\n",
    "\n",
    "# Use Keys that overlap between stim and base\n",
    "df_stim_key = df_stim_sel.keys()\n",
    "df_stim_key_set = np.array([set(k) for k in df_stim_key])\n",
    "            \n",
    "df_luts = {'stim': {'common_key': df_stim_key,\n",
    "                    'df_ind': df_stim_sel,\n",
    "                    'df_topo': df_globaltopo_stim}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Stimulation Energy Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Required import for following computations.\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.pyplot import figure, show\n",
    "\n",
    "\n",
    "def quad(plane='xy', origin=None, width=1, height=1, depth=0):\n",
    "    u, v = (0, 0) if origin is None else origin\n",
    "\n",
    "    plane = plane.lower()\n",
    "    if plane == 'xy':\n",
    "        vertices = ((u, v, depth),\n",
    "                    (u + width, v, depth),\n",
    "                    (u + width, v + height, depth),\n",
    "                    (u, v + height, depth))\n",
    "    elif plane == 'xz':\n",
    "        vertices = ((u, depth, v),\n",
    "                    (u + width, depth, v),\n",
    "                    (u + width, depth, v + height),\n",
    "                    (u, depth, v + height))\n",
    "    elif plane == 'yz':\n",
    "        vertices = ((depth, u, v),\n",
    "                    (depth, u + width, v),\n",
    "                    (depth, u + width, v + height),\n",
    "                    (depth, u, v + height))\n",
    "    else:\n",
    "        raise ValueError('\"{0}\" is not a supported plane!'.format(plane))\n",
    "\n",
    "    return np.array(vertices)\n",
    "\n",
    "\n",
    "def grid(plane='xy',\n",
    "         origin=None,\n",
    "         width=1,\n",
    "         height=1,\n",
    "         depth=0,\n",
    "         width_segments=1,\n",
    "         height_segments=1):\n",
    "    u, v = (0, 0) if origin is None else origin\n",
    "\n",
    "    w_x, h_y = width / width_segments, height / height_segments\n",
    "\n",
    "    quads = []\n",
    "    for i in range(width_segments):\n",
    "        for j in range(height_segments):\n",
    "            quads.append(\n",
    "                quad(plane, (i * w_x + u, j * h_y + v), w_x, h_y, depth))\n",
    "\n",
    "    return np.array(quads)\n",
    "\n",
    "\n",
    "def cube(plane=None,\n",
    "         origin=None,\n",
    "         width=1,\n",
    "         height=1,\n",
    "         depth=1,\n",
    "         width_segments=1,\n",
    "         height_segments=1,\n",
    "         depth_segments=1):\n",
    "    plane = (('+x', '-x', '+y', '-y', '+z', '-z')\n",
    "             if plane is None else\n",
    "             [p.lower() for p in plane])\n",
    "    u, v, w = (0, 0, 0) if origin is None else origin\n",
    "\n",
    "    w_s, h_s, d_s = width_segments, height_segments, depth_segments\n",
    "\n",
    "    grids = []\n",
    "    if '-z' in plane:\n",
    "        grids.extend(grid('xy', (u, w), width, depth, v, w_s, d_s))\n",
    "    if '+z' in plane:\n",
    "        grids.extend(grid('xy', (u, w), width, depth, v + height, w_s, d_s))\n",
    "\n",
    "    if '-y' in plane:\n",
    "        grids.extend(grid('xz', (u, v), width, height, w, w_s, h_s))\n",
    "    if '+y' in plane:\n",
    "        grids.extend(grid('xz', (u, v), width, height, w + depth, w_s, h_s))\n",
    "\n",
    "    if '-x' in plane:\n",
    "        grids.extend(grid('yz', (w, v), depth, height, u, d_s, h_s))\n",
    "    if '+x' in plane:\n",
    "        grids.extend(grid('yz', (w, v), depth, height, u + width, d_s, h_s))\n",
    "\n",
    "    return np.array(grids)\n",
    "\n",
    "\n",
    "stim_amp = np.sort(meta_ps['Stim_Amp'].unique())[1:] / 1000.\n",
    "stim_freq = np.sort(meta_ps['Stim_Freq'].unique())[1:]\n",
    "stim_dur = np.sort(meta_ps['Stim_Dur'].unique()) / 1000.\n",
    "\n",
    "n_amp = len(stim_amp)\n",
    "n_freq = len(stim_freq)\n",
    "n_dur = len(stim_dur)\n",
    "\n",
    "canvas = figure(figsize=(6,6), dpi=300.0)\n",
    "axes = Axes3D(canvas)\n",
    "quads = cube(width=stim_amp.max(), width_segments=n_amp,\n",
    "             height=stim_freq.max(), height_segments=n_freq,\n",
    "             depth=stim_dur.max(), depth_segments=n_dur)\n",
    "\n",
    "# define the colormap\n",
    "cmap = plt.get_cmap('magma')\n",
    "max_vals = stim_amp.max()*stim_freq.max()*stim_dur.max()\n",
    "vals = np.max(quads, axis=-2)\n",
    "vals = vals[:,0] * vals[:,1] * vals[:,2]\n",
    "\n",
    "\n",
    "# You can replace the following line by whatever suits you. Here, we compute\n",
    "# each quad colour by averaging its vertices positions.\n",
    "RGB = cmap(vals / max_vals)[:, :3]\n",
    "RGBA = np.hstack((RGB, np.full((RGB.shape[0], 1), .75)))\n",
    "\n",
    "collection = Poly3DCollection(quads, linewidths=0.0)\n",
    "collection.set_color(RGBA)\n",
    "axes.add_collection3d(collection)\n",
    "axes.set_xlim([0, stim_amp.max()])\n",
    "axes.set_ylim([0, stim_dur.max()])\n",
    "axes.set_zlim([0, stim_freq.max()])\n",
    "axes.view_init(azim=45)\n",
    "\n",
    "plt.savefig('{}/Stim_Energy.Cubed.svg'.format(path_Data['Figure'][reref]))\n",
    "\n",
    "show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Post Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@memory.cache\n",
    "def compute_prepost_coherence_stimenergy(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "        \n",
    "    # Initialize the measurement buckets (2 columns for post1/post2)\n",
    "    vals = {'Subject_ID': [],\n",
    "            'Coherence_ID': [],\n",
    "            'Stim_Type': [],\n",
    "            'Stim_Loc': [],\n",
    "            'Stim_Energy': [],\n",
    "            cfg_measure + '_Del_1': [],\n",
    "            cfg_measure + '_Del_2': []}\n",
    "    \n",
    "    # Condence the measurement across the common key criteria\n",
    "    for tp in df_luts.keys():\n",
    "        df_key = df_luts[tp]['common_key']\n",
    "        df_ind = df_luts[tp]['df_ind']        \n",
    "        df_topo = df_luts[tp]['df_topo']\n",
    "    \n",
    "        # Iterate over keys\n",
    "        for key_ii, key in enumerate(df_key):\n",
    "            df_sel = df_topo.iloc[df_ind[key]]\n",
    "\n",
    "            subj_id = df_sel['Subject_ID'].iloc[0]\n",
    "            coh_id = df_sel['Coherence_ID'].iloc[0]\n",
    "            stim_anode = df_sel['Stim_Anode'].iloc[0]\n",
    "            stim_cathode = df_sel['Stim_Cathode'].iloc[0]\n",
    "            stim_dur = df_sel['Stim_Dur'].iloc[0] / 1000.            \n",
    "            stim_freq = df_sel['Stim_Freq'].iloc[0]\n",
    "            stim_amp = df_sel['Stim_Amp'].iloc[0] / 1000.\n",
    "            stim_energy = stim_freq*stim_dur*stim_amp\n",
    "            \n",
    "            # Compute Measurement\n",
    "            if cfg_measure in ['Cfg_Str_Mean', 'Cfg_Str_Var']:\n",
    "                post1_vs_pre = (df_sel['Post1_' + cfg_measure] - df_sel['Pre_' + cfg_measure]).mean()\n",
    "                post2_vs_pre = (df_sel['Post2_' + cfg_measure] - df_sel['Pre_' + cfg_measure]).mean()\n",
    "            elif cfg_measure in ['Node_Str_Mean']:\n",
    "                post1_vs_pre = (df_sel['Post1_Node_Str'].apply(np.mean, axis=0) - df_sel['Pre_Node_Str'].apply(np.mean, axis=0)).mean()\n",
    "                post2_vs_pre = (df_sel['Post2_Node_Str'].apply(np.mean, axis=0) - df_sel['Pre_Node_Str'].apply(np.mean, axis=0)).mean()\n",
    "            elif cfg_measure in ['Node_Str_Var']:\n",
    "                post1_vs_pre = (df_sel['Post1_Node_Str'].apply(np.var, axis=0) - df_sel['Pre_Node_Str'].apply(np.var, axis=0)).mean()\n",
    "                post2_vs_pre = (df_sel['Post2_Node_Str'].apply(np.var, axis=0) - df_sel['Pre_Node_Str'].apply(np.var, axis=0)).mean()                \n",
    "            elif cfg_measure in ['Stim_Cfg_Sim']:\n",
    "                post1_vs_pre = ((df_sel[cfg_measure + '1'])).mean()\n",
    "                post2_vs_pre = ((df_sel[cfg_measure + '2'])).mean()\n",
    "            else:\n",
    "                raise ValueError('{} not a valid measurement'.format(cfg_measure))\n",
    "\n",
    "            # Add to the dictionary\n",
    "            vals['Subject_ID'].append(subj_id)\n",
    "            vals['Coherence_ID'].append(coh_id)\n",
    "            vals['Stim_Type'].append(tp)\n",
    "            vals['Stim_Loc'].append('_'.join(np.sort([stim_anode, stim_cathode])))\n",
    "            vals['Stim_Energy'].append(stim_energy)\n",
    "            vals[cfg_measure + '_Del_1'].append(post1_vs_pre)\n",
    "            vals[cfg_measure + '_Del_2'].append(post2_vs_pre)            \n",
    "    \n",
    "    # Convert to pandas dataframe\n",
    "    df = pd.DataFrame(vals, columns=vals.keys())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Mean Coherence)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},\n",
    "            'Node_Str_Mean':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Mean Node Strength)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},            \n",
    "            'Cfg_Str_Var':           {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Var Coherence)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},  \n",
    "            'Node_Str_Var':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Var Node Strength)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},              \n",
    "            'Stim_Cfg_Sim':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Edge Correlation)',\n",
    "                                      'color': sns.xkcd_palette(['amber'])[0]}}\n",
    "\n",
    "suffixes = ['_Del_1', '_Del_2']\n",
    "\n",
    "for meas in analysis.keys():\n",
    "    df = compute_prepost_coherence_stimenergy(meas)\n",
    "    suffixes = ['_Del_1', '_Del_2']\n",
    "    df = df.groupby(['Subject_ID', 'Stim_Loc', 'Stim_Energy', 'Coherence_ID']).mean().reset_index()\n",
    "    df_A = df.groupby(['Subject_ID', 'Stim_Loc', 'Coherence_ID'])[['Stim_Energy',\n",
    "                                                       meas+suffixes[0],\n",
    "                                                       meas+suffixes[1]]].corr('spearman').reset_index()\n",
    "    df_A = df_A[df_A['level_3'] == 'Stim_Energy']\n",
    "    \n",
    "    for suffix in suffixes:\n",
    "        meas_full = meas + suffix   \n",
    "        \n",
    "        # Get basic trends/stats\n",
    "        df_range_medn = df_A.groupby('Coherence_ID').quantile(q=0.50).reset_index()\n",
    "        df_range_qnt1 = df_A.groupby('Coherence_ID').quantile(q=0.25).reset_index()\n",
    "        df_range_qnt3 = df_A.groupby('Coherence_ID').quantile(q=0.75).reset_index()\n",
    "\n",
    "        # Seaborn params\n",
    "        plt.figure(figsize=(4,6), dpi=300)\n",
    "        ax = plt.subplot(111)        \n",
    "        sns_plot_params = {'x': 'Coherence_ID',\n",
    "                           'y': meas_full,\n",
    "                           'order': meta_dict['coherence_info'],\n",
    "                           'data': df_A,\n",
    "                           'color': analysis[meas]['color'],\n",
    "                           'ax': ax}\n",
    "\n",
    "        # Add Mean/Serr Bars\n",
    "        for c_ii, c_id in enumerate(meta_dict['coherence_info']):\n",
    "            medn = df_range_medn[df_range_medn['Coherence_ID'] == c_id][meas_full]\n",
    "            qnt1 = df_range_qnt1[df_range_qnt1['Coherence_ID'] == c_id][meas_full]\n",
    "            qnt3 = df_range_qnt3[df_range_qnt3['Coherence_ID'] == c_id][meas_full]            \n",
    "            ax.hlines(medn, c_ii-0.2, c_ii+0.2,\n",
    "                      color='k', linestyle='-', linewidth=2.0, zorder=100)\n",
    "            ax.hlines(qnt1, c_ii-0.3, c_ii+0.3,\n",
    "                      color='k', linestyle='--', linewidth=1.0, zorder=100)\n",
    "            ax.hlines(qnt3, c_ii-0.3, c_ii+0.3,\n",
    "                      color='k', linestyle='--', linewidth=1.0, zorder=100)    \n",
    "        ax.hlines(0.0, -0.5, len(meta_dict['coherence_info'])+0.5, linewidth=1.0, zorder=100)\n",
    "        \n",
    "        # Add a strip plot points            \n",
    "        ax = sns.stripplot(dodge=True,\n",
    "                           jitter=True,\n",
    "                           size=3,\n",
    "                           alpha=0.25,      \n",
    "                           **sns_plot_params)         \n",
    "        \n",
    "        # Prettify the plotting + add labels\n",
    "        ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "        ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "        ax.set_ylim([-1.0, 1.0])\n",
    "        ax.set_title(meas_full)\n",
    "        sns.despine(ax=ax)\n",
    "        #sns.set_context('paper')\n",
    "\n",
    "        plt.savefig('{}/Stim_Energy.{}.Distrib.svg'.format(path_Data['Figure'], meas_full))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "                \n",
    "        # Stats\n",
    "        write(':: STATS ::\\n')\n",
    "\n",
    "        df_A = df_A.dropna()\n",
    "        A_arr = []\n",
    "        for coh_id in meta_dict['coherence_info']:\n",
    "            A = df_A[df_A['Coherence_ID'] == coh_id][meas_full]\n",
    "            A_arr.append(A)  \n",
    "            \n",
    "            write('{}\\n'.format(coh_id))\n",
    "            write('    Shapiro   :: (Stim-Base) --> {}\\n'.format(stats.shapiro(A)))            \n",
    "            write('    t-test_{} :: (Stim-Base) --> {}\\n'.format(len(A)-1, stats.ttest_1samp(A, 0)))\n",
    "        write('Kruskal (Stim) :: F={}\\n'.format(stats.f_oneway(*np.array(A_arr))))        \n",
    "        write('\\n\\n\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stimulation Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth_roi = ['Isthmuscingulate',\n",
    "             'accumbensarea',\n",
    "             'caudalanteriorcingulate',\n",
    "             'caudate',\n",
    "             'entorhinal',\n",
    "             'hyppocampus',\n",
    "             'insula',\n",
    "             'isthmuscingulate',\n",
    "             'pallidum',\n",
    "             'posteriorcingulate',\n",
    "             'putamen',\n",
    "             'rostralanteriorcingulate',\n",
    "             'thalamusproper']\n",
    "\n",
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key = ['Subject_ID',\n",
    "                   'Stim_Anode',\n",
    "                   'Stim_Cathode',\n",
    "                   'Stim_Dur',\n",
    "                   'Coherence_ID']\n",
    "\n",
    "df_stim_sel = df_globaltopo_stim.groupby(unique_stim_key).indices\n",
    "df_base_sel = df_globaltopo_base.groupby(unique_stim_key).indices\n",
    "\n",
    "# Use Keys that overlap between stim and base\n",
    "df_base_key = df_base_sel.keys()\n",
    "df_stim_key = df_stim_sel.keys()\n",
    "df_base_key_set = np.array([set(k) for k in df_base_key])\n",
    "df_stim_key_set = np.array([set(k) for k in df_stim_key])\n",
    "\n",
    "df_base_common_key = []\n",
    "df_stim_common_key = []\n",
    "for b_k_ii, b_k in enumerate(df_base_key_set):\n",
    "    for s_k_ii, s_k in enumerate(df_stim_key_set):\n",
    "        if b_k == s_k:\n",
    "            df_base_common_key.append(df_base_key[b_k_ii])\n",
    "            df_stim_common_key.append(df_stim_key[s_k_ii])            \n",
    "            continue\n",
    "            \n",
    "df_luts = {'stim': {'common_key': df_stim_common_key,\n",
    "                    'df_ind': df_stim_sel,\n",
    "                    'df_topo': df_globaltopo_stim},\n",
    "           'base': {'common_key': df_base_common_key,\n",
    "                    'df_ind': df_base_sel,\n",
    "                    'df_topo': df_globaltopo_base}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Stimulation Locs (MNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, _, node_str, node_coord = compute_prepost_coherence_stimparam('Node_Str_Delta')\n",
    "\n",
    "def plot_sensors(node_coord, node_vals):\n",
    "    from Echobase.Plotting import render_brain_connectivity\n",
    "\n",
    "    ### Collect surface data\n",
    "    # Vertices and triangles\n",
    "    verts_rh, trias_rh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/rh.pial'.format(path_AtlasData))\n",
    "    verts_lh, trias_lh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/lh.pial'.format(path_AtlasData))\n",
    "\n",
    "    n_rh_verts = verts_rh.shape[0]\n",
    "    n_lh_verts = verts_lh.shape[0]\n",
    "\n",
    "    verts = np.vstack((verts_rh, verts_lh))\n",
    "    trias = np.vstack((trias_rh, trias_lh+n_rh_verts))\n",
    "\n",
    "    label_scalars = 20*np.zeros(n_rh_verts+n_lh_verts)\n",
    "\n",
    "    view_angle = {'Cor_RL': [90.0, 90.0],\n",
    "                  'Sag_PA': [0.0, 90.0],\n",
    "                  'Sag_AP': [180.0, 90.0]}\n",
    "    \n",
    "    cmap = plt.get_cmap('coolwarm')\n",
    "    node_rgba = np.array([cmap(nn) for nn in node_vals])\n",
    "    node_size= np.array([4.0 for nn in node_coord])\n",
    "\n",
    "    render_brain_connectivity.mlab.close(all=True)    \n",
    "    engine = render_brain_connectivity.draw(verts, trias, label_scalars, 'binary', 10.0,\n",
    "                                            node_coords=node_coord, node_sizes=node_size, node_colors=node_rgba,\n",
    "                                            conn_list=None, conn_cmap=None)\n",
    "    pixmap = {}\n",
    "    for ang in view_angle.keys():\n",
    "        render_brain_connectivity.mlab.view(azimuth=view_angle[ang][0],\n",
    "                                            elevation=view_angle[ang][1])\n",
    "        pixmap['{}'.format(ang)] = render_brain_connectivity.mlab.screenshot(mode='rgba')\n",
    "    render_brain_connectivity.mlab.close(all=True)\n",
    "    \n",
    "    return pixmap\n",
    "\n",
    "\n",
    "unique_node_coord = []\n",
    "unique_node_str = []\n",
    "for ii in xrange(node_coord['stim'].shape[0]):\n",
    "    nc = tuple(node_coord['stim'][ii, :])\n",
    "    if np.linalg.norm(nc) > 150:\n",
    "        continue\n",
    "    if nc in unique_node_coord:\n",
    "        continue        \n",
    "        \n",
    "    unique_node_coord.append(nc)\n",
    "    unique_node_str.append(node_str['stim'][ii, :, :])\n",
    "node_coord = np.array(unique_node_coord)\n",
    "node_str = np.array(unique_node_str)\n",
    "\n",
    "\"\"\"\n",
    "sensor_pixmap = plot_sensors(node_coord, np.ones((node_coord.shape[0])))   \n",
    "plt.figure(figsize=(4.5,1.5), dpi=600.0)\n",
    "for jj, key in enumerate(['Sag_PA', 'Cor_RL', 'Sag_AP']):\n",
    "    ax = plt.subplot(1,3,jj+1)\n",
    "    ax.imshow(sensor_pixmap[key])\n",
    "    ax.set_axis_off()\n",
    "plt.savefig('{}/Stim_Location.freesurfer.svg'.format(path_Data['Figure'][reref]))\n",
    "plt.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Post Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@memory.cache\n",
    "def compute_prepost_coherence_stimloc(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "        \n",
    "    # Initialize the measurement buckets (2 columns for post1/post2)\n",
    "    vals = {'Subject_ID': [],\n",
    "            'Coherence_ID': [],\n",
    "            'Stim_Type': [],\n",
    "            'Stim_Loc': [],\n",
    "            'Stim_ROI': [],\n",
    "            'Stim_Depth': [],            \n",
    "            'Stim_NodeStr': [],\n",
    "            cfg_measure + '_Del_1': [],\n",
    "            cfg_measure + '_Del_2': []}\n",
    "    \n",
    "    # Condence the measurement across the common key criteria\n",
    "    for tp in ['stim']:\n",
    "        df_key = df_luts[tp]['common_key']\n",
    "        df_ind = df_luts[tp]['df_ind']        \n",
    "        df_topo = df_luts[tp]['df_topo']\n",
    "        \n",
    "        df_key_base = df_luts['base']['common_key']\n",
    "        df_ind_base = df_luts['base']['df_ind']        \n",
    "        df_topo_base = df_luts['base']['df_topo']\n",
    "        \n",
    "        # Iterate over keys\n",
    "        for key_ii, key in enumerate(df_key):\n",
    "            df_sel = df_topo.iloc[df_ind[key]]\n",
    "            df_sel_base = df_topo_base.iloc[df_ind_base[df_key_base[key_ii]]]\n",
    "            \n",
    "            subj_id = df_sel['Subject_ID'].iloc[0]\n",
    "            coh_id = df_sel['Coherence_ID'].iloc[0]\n",
    "            \n",
    "            # Condense the labels for baseline (artifact_free)\n",
    "            stim_anode = df_sel_base['Stim_Anode'].iloc[0]\n",
    "            stim_cathode = df_sel_base['Stim_Cathode'].iloc[0]\n",
    "            \n",
    "            # Find the stim tag that matches current anode/cathode pair\n",
    "            monop = meta_dict['electrode_loc'][subj_id]['Monopolar']\n",
    "            for stim_tag in monop['lbl_artifact'].keys():\n",
    "                tags = stim_tag.split('_')\n",
    "                \n",
    "                if (((tags[0] == stim_anode) or (tags[0] == stim_cathode)) &\n",
    "                    ((tags[1] == stim_anode) or (tags[1] == stim_cathode))):\n",
    "                    break\n",
    "            \n",
    "            # Remove all artifact electrodes (excluding the stim channels)\n",
    "            nonstim_lbl_artifact = np.unique(np.setdiff1d(monop['lbl_artifact'][stim_tag],\n",
    "                                                          np.array([stim_anode, stim_cathode])))\n",
    "            nonstim_ix_artifact = np.array([np.flatnonzero(monop['lbl'] == lbl)[0]\n",
    "                                            for lbl in nonstim_lbl_artifact])\n",
    "            goodchan_ix = np.setdiff1d(np.arange(len(monop['lbl'])),\n",
    "                                       nonstim_ix_artifact)\n",
    "            good_lbls = monop['lbl'][goodchan_ix]\n",
    "                        \n",
    "            # Find the stim nodes in the electrode list and use base as reference node strengths\n",
    "            try:\n",
    "                anode_ix = np.flatnonzero(good_lbls == stim_anode)[0]\n",
    "                cathode_ix = np.flatnonzero(good_lbls == stim_cathode)[0]\n",
    "            except:\n",
    "                print('err 1: ---> ', subj_id)                \n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                stim_nodestr = []\n",
    "                for nodestr in df_sel_base['Pre_Node_Str']:\n",
    "                    stim_nodestr.append(0.5*(nodestr[anode_ix]+nodestr[cathode_ix]))\n",
    "                stim_nodestr = np.mean(stim_nodestr)\n",
    "                \n",
    "                stim_edgestr = []\n",
    "                for adj in df_sel_base['Mean_Adj']:\n",
    "                    stim_edgestr.append(np.delete(adj[anode_ix, :], obj=(anode_ix, cathode_ix)))\n",
    "                    stim_edgestr.append(np.delete(adj[cathode_ix, :], obj=(anode_ix, cathode_ix)))\n",
    "                stim_edgestr = np.array(stim_edgestr).mean(axis=0)\n",
    "            except:\n",
    "                print('err 2: ---> ', subj_id)\n",
    "                continue\n",
    "\n",
    "            # Compute Measurement\n",
    "            if cfg_measure in ['Cfg_Str_Mean', 'Cfg_Str_Var']:\n",
    "                post1_vs_pre = (df_sel['Post1_' + cfg_measure] - df_sel['Pre_' + cfg_measure]).mean()\n",
    "                post2_vs_pre = (df_sel['Post2_' + cfg_measure] - df_sel['Pre_' + cfg_measure]).mean()\n",
    "            elif cfg_measure in ['Node_Str_Mean']:\n",
    "                post1_vs_pre = (df_sel['Post1_Node_Str'].apply(np.mean, axis=0) - df_sel['Pre_Node_Str'].apply(np.mean, axis=0)).mean()\n",
    "                post2_vs_pre = (df_sel['Post2_Node_Str'].apply(np.mean, axis=0) - df_sel['Pre_Node_Str'].apply(np.mean, axis=0)).mean()\n",
    "            elif cfg_measure in ['Node_Str_Var']:\n",
    "                post1_vs_pre = (df_sel['Post1_Node_Str'].apply(np.var, axis=0) - df_sel['Pre_Node_Str'].apply(np.var, axis=0)).mean()\n",
    "                post2_vs_pre = (df_sel['Post2_Node_Str'].apply(np.var, axis=0) - df_sel['Pre_Node_Str'].apply(np.var, axis=0)).mean()                \n",
    "            elif cfg_measure in ['Stim_Cfg_Sim']:\n",
    "                post1_vs_pre = ((df_sel[cfg_measure + '1'])).mean()\n",
    "                post2_vs_pre = ((df_sel[cfg_measure + '2'])).mean()\n",
    "            elif cfg_measure in ['Edge_Pred_MeanNodeStr']:\n",
    "                post1_vs_pre = np.abs(np.array([val for val in (df_sel['Post1_Node_Str']-df_sel['Pre_Node_Str']).values])).mean(axis=0)\n",
    "                post2_vs_pre = np.abs(np.array([val for val in (df_sel['Post2_Node_Str']-df_sel['Pre_Node_Str']).values])).mean(axis=0)\n",
    "                try: \n",
    "                    post1_vs_pre = stats.spearmanr(stim_edgestr, post1_vs_pre)[0]\n",
    "                except:\n",
    "                    post1_vs_pre = np.nan\n",
    "                try:\n",
    "                    post2_vs_pre = stats.spearmanr(stim_edgestr, post2_vs_pre)[0]                \n",
    "                except:\n",
    "                    post2_vs_pre = np.nan\n",
    "            elif cfg_measure in ['Edge_Pred_VarNodeStr']:\n",
    "                post1_vs_pre = np.abs(np.array([val for val in (df_sel['Post1_Node_Str']-df_sel['Pre_Node_Str']).values])).var(axis=0)\n",
    "                post2_vs_pre = np.abs(np.array([val for val in (df_sel['Post2_Node_Str']-df_sel['Pre_Node_Str']).values])).var(axis=0)\n",
    "                try: \n",
    "                    post1_vs_pre = stats.spearmanr(stim_edgestr, post1_vs_pre)[0]\n",
    "                except:\n",
    "                    post1_vs_pre = np.nan\n",
    "                try:\n",
    "                    post2_vs_pre = stats.spearmanr(stim_edgestr, post2_vs_pre)[0]                \n",
    "                except:\n",
    "                    post2_vs_pre = np.nan                    \n",
    "            else:\n",
    "                raise ValueError('{} not a valid measurement'.format(cfg_measure))\n",
    "\n",
    "            # Stim ROI\n",
    "            stim_loc_ix = np.flatnonzero(meta_dict['electrode_loc'][subj_id]['Monopolar']['lbl'] == stim_anode)[0]\n",
    "            stim_loc_roi = meta_dict['electrode_loc'][subj_id]['Atlas']['lbl']['scale500'][stim_loc_ix]\n",
    "            stim_loc_roi = stim_loc_roi.split('_')[1].lower()\n",
    "            \n",
    "            if stim_loc_roi in depth_roi:\n",
    "                stim_depth = 'DEPTH'\n",
    "            else:\n",
    "                stim_depth = 'SURFACE'\n",
    "                \n",
    "            # Add to the dictionary\n",
    "            vals['Subject_ID'].append(subj_id)\n",
    "            vals['Coherence_ID'].append(coh_id)\n",
    "            vals['Stim_Type'].append(tp)\n",
    "            vals['Stim_Loc'].append('_'.join(np.sort([stim_anode, stim_cathode])))\n",
    "            vals['Stim_ROI'].append(stim_loc_roi)\n",
    "            vals['Stim_Depth'].append(stim_depth)            \n",
    "            vals['Stim_NodeStr'].append(stim_nodestr)\n",
    "            vals[cfg_measure + '_Del_1'].append(post1_vs_pre)\n",
    "            vals[cfg_measure + '_Del_2'].append(post2_vs_pre)            \n",
    "    \n",
    "    # Convert to pandas dataframe\n",
    "    df = pd.DataFrame(vals, columns=vals.keys())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Mean Coherence)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},\n",
    "            'Node_Str_Mean':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Mean Node Strength)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},            \n",
    "            'Cfg_Str_Var':           {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Var Coherence)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},  \n",
    "            'Node_Str_Var':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Var Node Strength)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},              \n",
    "            'Stim_Cfg_Sim':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Edge Correlation)',\n",
    "                                      'color': sns.xkcd_palette(['amber'])[0]}}\n",
    "suffixes = ['_Del_1', '_Del_2']\n",
    "\n",
    "for meas in analysis.keys():\n",
    "    df = compute_prepost_coherence_stimloc(meas)\n",
    "    \n",
    "    df = df.groupby(['Subject_ID', 'Stim_Loc', 'Stim_Depth', 'Coherence_ID']).mean().reset_index()    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    assert True == False\n",
    "    \n",
    "    for suffix in suffixes:\n",
    "        meas_full = meas + suffix   \n",
    "        \n",
    "        df_A = {'Coherence_ID': [],\n",
    "                meas_full + '_rv': [],\n",
    "                meas_full + '_pv': []}\n",
    "        for c_id in meta_dict['coherence_info']:\n",
    "            rv, pv = stats.spearmanr(df[df['Coherence_ID'] == c_id]['Stim_NodeStr'],\n",
    "                                     df[df['Coherence_ID'] == c_id][meas_full])\n",
    "            df_A['Coherence_ID'].append(c_id)\n",
    "            df_A[meas_full + '_rv'].append(rv)\n",
    "            df_A[meas_full + '_pv'].append(pv)            \n",
    "        df_A = pd.DataFrame(df_A, columns=df_A.keys())\n",
    "\n",
    "            \n",
    "        # Get basic trends/stats\n",
    "        df_range_medn = df_A.groupby('Coherence_ID').quantile(q=0.50).reset_index()\n",
    "        df_range_qnt1 = df_A.groupby('Coherence_ID').quantile(q=0.25).reset_index()\n",
    "        df_range_qnt3 = df_A.groupby('Coherence_ID').quantile(q=0.75).reset_index()\n",
    "\n",
    "        # Seaborn params\n",
    "        plt.figure(figsize=(4,6), dpi=300.0)\n",
    "        ax = plt.subplot(111)        \n",
    "        sns_plot_params = {'x': 'Coherence_ID',\n",
    "                           'y': meas_full+'_rv',\n",
    "                           'order': meta_dict['coherence_info'],\n",
    "                           'data': df_A,\n",
    "                           'color': analysis[meas]['color'],\n",
    "                           'ax': ax}\n",
    "\n",
    "        # Add a bar plot points            \n",
    "        ax = sns.barplot(**sns_plot_params)      \n",
    "        ax.hlines(0.0, -0.5, len(meta_dict['coherence_info'])+0.5, linewidth=2.0, zorder=100)        \n",
    "        \n",
    "        # Prettify the plotting + add labels\n",
    "        ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "        ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "        ax.set_ylim([-1.0, 1.0])\n",
    "        ax.set_title(meas_full)\n",
    "        sns.despine(ax=ax)\n",
    "        #sns.set_context('paper')\n",
    "\n",
    "        plt.savefig('{}/Stim_Loc.{}.Distrib.svg'.format(path_Data['Figure'], meas_full))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "                \n",
    "        # Stats\n",
    "        write(':: STATS ::\\n')\n",
    "\n",
    "        df_A = df_A.dropna()\n",
    "        for coh_id in meta_dict['coherence_info']:\n",
    "            rv = df_A[df_A['Coherence_ID'] == coh_id][meas_full + '_rv'].iloc[0]\n",
    "            pv = df_A[df_A['Coherence_ID'] == coh_id][meas_full + '_pv'].iloc[0]           \n",
    "            \n",
    "            write('{}\\n'.format(coh_id))\n",
    "            write('    Spearman_{} :: (Stim)      --> rv={}, pv={}\\n'.format(len(df[df['Coherence_ID'] == coh_id])-2, rv, pv))\n",
    "        write('\\n\\n\\n')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare Depth vs Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Mean Coherence)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},\n",
    "            'Node_Str_Mean':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Mean Node Strength)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},            \n",
    "            'Cfg_Str_Var':           {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Var Coherence)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},  \n",
    "            'Node_Str_Var':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Delta Var Node Strength)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},              \n",
    "            'Stim_Cfg_Sim':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Energy, Edge Correlation)',\n",
    "                                      'color': sns.xkcd_palette(['amber'])[0]}}\n",
    "suffixes = ['_Del_1', '_Del_2']\n",
    "\n",
    "for meas in analysis.keys():\n",
    "    for depth in ['DEPTH', 'SURFACE']:\n",
    "        df = compute_prepost_coherence_stimloc(meas)\n",
    "\n",
    "        df = df.groupby(['Subject_ID', 'Stim_Loc', 'Stim_Depth', 'Coherence_ID']).mean().reset_index()    \n",
    "        df = df[df['Stim_Depth'] == depth]\n",
    "        \n",
    "        print('====== {}, {} ====='.format(depth, (df.groupby(['Stim_Depth']).size() / 4)[0]))\n",
    "        \n",
    "        df = df.dropna()\n",
    "\n",
    "\n",
    "        for suffix in suffixes:\n",
    "            meas_full = meas + suffix   \n",
    "\n",
    "            df_A = {'Coherence_ID': [],\n",
    "                    meas_full + '_rv': [],\n",
    "                    meas_full + '_pv': []}\n",
    "            for c_id in meta_dict['coherence_info']:\n",
    "                rv, pv = stats.spearmanr(df[df['Coherence_ID'] == c_id]['Stim_NodeStr'],\n",
    "                                         df[df['Coherence_ID'] == c_id][meas_full])\n",
    "                df_A['Coherence_ID'].append(c_id)\n",
    "                df_A[meas_full + '_rv'].append(rv)\n",
    "                df_A[meas_full + '_pv'].append(pv)            \n",
    "            df_A = pd.DataFrame(df_A, columns=df_A.keys())\n",
    "\n",
    "\n",
    "            # Get basic trends/stats\n",
    "            df_range_medn = df_A.groupby('Coherence_ID').quantile(q=0.50).reset_index()\n",
    "            df_range_qnt1 = df_A.groupby('Coherence_ID').quantile(q=0.25).reset_index()\n",
    "            df_range_qnt3 = df_A.groupby('Coherence_ID').quantile(q=0.75).reset_index()\n",
    "\n",
    "            # Seaborn params\n",
    "            plt.figure(figsize=(4,6), dpi=300.0)\n",
    "            ax = plt.subplot(111)        \n",
    "            sns_plot_params = {'x': 'Coherence_ID',\n",
    "                               'y': meas_full+'_rv',\n",
    "                               'order': meta_dict['coherence_info'],\n",
    "                               'data': df_A,\n",
    "                               'color': analysis[meas]['color'],\n",
    "                               'ax': ax}\n",
    "\n",
    "            # Add a bar plot points            \n",
    "            ax = sns.barplot(**sns_plot_params)      \n",
    "            ax.hlines(0.0, -0.5, len(meta_dict['coherence_info'])+0.5, linewidth=2.0, zorder=100)        \n",
    "\n",
    "            # Prettify the plotting + add labels\n",
    "            ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "            ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "            ax.set_ylim([-1.0, 1.0])\n",
    "            ax.set_title(meas_full)\n",
    "            sns.despine(ax=ax)\n",
    "            #sns.set_context('paper')\n",
    "\n",
    "            plt.savefig('{}/Stim_ROI_{}.{}.Distrib.svg'.format(path_Data['Figure'], depth, meas_full))\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            # Stats\n",
    "            write(':: STATS ::\\n')\n",
    "\n",
    "            df_A = df_A.dropna()\n",
    "            for coh_id in meta_dict['coherence_info']:\n",
    "                rv = df_A[df_A['Coherence_ID'] == coh_id][meas_full + '_rv'].iloc[0]\n",
    "                pv = df_A[df_A['Coherence_ID'] == coh_id][meas_full + '_pv'].iloc[0]           \n",
    "\n",
    "                write('{}\\n'.format(coh_id))\n",
    "                write('    Spearman_{} :: (Stim)      --> rv={}, pv={}\\n'.format(len(df[df['Coherence_ID'] == coh_id])-2, rv, pv))\n",
    "            write('\\n\\n\\n')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Predictive Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Edge_Pred_MeanNodeStr': {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'rho(Edge_Str, Mean_NodeStr)',\n",
    "                                      'color': sns.xkcd_palette(['blood red'])[0]},\n",
    "            'Edge_Pred_VarNodeStr': {'xlabel': 'Frequency Range',\n",
    "                                     'ylabel': 'rho(Edge_Str, Var_NodeStr)',\n",
    "                                     'color': sns.xkcd_palette(['cobalt'])[0]}} \n",
    "\n",
    "suffixes = ['_Del_1', '_Del_2']\n",
    "\n",
    "for meas in analysis.keys():\n",
    "    df = compute_prepost_coherence_stimloc(meas)\n",
    "    df = df.groupby(['Subject_ID', 'Stim_Loc', 'Coherence_ID']).mean().reset_index()\n",
    "    \n",
    "    for suffix in suffixes:\n",
    "        meas_full = meas + suffix   \n",
    "        \n",
    "        # Get basic trends/stats\n",
    "        df_range_medn = df.groupby('Coherence_ID').quantile(q=0.50).reset_index()\n",
    "        df_range_qnt1 = df.groupby('Coherence_ID').quantile(q=0.25).reset_index()\n",
    "        df_range_qnt3 = df.groupby('Coherence_ID').quantile(q=0.75).reset_index()\n",
    "\n",
    "        # Seaborn params\n",
    "        plt.figure(figsize=(4,6), dpi=300)\n",
    "        ax = plt.subplot(111)        \n",
    "        sns_plot_params = {'x': 'Coherence_ID',\n",
    "                           'y': meas_full,\n",
    "                           'order': meta_dict['coherence_info'],\n",
    "                           'data': df,\n",
    "                           'color': analysis[meas]['color'],\n",
    "                           'ax': ax}\n",
    "\n",
    "        # Add Mean/Serr Bars\n",
    "        for c_ii, c_id in enumerate(meta_dict['coherence_info']):\n",
    "            medn = df_range_medn[df_range_medn['Coherence_ID'] == c_id][meas_full]\n",
    "            qnt1 = df_range_qnt1[df_range_qnt1['Coherence_ID'] == c_id][meas_full]\n",
    "            qnt3 = df_range_qnt3[df_range_qnt3['Coherence_ID'] == c_id][meas_full]            \n",
    "            ax.hlines(medn, c_ii-0.2, c_ii+0.2,\n",
    "                      color='k', linestyle='-', linewidth=2.0, zorder=100)\n",
    "            ax.hlines(qnt1, c_ii-0.3, c_ii+0.3,\n",
    "                      color='k', linestyle='--', linewidth=1.0, zorder=100)\n",
    "            ax.hlines(qnt3, c_ii-0.3, c_ii+0.3,\n",
    "                      color='k', linestyle='--', linewidth=1.0, zorder=100)    \n",
    "        ax.hlines(0.0, -0.5, len(meta_dict['coherence_info'])+0.5, linewidth=1.0, zorder=100)\n",
    "        \n",
    "        # Add a strip plot points            \n",
    "        ax = sns.stripplot(dodge=True,\n",
    "                           jitter=True,\n",
    "                           size=3,\n",
    "                           alpha=0.25,      \n",
    "                           **sns_plot_params)         \n",
    "        \n",
    "        # Prettify the plotting + add labels\n",
    "        ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "        ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "        ax.set_ylim([-1.0, 1.0])\n",
    "        ax.set_title(meas_full)\n",
    "        sns.despine(ax=ax)\n",
    "        #sns.set_context('paper')\n",
    "\n",
    "        plt.savefig('{}/Stim_EdgeLoc.{}.Distrib.svg'.format(path_Data['Figure'], meas_full))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "                \n",
    "        # Stats\n",
    "        write(':: STATS ::\\n')\n",
    "\n",
    "        df_A = df.dropna()\n",
    "        A_arr = []\n",
    "        for coh_id in meta_dict['coherence_info']:\n",
    "            A = df_A[df_A['Coherence_ID'] == coh_id][meas_full]\n",
    "            A_arr.append(A)  \n",
    "            \n",
    "            write('{}\\n'.format(coh_id))\n",
    "            write('    Shapiro   :: (Stim-Base) --> {}\\n'.format(stats.shapiro(A)))            \n",
    "            write('    Wilcoxon_{} :: (Stim-Base) --> {}\\n'.format(len(A)-1, stats.wilcoxon(A)))\n",
    "        write('Kruskal (Stim) :: F={}\\n'.format(stats.kruskal(*np.array(A_arr))))        \n",
    "        write('\\n\\n\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Location Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate location keys\n",
    "loc_keys = list(np.unique(np.array([roi.split('_')[1]\n",
    "                                    for roi in meta_dict['atlas_info']['scale500'].keys()])))\n",
    "loc_keys.remove('brainstem')\n",
    "\n",
    "loc_dict = {}\n",
    "for key in loc_keys:\n",
    "    loc_dict[key] = 0\n",
    "\n",
    "# Count stim locations\n",
    "df = compute_prepost_coherence_stimloc('Cfg_Str_Var')\n",
    "for name, group in df.groupby(['Subject_ID', 'Stim_Loc']):\n",
    "    subj_id = name[0]\n",
    "    stim_loc = name[1].split('_')[0]\n",
    "    \n",
    "    stim_loc_ix = np.flatnonzero(meta_dict['electrode_loc'][subj_id]['Monopolar']['lbl'] == stim_loc)[0]\n",
    "    stim_loc_roi = meta_dict['electrode_loc'][subj_id]['Atlas']['lbl']['scale500'][stim_loc_ix]\n",
    "    stim_loc_roi = stim_loc_roi.split('_')[1]\n",
    "    \n",
    "    try:\n",
    "        loc_dict[stim_loc_roi] += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "roi_counts = np.array([(k.lower(),v) for k,v in loc_dict.iteritems()])    \n",
    "roi_counts = roi_counts[np.argsort(roi_counts[:, 0]), :]\n",
    "\n",
    "# Seaborn params\n",
    "plt.figure(figsize=(6,3), dpi=300)\n",
    "ax = plt.subplot(111)        \n",
    "\n",
    "ax.bar(range(len(roi_counts)),\n",
    "       roi_counts[:,1], align='center')\n",
    "ax.set_xticks(range(len(roi_counts)))\n",
    "ax.set_xticklabels(roi_counts[:, 0], rotation=90)\n",
    "ax.set_xlim([-1, len(roi_counts)])\n",
    "sns.despine(ax=ax)\n",
    "\n",
    "plt.savefig('{}/Stim_Electrode_Lausanne.Distrib.svg'.format(path_Data['Figure']))\n",
    "#plt.show()\n",
    "plt.close()  \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Prettify the plotting + add labels\n",
    "ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "ax.set_ylim([-1.0, 1.0])\n",
    "ax.set_title(meas_full)\n",
    "sns.despine(ax=ax)\n",
    "#sns.set_context('paper')\n",
    "\n",
    "plt.savefig('{}/Stim_EdgeLoc.{}.Distrib.svg'.format(path_Data['Figure'], meas_full))\n",
    "#plt.show()\n",
    "plt.close()  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Structural Node Strength to Baseline Node Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key = ['Subject_ID',\n",
    "                   'Coherence_ID']\n",
    "\n",
    "df_base_sel = df_globaltopo_base.groupby(unique_stim_key).indices\n",
    "\n",
    "# Use Keys that overlap between stim and base\n",
    "df_base_key = df_base_sel.keys()\n",
    "df_base_key_set = np.array([set(k) for k in df_base_key])\n",
    "            \n",
    "df_luts = {'base': {'common_key': df_base_key,\n",
    "                    'df_ind': df_base_sel,\n",
    "                    'df_topo': df_globaltopo_base}}\n",
    "\n",
    "\n",
    "def struct_funct_corr():\n",
    "    vals = {'Subject_ID': [],\n",
    "            'Scale_ID': [],\n",
    "            'Conn_ID': [],\n",
    "            'Coherence_ID': [],\n",
    "            'Conn_Corr': [],\n",
    "            'Node_Corr': []}\n",
    "\n",
    "    df_key = df_luts['base']['common_key']\n",
    "    df_ind = df_luts['base']['df_ind']        \n",
    "    df_topo = df_luts['base']['df_topo']\n",
    "\n",
    "    # Iterate over keys\n",
    "    for key_ii, key in enumerate(df_key):\n",
    "        df_sel = df_topo.iloc[df_ind[key]]\n",
    "\n",
    "        subj_id = df_sel['Subject_ID'].iloc[0]\n",
    "        if subj_id not in meta_dict['struct_adj'].keys():\n",
    "            continue\n",
    "        if 'E' in subj_id:\n",
    "            continue\n",
    "        coh_id = df_sel['Coherence_ID'].iloc[0]\n",
    "        adj_base = df_sel['Mean_Adj'].iloc[0]\n",
    "        \n",
    "        # Condense the labels for baseline (artifact_free)\n",
    "        stim_anode = df_sel['Stim_Anode'].iloc[0]\n",
    "        stim_cathode = df_sel['Stim_Cathode'].iloc[0]\n",
    "\n",
    "        # Find the stim tag that matches current anode/cathode pair\n",
    "        monop = meta_dict['electrode_loc'][subj_id]['Monopolar']\n",
    "        for stim_tag in monop['lbl_artifact'].keys():\n",
    "            tags = stim_tag.split('_')\n",
    "\n",
    "            if (((tags[0] == stim_anode) or (tags[0] == stim_cathode)) &\n",
    "                ((tags[1] == stim_anode) or (tags[1] == stim_cathode))):\n",
    "                break\n",
    "\n",
    "        # Remove all artifact electrodes (excluding the stim channels)\n",
    "        nonstim_lbl_artifact = np.unique(np.setdiff1d(monop['lbl_artifact'][stim_tag],\n",
    "                                                      np.array([stim_anode, stim_cathode])))\n",
    "        nonstim_ix_artifact = np.array([np.flatnonzero(monop['lbl'] == lbl)[0]\n",
    "                                        for lbl in nonstim_lbl_artifact])\n",
    "        goodchan_ix = np.setdiff1d(np.arange(len(monop['lbl'])),\n",
    "                                   nonstim_ix_artifact)\n",
    "        \n",
    "        assert adj_base.shape[0] == len(goodchan_ix)\n",
    "        \n",
    "        # Convert to configuration vector\n",
    "        triu_ix, triu_iy = np.triu_indices(len(goodchan_ix), k=1)\n",
    "        cfg_base = adj_base[triu_ix, triu_iy]\n",
    "        node_base = adj_base.mean(axis=0)\n",
    "        \n",
    "        for scale_id in meta_dict['electrode_loc'][subj_id]['Atlas']['ix'].keys():\n",
    "            struct_elec_ix = meta_dict['electrode_loc'][subj_id]['Atlas']['ix'][scale_id][goodchan_ix]\n",
    "            \n",
    "            for conn_id in meta_dict['struct_adj'][subj_id][scale_id].keys():\n",
    "                adj_struct = meta_dict['struct_adj'][subj_id][scale_id][conn_id]['adj']\n",
    "                \n",
    "                cfg_struct = []\n",
    "                for ix, iy in zip(triu_ix, triu_iy):\n",
    "                    cfg_struct.append(adj_struct[struct_elec_ix[ix],\n",
    "                                                 struct_elec_ix[iy]])\n",
    "                cfg_struct = np.array(cfg_struct)                \n",
    "                node_struct = structural_control.modal_control(adj_struct)[struct_elec_ix]\n",
    "            \n",
    "                cfg_rv, _ = stats.pearsonr(cfg_struct[cfg_struct != 0], cfg_base[cfg_struct != 0])\n",
    "                node_rv, _ = stats.spearmanr(node_struct, node_base)\n",
    "                \n",
    "                vals['Subject_ID'].append(subj_id)\n",
    "                vals['Coherence_ID'].append(coh_id)                \n",
    "                vals['Scale_ID'].append(scale_id)\n",
    "                vals['Conn_ID'].append(conn_id)\n",
    "                vals['Conn_Corr'].append(cfg_rv)\n",
    "                vals['Node_Corr'].append(node_rv)                \n",
    "    \n",
    "    return pd.DataFrame(vals, columns=vals.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = struct_funct_corr()\n",
    "df = df.groupby(['Subject_ID', 'Conn_ID', 'Scale_ID', 'Coherence_ID']).mean().reset_index()\n",
    "\n",
    "for conn_id in df['Conn_ID'].unique():\n",
    "    for scale_id in df['Scale_ID'].unique():\n",
    "        df_A = df[(df['Conn_ID'] == conn_id) &\n",
    "                  (df['Scale_ID'] == scale_id)]\n",
    "\n",
    "        # Get basic trends/stats\n",
    "        df_range_medn = df_A.dropna().groupby(['Coherence_ID']).quantile(q=0.50).reset_index()\n",
    "        df_range_qnt1 = df_A.dropna().groupby(['Coherence_ID']).quantile(q=0.25).reset_index()\n",
    "        df_range_qnt3 = df_A.dropna().groupby(['Coherence_ID']).quantile(q=0.75).reset_index()\n",
    "        df_range_qnt0 = df_A.dropna().groupby(['Coherence_ID']).quantile(q=0.05).reset_index()\n",
    "        df_range_qnt4 = df_A.dropna().groupby(['Coherence_ID']).quantile(q=0.95).reset_index()        \n",
    "                    \n",
    "        # Seaborn params\n",
    "        plt.figure(figsize=(4,6), dpi=300)\n",
    "        ax = plt.subplot(111)        \n",
    "        sns_plot_params = {'x': 'Coherence_ID',\n",
    "                           'y': 'Conn_Corr',\n",
    "                           'order': meta_dict['coherence_info'],\n",
    "                           'data': df_A,\n",
    "                           'color': [0.2, 0.2, 0.2],\n",
    "                           'ax': ax}\n",
    "\n",
    "        # Add Mean/Serr Bars\n",
    "        for c_ii, c_id in enumerate(meta_dict['coherence_info']):\n",
    "            medn = df_range_medn[df_range_medn['Coherence_ID'] == c_id]['Conn_Corr']\n",
    "            qnt1 = df_range_qnt1[df_range_qnt1['Coherence_ID'] == c_id]['Conn_Corr']\n",
    "            qnt3 = df_range_qnt3[df_range_qnt3['Coherence_ID'] == c_id]['Conn_Corr']\n",
    "            ax.hlines(medn, c_ii-0.2, c_ii+0.2,\n",
    "                      color='k', linestyle='-', linewidth=2.0, zorder=100)\n",
    "            ax.hlines(qnt1, c_ii-0.3, c_ii+0.3,\n",
    "                      color='k', linestyle='--', linewidth=1.0, zorder=100)\n",
    "            ax.hlines(qnt3, c_ii-0.3, c_ii+0.3,\n",
    "                      color='k', linestyle='--', linewidth=1.0, zorder=100)    \n",
    "        ax.hlines(0.0, -0.5, len(meta_dict['coherence_info'])+0.5, linewidth=1.0, zorder=100)\n",
    "        \n",
    "        # Add a strip plot points            \n",
    "        ax = sns.stripplot(dodge=True,\n",
    "                           jitter=True,\n",
    "                           size=4,\n",
    "                           alpha=0.25,      \n",
    "                           **sns_plot_params)          \n",
    "        \n",
    "        # Prettify the plotting + add labels\n",
    "        ax.set_xlabel('Frequency Label')\n",
    "        ax.set_ylabel('Spearmans Rho')   \n",
    "        ax.set_ylim([-0.4, 0.4])\n",
    "        sns.despine(ax=ax)\n",
    "        #sns.set_context('paper')\n",
    "\n",
    "        plt.savefig('{}/Struct_Corr.{}.{}.Distrib.svg'.format(path_Data['Figure'], conn_id, scale_id))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        # Stats\n",
    "        write(':: STATS ::\\n')\n",
    "        \n",
    "        df_A = df_A.dropna()\n",
    "        A_arr = []\n",
    "        for coh_id in meta_dict['coherence_info']:\n",
    "            A = df_A[df_A['Coherence_ID'] == coh_id]['Conn_Corr']\n",
    "            A_arr.append(A)            \n",
    "            \n",
    "            write('{} -- Conn_ID: {} -- Scale_ID: {}\\n'.format(coh_id, conn_id, scale_id))\n",
    "            write('    Shapiro   :: (Stim-Base) --> {}\\n'.format(stats.shapiro(A)))            \n",
    "            write('    Wilcoxon_{} :: (Stim-Base) --> {}\\n'.format(len(A)-1, stats.ttest_1samp(A, 0)))\n",
    "        write('Kruskal (Stim) :: F={}\\n'.format(stats.kruskal(*np.array(A_arr))))        \n",
    "        write('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Controllability to Memory Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "meta_memr = meta_dict['memory_info']\n",
    "meta_memr['Delta_Prob'] = meta_memr['Post_Stim_Prob'] - meta_memr['Pre_Stim_Prob']\n",
    "meta_memr_lut = meta_memr.groupby(['Subject_ID',\n",
    "                                   'Stim_Anode',\n",
    "                                   'Stim_Cathode'])['Delta_Prob'].mean().reset_index()\n",
    "\n",
    "def struct_memory_corr():\n",
    "    vals = {'Subject_ID': [],\n",
    "            'Scale_ID': [],\n",
    "            'Conn_ID': [],\n",
    "            'Stim_Loc': [],\n",
    "            'Stim_Modal': [],\n",
    "            'Delta_Prob': []}\n",
    "\n",
    "    # Iterate over keys\n",
    "    for key_ii, key in meta_memr_lut.reset_index().iterrows():\n",
    "        subj_id = key['Subject_ID']\n",
    "        if subj_id not in meta_dict['struct_adj'].keys():\n",
    "            continue\n",
    "        if 'E' in subj_id:\n",
    "            continue\n",
    "        \n",
    "        # Condense the labels for baseline (artifact_free)\n",
    "        stim_anode = key['Stim_Anode'].upper()\n",
    "        stim_cathode = key['Stim_Cathode'].upper()\n",
    "\n",
    "        # Find the stim tag that matches current anode/cathode pair\n",
    "        monop = meta_dict['electrode_loc'][subj_id]['Monopolar']\n",
    "        stim_ix = np.array([np.flatnonzero(monop['lbl'] == lbl)[0]\n",
    "                            for lbl in [stim_anode, stim_cathode]])\n",
    "        \n",
    "        for scale_id in meta_dict['electrode_loc'][subj_id]['Atlas']['ix'].keys():\n",
    "            struct_elec_ix = meta_dict['electrode_loc'][subj_id]['Atlas']['ix'][scale_id][stim_ix]\n",
    "            \n",
    "            for conn_id in meta_dict['struct_adj'][subj_id][scale_id].keys():\n",
    "                adj_struct = meta_dict['struct_adj'][subj_id][scale_id][conn_id]['adj']\n",
    "                \n",
    "                control_val = structural_control.modal_control(adj_struct)[struct_elec_ix].mean()\n",
    "                \n",
    "                vals['Subject_ID'].append(subj_id)\n",
    "                vals['Scale_ID'].append(scale_id)\n",
    "                vals['Conn_ID'].append(conn_id)\n",
    "                vals['Stim_Loc'].append('{}-{}'.format(stim_anode, stim_cathode))\n",
    "                vals['Stim_Modal'].append(control_val)\n",
    "                vals['Delta_Prob'].append(key['Delta_Prob'])                \n",
    "    \n",
    "    return pd.DataFrame(vals, columns=vals.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = struct_memory_corr()\n",
    "df = df.groupby(['Subject_ID', 'Stim_Loc', 'Conn_ID', 'Scale_ID']).mean().reset_index()\n",
    "\n",
    "for conn_id in df['Conn_ID'].unique():\n",
    "    for scale_id in df['Scale_ID'].unique():\n",
    "        df_A = df[(df['Conn_ID'] == conn_id) &\n",
    "                  (df['Scale_ID'] == scale_id)]\n",
    "\n",
    "        # Seaborn params\n",
    "        plt.figure(figsize=(4,6), dpi=300.0)\n",
    "        ax = plt.subplot(111)     \n",
    "        ax = sns.regplot(x='Stim_Modal', \n",
    "                         y='Delta_Prob',\n",
    "                         data=df_A,\n",
    "                         ci=68,\n",
    "                         color=[0.2, 0.2, 0.2],\n",
    "                         scatter_kws={'s':15.0},\n",
    "                         ax=ax)\n",
    "\n",
    "        # Prettify the plotting + add labels\n",
    "        ax.set_xlabel('Modal Cntrl. (stim)')\n",
    "        ax.set_ylabel('Del. Mem. Enc. State Prob.')\n",
    "        ax.set_ylim([-0.02, 0.02])\n",
    "        sns.despine(ax=ax)\n",
    "\n",
    "        plt.savefig('{}/Mem_Class.{}.{}.Distrib.svg'.format(path_Data['Figure'], conn_id, scale_id))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        # Stats\n",
    "        write(':: STATS ::\\n')\n",
    "\n",
    "        write('Conn_ID: {} -- Scale_ID: {}\\n'.format(conn_id, scale_id))\n",
    "        write('    Pearson_{} :: (Stim)      --> {}\\n'.format(df_A.shape[0]-2, stats.pearsonr(df_A['Stim_Modal'], df_A['Delta_Prob'])))\n",
    "        write('    Spearman_{} :: (Stim)      --> {}\\n'.format(df_A.shape[0]-2, stats.spearmanr(df_A['Stim_Modal'], df_A['Delta_Prob'])))\n",
    "        write('\\n\\n\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Controllability to Pre-Post Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key = ['Subject_ID',\n",
    "                   'Stim_Anode',\n",
    "                   'Stim_Cathode',\n",
    "                   'Stim_Dur',\n",
    "                   'Coherence_ID']\n",
    "\n",
    "df_stim_sel = df_globaltopo_stim.groupby(unique_stim_key).indices\n",
    "\n",
    "# Use Keys that overlap between stim and base\n",
    "df_stim_key = df_stim_sel.keys()\n",
    "df_stim_key_set = np.array([set(k) for k in df_stim_key])\n",
    "            \n",
    "df_luts = {'stim': {'common_key': df_stim_key,\n",
    "                    'df_ind': df_stim_sel,\n",
    "                    'df_topo': df_globaltopo_stim}}\n",
    "\n",
    "def compute_prepost_coherence_stimmodal(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "        \n",
    "    # Initialize the measurement buckets (2 columns for post1/post2)\n",
    "    vals = {'Subject_ID': [],\n",
    "            'Coherence_ID': [],\n",
    "            'Stim_Loc': [],\n",
    "            'Scale_ID': [],\n",
    "            'Conn_ID': [],\n",
    "            'Stim_Modal': [],\n",
    "            cfg_measure + '_Del_1': [],\n",
    "            cfg_measure + '_Del_2': []}\n",
    "    \n",
    "    # Condence the measurement across the common key criteria\n",
    "    df_key = df_luts['stim']['common_key']\n",
    "    df_ind = df_luts['stim']['df_ind']        \n",
    "    df_topo = df_luts['stim']['df_topo']\n",
    "\n",
    "    # Iterate over keys\n",
    "    for key_ii, key in enumerate(df_key):\n",
    "        df_sel = df_topo.iloc[df_ind[key]]\n",
    "\n",
    "        subj_id = df_sel['Subject_ID'].iloc[0]\n",
    "        if subj_id not in meta_dict['struct_adj'].keys():\n",
    "            continue\n",
    "        #if 'E' in subj_id:\n",
    "        #    continue        \n",
    "        coh_id = df_sel['Coherence_ID'].iloc[0]\n",
    "        \n",
    "        # Condense the labels for baseline (artifact_free)\n",
    "        stim_anode = df_sel['Stim_Anode'].iloc[0]\n",
    "        stim_cathode = df_sel['Stim_Cathode'].iloc[0]\n",
    "                \n",
    "        # Find the stim tag that matches current anode/cathode pair\n",
    "        monop = meta_dict['electrode_loc'][subj_id]['Monopolar']\n",
    "        stim_ix = np.array([np.flatnonzero(monop['lbl'] == lbl)[0]\n",
    "                            for lbl in [stim_anode, stim_cathode]])\n",
    "        \n",
    "        for scale_id in meta_dict['electrode_loc'][subj_id]['Atlas']['ix'].keys():\n",
    "            struct_elec_ix = meta_dict['electrode_loc'][subj_id]['Atlas']['ix'][scale_id][stim_ix]\n",
    "            \n",
    "            for conn_id in meta_dict['struct_adj'][subj_id][scale_id].keys():\n",
    "                adj_struct = meta_dict['struct_adj'][subj_id][scale_id][conn_id]['adj']\n",
    "\n",
    "                control_val = structural_control.modal_control(adj_struct)[struct_elec_ix].mean()      \n",
    "        \n",
    "                # Compute Measurement\n",
    "                if cfg_measure in ['Cfg_Str_Mean', 'Cfg_Str_Var']:\n",
    "                    post1_vs_pre = (df_sel['Post1_' + cfg_measure] - df_sel['Pre_' + cfg_measure]).mean()\n",
    "                    post2_vs_pre = (df_sel['Post2_' + cfg_measure] - df_sel['Pre_' + cfg_measure]).mean()\n",
    "                elif cfg_measure in ['Node_Str_Mean']:\n",
    "                    post1_vs_pre = (df_sel['Post1_Node_Str'].apply(np.mean, axis=0) - df_sel['Pre_Node_Str'].apply(np.mean, axis=0)).mean()\n",
    "                    post2_vs_pre = (df_sel['Post2_Node_Str'].apply(np.mean, axis=0) - df_sel['Pre_Node_Str'].apply(np.mean, axis=0)).mean()\n",
    "                elif cfg_measure in ['Node_Str_Var']:\n",
    "                    post1_vs_pre = (df_sel['Post1_Node_Str'].apply(np.var, axis=0) - df_sel['Pre_Node_Str'].apply(np.var, axis=0)).mean()\n",
    "                    post2_vs_pre = (df_sel['Post2_Node_Str'].apply(np.var, axis=0) - df_sel['Pre_Node_Str'].apply(np.var, axis=0)).mean()                \n",
    "                elif cfg_measure in ['Stim_Cfg_Sim']:\n",
    "                    post1_vs_pre = ((df_sel[cfg_measure + '1'])).mean()\n",
    "                    post2_vs_pre = ((df_sel[cfg_measure + '2'])).mean()\n",
    "                else:\n",
    "                    raise ValueError('{} not a valid measurement'.format(cfg_measure))\n",
    "\n",
    "                # Add to the dictionary\n",
    "                vals['Subject_ID'].append(subj_id)\n",
    "                vals['Coherence_ID'].append(coh_id)\n",
    "                vals['Stim_Loc'].append('_'.join(np.sort([stim_anode, stim_cathode])))\n",
    "                vals['Scale_ID'].append(scale_id)\n",
    "                vals['Conn_ID'].append(conn_id)                \n",
    "                vals['Stim_Modal'].append(control_val)\n",
    "                vals[cfg_measure + '_Del_1'].append(post1_vs_pre)\n",
    "                vals[cfg_measure + '_Del_2'].append(post2_vs_pre)            \n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    df = pd.DataFrame(vals, columns=vals.keys())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Modal, Delta Mean Coherence)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},\n",
    "            'Node_Str_Mean':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Modal, Delta Mean Node Strength)',\n",
    "                                      'color': sns.xkcd_palette(['windows blue'])[0]},            \n",
    "            'Cfg_Str_Var':           {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Modal, Delta Var Coherence)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},  \n",
    "            'Node_Str_Var':         {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Modal, Delta Var Node Strength)',\n",
    "                                      'color': sns.xkcd_palette(['light olive green'])[0]},              \n",
    "            'Stim_Cfg_Sim':          {'xlabel': 'Frequency Range',\n",
    "                                      'ylabel': 'r2(Stim_Modal, Edge Correlation)',\n",
    "                                      'color': sns.xkcd_palette(['amber'])[0]}}\n",
    "suffixes = ['_Del_1', '_Del_2']\n",
    "\n",
    "for meas in analysis.keys():\n",
    "    df = compute_prepost_coherence_stimmodal(meas)\n",
    "    \n",
    "    for scale_id in df['Scale_ID'].unique():\n",
    "        for conn_id in df['Conn_ID'].unique():\n",
    "            \n",
    "            df_A = df[(df['Conn_ID'] == conn_id) &\n",
    "                      (df['Scale_ID'] == scale_id)]\n",
    "\n",
    "            df_A = df_A.groupby(['Subject_ID', 'Stim_Loc', 'Coherence_ID']).mean().reset_index()    \n",
    "            df_A = df_A.dropna()\n",
    "\n",
    "            for suffix in suffixes:\n",
    "                meas_full = meas + suffix   \n",
    "\n",
    "                df_AA = {'Coherence_ID': [],\n",
    "                        meas_full + '_rv': [],\n",
    "                        meas_full + '_pv': []}\n",
    "                for c_id in meta_dict['coherence_info']:\n",
    "                    rv, pv = stats.spearmanr(df_A[df_A['Coherence_ID'] == c_id]['Stim_Modal'],\n",
    "                                             df_A[df_A['Coherence_ID'] == c_id][meas_full])\n",
    "                    df_AA['Coherence_ID'].append(c_id)\n",
    "                    df_AA[meas_full + '_rv'].append(rv)\n",
    "                    df_AA[meas_full + '_pv'].append(pv)            \n",
    "                df_AA = pd.DataFrame(df_AA, columns=df_AA.keys())\n",
    "\n",
    "\n",
    "                # Get basic trends/stats\n",
    "                df_range_medn = df_AA.groupby('Coherence_ID').quantile(q=0.50).reset_index()\n",
    "                df_range_qnt1 = df_AA.groupby('Coherence_ID').quantile(q=0.25).reset_index()\n",
    "                df_range_qnt3 = df_AA.groupby('Coherence_ID').quantile(q=0.75).reset_index()\n",
    "\n",
    "                # Seaborn params\n",
    "                plt.figure(figsize=(4,6), dpi=300.0)\n",
    "                ax = plt.subplot(111)        \n",
    "                sns_plot_params = {'x': 'Coherence_ID',\n",
    "                                   'y': meas_full+'_rv',\n",
    "                                   'order': meta_dict['coherence_info'],\n",
    "                                   'data': df_AA,\n",
    "                                   'color': analysis[meas]['color'],\n",
    "                                   'ax': ax}\n",
    "\n",
    "                # Add a bar plot points            \n",
    "                ax = sns.barplot(**sns_plot_params)      \n",
    "                ax.hlines(0.0, -0.5, len(meta_dict['coherence_info'])+0.5, linewidth=2.0, zorder=100)        \n",
    "\n",
    "                # Prettify the plotting + add labels\n",
    "                ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "                ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "                ax.set_ylim([-1.0, 1.0])\n",
    "                ax.set_title(meas_full)\n",
    "                sns.despine(ax=ax)\n",
    "                #sns.set_context('paper')\n",
    "\n",
    "                plt.savefig('{}/Stim_Modal.{}.{}.{}.Distrib.svg'.format(path_Data['Figure'], meas_full, conn_id, scale_id))\n",
    "                #plt.show()\n",
    "                plt.close()\n",
    "\n",
    "                # Stats\n",
    "                write(':: STATS ::\\n')\n",
    "\n",
    "                df_AA = df_AA.dropna()\n",
    "                for coh_id in meta_dict['coherence_info']:\n",
    "                    rv = df_AA[df_AA['Coherence_ID'] == coh_id][meas_full + '_rv'].iloc[0]\n",
    "                    pv = df_AA[df_AA['Coherence_ID'] == coh_id][meas_full + '_pv'].iloc[0]           \n",
    "\n",
    "                    write('{} -- {} -- Conn_ID: {} -- Scale_ID: {}\\n'.format(meas_full, coh_id, conn_id, scale_id))\n",
    "                    write('    Spearman_{} :: (Stim)      --> rv={}, pv={}\\n'.format(len(df_A[df_A['Coherence_ID'] == coh_id])-2, rv, pv))\n",
    "                write('\\n\\n\\n')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Energy Landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x, y = np.mgrid[-1:1:.005, -1:1:.005]\n",
    "pos = np.empty(x.shape + (2,))\n",
    "pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "rv_1 = stats.multivariate_normal(mean=[-0.50, +0.50], cov=[0.04, 0.04])\n",
    "rv_2 = stats.multivariate_normal(mean=[+0.00, -0.50], cov=[0.25, 0.25])\n",
    "rv_3 = stats.multivariate_normal(mean=[+0.25, +0.75], cov=[0.10, 0.10])\n",
    "rv = 0.75*rv_1.pdf(pos) + 2.00*rv_2.pdf(pos) + rv_3.pdf(pos)\n",
    "rv = (rv - rv.min()) / (rv.max()-rv.min())\n",
    "\n",
    "fig = plt.figure(figsize=(3,3), dpi=300.0)\n",
    "ax = fig.gca(projection='3d')\n",
    "ss = ax.plot_surface(x, y, rv, cmap=plt.cm.YlGnBu_r, lw=0.0)\n",
    "ax.view_init(25, -40)\n",
    "ax.set_axis_off()\n",
    "plt.colorbar(ss, ax=ax)\n",
    "plt.savefig('{}/Artifical_Energy_Landscape.svg'.format(path_Data['Figure'][reref]))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "336px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "880px",
    "left": "0px",
    "right": "1707px",
    "top": "107px",
    "width": "432px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "655px",
   "left": "1562.08px",
   "right": "20px",
   "top": "129px",
   "width": "340px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
