{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev1 toc-item\"><a href=\"#Gather-all-data-sets\" data-toc-modified-id=\"Gather-all-data-sets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Gather all data sets</a></div><div class=\"lev2 toc-item\"><a href=\"#Structural-data\" data-toc-modified-id=\"Structural-data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Structural data</a></div><div class=\"lev2 toc-item\"><a href=\"#Channel-data\" data-toc-modified-id=\"Channel-data-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Channel data</a></div><div class=\"lev2 toc-item\"><a href=\"#Baseline-data\" data-toc-modified-id=\"Baseline-data-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Baseline data</a></div><div class=\"lev2 toc-item\"><a href=\"#Stim-data\" data-toc-modified-id=\"Stim-data-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Stim data</a></div><div class=\"lev2 toc-item\"><a href=\"#Memory-State-data\" data-toc-modified-id=\"Memory-State-data-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Memory State data</a></div><div class=\"lev1 toc-item\"><a href=\"#Figures-for-pipeline\" data-toc-modified-id=\"Figures-for-pipeline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Figures for pipeline</a></div><div class=\"lev2 toc-item\"><a href=\"#Project-Population-Level-Electrodes-to-Surface\" data-toc-modified-id=\"Project-Population-Level-Electrodes-to-Surface-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Project Population-Level Electrodes to Surface</a></div><div class=\"lev2 toc-item\"><a href=\"#Plot-time-series-from-baseline---&gt;-stim\" data-toc-modified-id=\"Plot-time-series-from-baseline--->-stim-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Plot time-series from baseline --&gt; stim</a></div><div class=\"lev1 toc-item\"><a href=\"#Measure-Global-Topology\" data-toc-modified-id=\"Measure-Global-Topology-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Measure Global Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Baseline-Topology\" data-toc-modified-id=\"Baseline-Topology-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Baseline Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Stim-Topology\" data-toc-modified-id=\"Stim-Topology-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Stim Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Update-Stim-Dataframe-with-Stim-Node-Z-Score\" data-toc-modified-id=\"Update-Stim-Dataframe-with-Stim-Node-Z-Score-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Update Stim Dataframe with Stim Node Z-Score</a></div><div class=\"lev2 toc-item\"><a href=\"#Global-Alterations-in-Topology\" data-toc-modified-id=\"Global-Alterations-in-Topology-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Global Alterations in Topology</a></div><div class=\"lev3 toc-item\"><a href=\"#Mean-Connection-Strength\" data-toc-modified-id=\"Mean-Connection-Strength-441\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Mean Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#Topological-Similarity\" data-toc-modified-id=\"Topological-Similarity-442\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Topological Similarity</a></div><div class=\"lev3 toc-item\"><a href=\"#Is-Reorganization-Driven-By-Shifts-in-Mean-Connectivity?\" data-toc-modified-id=\"Is-Reorganization-Driven-By-Shifts-in-Mean-Connectivity?-443\"><span class=\"toc-item-num\">4.4.3&nbsp;&nbsp;</span>Is Reorganization Driven By Shifts in Mean Connectivity?</a></div><div class=\"lev3 toc-item\"><a href=\"#Does-Pre-Stim-State-Predict-Reorganization?\" data-toc-modified-id=\"Does-Pre-Stim-State-Predict-Reorganization?-444\"><span class=\"toc-item-num\">4.4.4&nbsp;&nbsp;</span>Does Pre-Stim State Predict Reorganization?</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Input-Energy\" data-toc-modified-id=\"Effect-of-Input-Energy-45\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Effect of Input Energy</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Reorganization-of-Connectivity\" data-toc-modified-id=\"On-Reorganization-of-Connectivity-451\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>On Reorganization of Connectivity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Distance-to-Maximal-Change\" data-toc-modified-id=\"On-Distance-to-Maximal-Change-452\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>On Distance to Maximal Change</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Stimulation-Location-(Functional-Hubness)\" data-toc-modified-id=\"Effect-of-Stimulation-Location-(Functional-Hubness)-46\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Effect of Stimulation Location (Functional Hubness)</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Mean-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Mean-Change-in-Connection-Strength-461\"><span class=\"toc-item-num\">4.6.1&nbsp;&nbsp;</span>On Mean Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Variance-of-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Variance-of-Change-in-Connection-Strength-462\"><span class=\"toc-item-num\">4.6.2&nbsp;&nbsp;</span>On Variance of Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#Effect-on-Strongest-of-Changes-in-Connection-Strength\" data-toc-modified-id=\"Effect-on-Strongest-of-Changes-in-Connection-Strength-463\"><span class=\"toc-item-num\">4.6.3&nbsp;&nbsp;</span>Effect on Strongest of Changes in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity-of-Evoked-Connectivity\" data-toc-modified-id=\"On-Topological-Similarity-of-Evoked-Connectivity-464\"><span class=\"toc-item-num\">4.6.4&nbsp;&nbsp;</span>On Topological Similarity of Evoked Connectivity</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Stimulation-Location-(Functional-Region)\" data-toc-modified-id=\"Effect-of-Stimulation-Location-(Functional-Region)-47\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Effect of Stimulation Location (Functional Region)</a></div><div class=\"lev3 toc-item\"><a href=\"#Baseline-Node-Strength\" data-toc-modified-id=\"Baseline-Node-Strength-471\"><span class=\"toc-item-num\">4.7.1&nbsp;&nbsp;</span>Baseline Node Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Mean-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Mean-Change-in-Connection-Strength-472\"><span class=\"toc-item-num\">4.7.2&nbsp;&nbsp;</span>On Mean Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Variance-of-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Variance-of-Change-in-Connection-Strength-473\"><span class=\"toc-item-num\">4.7.3&nbsp;&nbsp;</span>On Variance of Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity-of-Evoked-Connectivity\" data-toc-modified-id=\"On-Topological-Similarity-of-Evoked-Connectivity-474\"><span class=\"toc-item-num\">4.7.4&nbsp;&nbsp;</span>On Topological Similarity of Evoked Connectivity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Modulated-Hubness-of-Brain-Regions\" data-toc-modified-id=\"On-Modulated-Hubness-of-Brain-Regions-475\"><span class=\"toc-item-num\">4.7.5&nbsp;&nbsp;</span>On Modulated Hubness of Brain Regions</a></div><div class=\"lev1 toc-item\"><a href=\"#Generate-Electrode-Level-Adjacency-Matrices\" data-toc-modified-id=\"Generate-Electrode-Level-Adjacency-Matrices-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Generate Electrode-Level Adjacency Matrices</a></div><div class=\"lev1 toc-item\"><a href=\"#Memory-States\" data-toc-modified-id=\"Memory-States-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Memory States</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Input-Energy\" data-toc-modified-id=\"Effect-of-Input-Energy-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Effect of Input Energy</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Stimulation-Location-(Structural-Control)\" data-toc-modified-id=\"Effect-of-Stimulation-Location-(Structural-Control)-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Effect of Stimulation Location (Structural Control)</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Network-State-on-Memory-State\" data-toc-modified-id=\"Effect-of-Network-State-on-Memory-State-63\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Effect of Network State on Memory State</a></div><div class=\"lev3 toc-item\"><a href=\"#Example-Subject\" data-toc-modified-id=\"Example-Subject-631\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Example Subject</a></div><div class=\"lev2 toc-item\"><a href=\"#Prepare-data-for-trajectory-analysis-(for-Jeni)\" data-toc-modified-id=\"Prepare-data-for-trajectory-analysis-(for-Jeni)-64\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Prepare data for trajectory analysis (for Jeni)</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "rcParams.update(rcParams)\n",
    "\n",
    "path_AtlasData = '/Users/akhambhati/Remotes/CORE.MRI_Atlases'\n",
    "path_CoreData = '/Users/akhambhati/Remotes/CORE.RAM_Stim'\n",
    "path_PeriphData = '/Users/akhambhati/Remotes/RSRCH.RAM_Stim'\n",
    "path_InpData = path_PeriphData + '/e01-FuncNetw'\n",
    "path_InpData_Baseline = path_PeriphData + '/e01b-FuncNetw'\n",
    "path_ExpData = path_PeriphData + '/e02-GlobalTopo'\n",
    "path_Figures = './e02-Figures'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData, path_Figures]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather all data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('{}/structural_dict.pkl'.format(path_ExpData)):\n",
    "    struct_dict = pkl.load(open('{}/structural_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    stradj_subj = glob.glob('{}/Adjacency_Matrices/Epilepsy_Subjects/lausanne/*'.format(path_CoreData))\n",
    "    struct_subj = glob.glob('{}/Controllability/Parcel_ROI/Epilepsy_Subjects/lausanne/*'.format(path_CoreData))\n",
    "    struct_dict = {'Subject': {},\n",
    "                   'Atlas': {'scale33': {},\n",
    "                             'scale60': {},\n",
    "                             'scale125': {},\n",
    "                             'scale250': {}}}\n",
    "\n",
    "    for scale in struct_dict['Atlas'].keys():\n",
    "\n",
    "        # Populate controllabiliy\n",
    "        for sadj_path, full_path in zip(stradj_subj, struct_subj):\n",
    "            subj_id = full_path.split('/')[-1]\n",
    "            try:\n",
    "                struct_dict['Subject'][subj_id]\n",
    "            except:\n",
    "                struct_dict['Subject'][subj_id] = {}\n",
    "            struct_dict['Subject'][subj_id][scale] = {}        \n",
    "\n",
    "            adj_gfa_path = glob.glob('{}/*ROIv_{}*{}*.mat'.format(sadj_path, scale, 'gfa'))[0]\n",
    "            adj_gfa = io.loadmat(adj_gfa_path)['connectivity']\n",
    "            ctl_gfa_path = glob.glob('{}/*{}*{}*.mat'.format(full_path, scale, 'gfa'))[0]\n",
    "            avg_ctl_gfa = io.loadmat(ctl_gfa_path)['avg_vector'][:, 0]\n",
    "            mod_ctl_gfa = io.loadmat(ctl_gfa_path)['modal_vector'][:, 0]            \n",
    "\n",
    "            adj_qa_path = glob.glob('{}/*ROIv_{}*{}*.mat'.format(sadj_path, scale, 'qa'))[0]            \n",
    "            adj_qa = io.loadmat(adj_qa_path)['connectivity']            \n",
    "            ctl_qa_path = glob.glob('{}/*{}*{}*.mat'.format(full_path, scale, 'qa'))[0]\n",
    "            avg_ctl_qa = io.loadmat(ctl_qa_path)['avg_vector'][:, 0]\n",
    "            mod_ctl_qa = io.loadmat(ctl_qa_path)['modal_vector'][:, 0]  \n",
    "\n",
    "            # Populate the subject dict\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA'] = {}\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA']['adj'] = adj_gfa\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA']['avg_ctl'] = avg_ctl_gfa\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA']['mod_ctl'] = mod_ctl_gfa        \n",
    "            struct_dict['Subject'][subj_id][scale]['QA'] = {}        \n",
    "            struct_dict['Subject'][subj_id][scale]['QA']['adj'] = adj_qa            \n",
    "            struct_dict['Subject'][subj_id][scale]['QA']['avg_ctl'] = avg_ctl_qa\n",
    "            struct_dict['Subject'][subj_id][scale]['QA']['mod_ctl'] = mod_ctl_qa        \n",
    "\n",
    "\n",
    "        # Populate MNI Coordinates for each ROI of each Lausanne Atlas\n",
    "        # Find voxel coordinates for each ROI\n",
    "        atlas_label = pd.read_csv('{}/Lausanne/{}.csv'.format(path_AtlasData, scale))    \n",
    "        atlas = nib.load('{}/Lausanne/lausanne/ROIv_{}_dilated.nii.gz'.format(path_AtlasData, scale))\n",
    "        atlas_data = atlas.get_data()\n",
    "        for roi_id in np.unique(atlas_data)[1:]:        \n",
    "            i,j,k = np.nonzero(atlas_data == roi_id)\n",
    "\n",
    "            roi_coords = []\n",
    "            for ii, jj, kk in zip(i, j, k):\n",
    "                xx, yy, zz = atlas.affine[:3, :3].dot([ii, jj, kk]) + atlas.affine[:3, 3]\n",
    "                roi_coords.append((xx, yy, zz))\n",
    "            roi_coords = np.array(roi_coords)\n",
    "\n",
    "            # Add to coords for ROI label to dict\n",
    "            sel_lbl = (atlas_label['Label_ID'] == roi_id)\n",
    "            roi_lbl = (atlas_label[sel_lbl]['Hemisphere'] + '_' + atlas_label[sel_lbl]['ROI']).as_matrix()[0]\n",
    "            struct_dict['Atlas'][scale][roi_lbl] = roi_coords\n",
    "\n",
    "    pkl.dump(struct_dict, open('{}/structural_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "print('There are {} processed structural datasets to analyze.'.format(len(struct_dict['Subject'].keys())))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('{}/channel_dict.pkl'.format(path_ExpData)):\n",
    "    channel_dict = pkl.load(open('{}/channel_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    channel_subj = glob.glob('{}/Exp_Info/Channel_Info/*.mat'.format(path_CoreData))\n",
    "    channel_dict = {'Subject': {}}\n",
    "    \"\"\"\n",
    "    contains:  \n",
    "    - Jacksheet #: int\n",
    "    - Label: (good_channels x 1)\n",
    "    - Atlas_Label: {'scale': (good_channels x 1)}    \n",
    "    - MNI_Coord: (good_channels x 3)\n",
    "    - Dist_Matrix: spatial distances between electrodes\n",
    "    \"\"\"\n",
    "    \n",
    "    for full_path in channel_subj:\n",
    "        subj_id = full_path.split('/')[-1].split('.')[0]\n",
    "        try:\n",
    "            channel_dict['Subject'][subj_id]\n",
    "        except:\n",
    "            channel_dict['Subject'][subj_id] = {}        \n",
    "        \n",
    "        ### Get channel map for subject\n",
    "        chan_file = glob.glob('{}/Exp_Info/Channel_Info/{}.mat'.format(path_CoreData, subj_id))\n",
    "        if len(chan_file) != 1:\n",
    "            continue\n",
    "        df_chan = io.loadmat(chan_file[0])\n",
    "        if df_chan['good_channels_jack'].shape[1] != df_chan['good_channels_ind'].shape[1]:\n",
    "            continue\n",
    "        if df_chan['good_channels_jack'].shape[1] != df_chan['good_channels_lbl'].shape[1]:\n",
    "            continue\n",
    "            \n",
    "        ### Reformat channel labels\n",
    "        chan_lbl = np.array([lbl[0] for lbl in df_chan['good_channels_lbl'][0, :]])\n",
    "            \n",
    "        ### MNI Coords for good channels\n",
    "        mni_coords = []\n",
    "        for gc in df_chan['good_channels_jack'][0, :]:\n",
    "            gc_ix = np.flatnonzero(df_chan['xyzcoords'][:, 0] == gc)\n",
    "            if len(gc_ix) > 0:\n",
    "                mni_coords.append(tuple(df_chan['xyzcoords'][gc_ix[0], 1:]))\n",
    "            else:\n",
    "                mni_coords.append(tuple([np.nan, np.nan, np.nan]))\n",
    "                if gc_ix < len(df_chan['xyzcoords'][:, 0])-10:\n",
    "                    print(subj_id + ' -- middle bad channel')\n",
    "        mni_coords = np.array(mni_coords)\n",
    "        \n",
    "        ### Compute Inter-Electrode Distances\n",
    "        n_node = df_chan['good_channels_jack'].shape[1]\n",
    "        dist_matr = np.zeros((n_node, n_node))\n",
    "        triu_ix, triu_iy = np.triu_indices(n_node, k=1)\n",
    "        for ix, iy in zip(triu_ix, triu_iy):\n",
    "            ix_chan_loc = mni_coords[ix, :]\n",
    "            iy_chan_loc = mni_coords[iy, :]            \n",
    "            dist_matr[ix, iy] = np.sqrt(np.sum((ix_chan_loc-iy_chan_loc)**2))            \n",
    "        dist_matr += dist_matr.T\n",
    "        \n",
    "        ### Assign channel to an ROI using greedy approach\n",
    "        atlas_label = {}\n",
    "        for scale in struct_dict['Atlas'].keys():\n",
    "            roi_names = struct_dict['Atlas'][scale].keys()\n",
    "            chan_assign = []\n",
    "            for ch_crd in mni_coords:\n",
    "                roi_voxel_dist = []\n",
    "                for roi in roi_names:\n",
    "                    roi_crd = struct_dict['Atlas'][scale][roi]\n",
    "                    nearest_voxel = np.min(np.sqrt(np.sum((ch_crd - roi_crd)**2, axis=1)))\n",
    "                    roi_voxel_dist.append(nearest_voxel)\n",
    "                roi_ix = np.argmin(roi_voxel_dist)\n",
    "                chan_assign.append(roi_names[roi_ix])\n",
    "            atlas_label[scale] = np.array(chan_assign)\n",
    "\n",
    "        \n",
    "        ### Populate dict\n",
    "        channel_dict['Subject'][subj_id]['Jacksheet'] = df_chan['good_channels_jack'][0, :]\n",
    "        channel_dict['Subject'][subj_id]['Channel_Label'] = chan_lbl     \n",
    "        channel_dict['Subject'][subj_id]['Atlas_Label'] = atlas_label\n",
    "        channel_dict['Subject'][subj_id]['MNI_Coord'] = mni_coords\n",
    "        channel_dict['Subject'][subj_id]['Dist_Matr'] = dist_matr\n",
    "        \n",
    "    pkl.dump(channel_dict, open('{}/channel_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "print('There are {} processed channel datasets to analyze.'.format(len(channel_dict['Subject'].keys())))                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/base_dict.pkl'.format(path_ExpData)):\n",
    "    base_dict = pkl.load(open('{}/base_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    base_list = glob.glob('{}/Adjacency.*.npz'.format(path_InpData_Baseline))\n",
    "    all_subj_id = np.unique([pth.split('/')[-1].split('.')[1] for pth in base_list])\n",
    "\n",
    "    base_dict = {'Subject_ID': [],\n",
    "                 'Base_ID': [],\n",
    "                 'Adj_Path': []}\n",
    "\n",
    "\n",
    "    for subj_id in all_subj_id:\n",
    "        print(subj_id)\n",
    "\n",
    "        ### Iterate over all baseline events for the subject\n",
    "        for pth in glob.glob('{}/Adjacency.{}.*.npz'.format(path_InpData_Baseline, subj_id)):    \n",
    "            full_file = pth.split('/')[-1]    \n",
    "            subj_id = full_file.split('.')[1]\n",
    "            base_id = int(full_file.split('.')[2].split('_')[-1])\n",
    "\n",
    "            ### Populate the dictionary\n",
    "            base_dict['Subject_ID'].append(subj_id)\n",
    "            base_dict['Base_ID'].append(base_id)    \n",
    "            base_dict['Adj_Path'].append(pth)\n",
    "\n",
    "    pkl.dump(base_dict, open('{}/base_dict.pkl'.format(path_ExpData), 'w')) \n",
    "\n",
    "df_base = pd.DataFrame(base_dict, columns=base_dict.keys())    \n",
    "print('There are {} processed baseline events to analyze.'.format(len(base_dict['Subject_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/stim_trial_dict.pkl'.format(path_ExpData)):\n",
    "    trial_dict = pkl.load(open('{}/stim_trial_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    trial_list = glob.glob('{}/Adjacency.*.npz'.format(path_InpData))\n",
    "    all_subj_id = np.unique([pth.split('/')[-1].split('.')[1] for pth in trial_list])\n",
    "\n",
    "    trial_dict = {'Subject_ID': [],\n",
    "                  'Experiment_ID': [],\n",
    "                  'Trial_ID': [],\n",
    "                  'Event_ID': [],\n",
    "                  'Stim_Freq': [],\n",
    "                  'Stim_Amp': [],\n",
    "                  'Stim_Anode': [],\n",
    "                  'Stim_Cathode': [],           \n",
    "                  'Adj_Path': []}\n",
    "\n",
    "    for subj_id in all_subj_id:\n",
    "        print(subj_id)\n",
    "\n",
    "        ### Get Trial LUT for Subject\n",
    "        trial_lut_file = glob.glob('{}/Exp_Info/LUT_Trial_Events/{}_trial_lut.mat'.format(path_CoreData, subj_id))\n",
    "        if len(trial_lut_file) != 1:\n",
    "            continue\n",
    "        df_lut = h5py.File(trial_lut_file[0], 'r')\n",
    "\n",
    "        ### Get event table for subject\n",
    "        event_file = glob.glob('{}/Exp_Info/PS_Events/{}_events.mat'.format(path_CoreData, subj_id))\n",
    "        if len(event_file) != 1:\n",
    "            continue\n",
    "        df_event = io.loadmat(event_file[0])\n",
    "\n",
    "        ### Iterate over all trials for the subject\n",
    "        for pth in glob.glob('{}/Adjacency.{}.*.npz'.format(path_InpData, subj_id)):    \n",
    "            full_file = pth.split('/')[-1]    \n",
    "            subj_id = full_file.split('.')[1]\n",
    "            trial_id = int(full_file.split('.')[2].split('_')[-1])\n",
    "\n",
    "            ### Convert the Trial ID to Event ID\n",
    "            event_id = df_lut['trial_lut'][1, :][df_lut['trial_lut'][0, :] == trial_id]\n",
    "            if len(event_id) != 1:\n",
    "                continue\n",
    "            event_id = int(event_id[0] - 1)\n",
    "\n",
    "            ### Get Trial Parameters\n",
    "            sel_event = df_event['events'][0, event_id]\n",
    "            stim_type = sel_event['type'][0].lower()\n",
    "            if not (stim_type =='stimulating'):\n",
    "                continue        \n",
    "\n",
    "            stim_exp = sel_event['experiment'][0]        \n",
    "            stim_amp = sel_event['amplitude'][0, 0]\n",
    "            stim_freq = sel_event['pulse_frequency'][0, 0]\n",
    "\n",
    "            stim_anode_jack = df_event['events'][0, event_id]['stimAnode'][0, 0]\n",
    "            stim_cathode_jack = df_event['events'][0, event_id]['stimCathode'][0, 0]\n",
    "\n",
    "            ### Populate the dictionary\n",
    "            trial_dict['Subject_ID'].append(subj_id)\n",
    "            trial_dict['Experiment_ID'].append(stim_exp)        \n",
    "            trial_dict['Trial_ID'].append(trial_id)    \n",
    "            trial_dict['Event_ID'].append(event_id)\n",
    "            trial_dict['Stim_Freq'].append(stim_freq)\n",
    "            trial_dict['Stim_Amp'].append(stim_amp)    \n",
    "            trial_dict['Stim_Anode'].append(stim_anode_jack)\n",
    "            trial_dict['Stim_Cathode'].append(stim_cathode_jack)\n",
    "            trial_dict['Adj_Path'].append(pth)\n",
    "        df_lut.close()\n",
    "    \n",
    "    pkl.dump(trial_dict, open('{}/stim_trial_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "df_trial = pd.DataFrame(trial_dict, columns=trial_dict.keys())    \n",
    "print('There are {} processed trials to analyze.'.format(len(trial_dict['Subject_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/memory_trial_dict.pkl'.format(path_ExpData)):\n",
    "    memory_dict = pkl.load(open('{}/memory_trial_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    memory_list = glob.glob('{}/Memory_States/Memory_States/*.*.memory_states.mat'.format(path_CoreData))\n",
    "\n",
    "    memory_dict = {'Subject_ID': [],\n",
    "                   'Event_ID': [],\n",
    "                   'Experiment_ID': [],\n",
    "                   'Pre_Stim_Prob': [],\n",
    "                   'Post_Stim_Prob': [],                   \n",
    "                   'Stim_Freq': [],\n",
    "                   'Stim_Amp': [],\n",
    "                   'Stim_Duration': [],\n",
    "                   'Stim_Anode': [],\n",
    "                   'Stim_Cathode': []}\n",
    "\n",
    "    for pth in memory_list:\n",
    "        subj_id = pth.split('/')[-1].split('.')[0]\n",
    "        expr_id = pth.split('/')[-1].split('.')[1]\n",
    "\n",
    "        ### Get event table for subject\n",
    "        stim_event_file = glob.glob('{}/Exp_Info/PS_Events/{}_events.mat'.format(path_CoreData, subj_id))\n",
    "        try:\n",
    "            df_stim_event = io.loadmat(stim_event_file[0])\n",
    "            event_ids = []\n",
    "            for ii in xrange(len(df_stim_event['events'][0, :])):\n",
    "                if (df_stim_event['events'][0, ii]['experiment'] == 'PS2') & \\\n",
    "                   (df_stim_event['events'][0, ii]['type'] == 'STIMULATING'):\n",
    "                    event_ids.append(ii)\n",
    "        except:\n",
    "            event_ids = []\n",
    "        n_stim_event = len(event_ids)\n",
    "        \n",
    "        ### Get memory state table for subject\n",
    "        df_mem_event = io.loadmat(pth)\n",
    "        n_mem_event = df_mem_event['stim_freq'].shape[1]\n",
    "        \n",
    "        ### Sanity check\n",
    "        print(subj_id, expr_id, n_stim_event, n_mem_event, n_mem_event == n_stim_event)\n",
    "\n",
    "        ### Iterate over all trials for the subject\n",
    "        for ix in xrange(n_mem_event):\n",
    "            \n",
    "            ### Populate the dictionary\n",
    "            memory_dict['Subject_ID'].append(subj_id)\n",
    "            try:\n",
    "                memory_dict['Event_ID'].append(event_ids[ix])\n",
    "            except:\n",
    "                memory_dict['Event_ID'].append(np.nan)\n",
    "            memory_dict['Experiment_ID'].append(expr_id) \n",
    "            memory_dict['Pre_Stim_Prob'].append(df_mem_event['pre_stim_mem_prob'][0, ix])\n",
    "            memory_dict['Post_Stim_Prob'].append(df_mem_event['post_stim_mem_prob'][0, ix])            \n",
    "            memory_dict['Stim_Freq'].append(df_mem_event['stim_freq'][0, ix])\n",
    "            memory_dict['Stim_Amp'].append(df_mem_event['stim_amp'][0, ix]) \n",
    "            memory_dict['Stim_Duration'].append(df_mem_event['stim_duration'][0, ix])  \n",
    "            memory_dict['Stim_Anode'].append(df_mem_event['stim_anode_jack'][0, ix])\n",
    "            memory_dict['Stim_Cathode'].append(df_mem_event['stim_cathode_jack'][0, ix])\n",
    "\n",
    "    pkl.dump(memory_dict, open('{}/memory_trial_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "df_memory = pd.DataFrame(memory_dict, columns=memory_dict.keys())    \n",
    "print('There are {} processed trials to analyze.'.format(len(memory_dict['Subject_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Population-Level Electrodes to Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('{}/subject_electrode_pixmap.pkl'.format(path_ExpData)):\n",
    "    electrode_pixmap = pkl.load(open('{}/subject_electrode_pixmap.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "\n",
    "    from Echobase.Plotting import render_brain_connectivity\n",
    "\n",
    "    ### Collect surface data\n",
    "    # Vertices and triangles\n",
    "    verts_rh, trias_rh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/rh.pial'.format(path_AtlasData))\n",
    "    verts_lh, trias_lh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/lh.pial'.format(path_AtlasData))\n",
    "\n",
    "    n_rh_verts = verts_rh.shape[0]\n",
    "    n_lh_verts = verts_lh.shape[0]\n",
    "\n",
    "    verts = np.vstack((verts_rh, verts_lh))\n",
    "    trias = np.vstack((trias_rh, trias_lh+n_rh_verts))\n",
    "\n",
    "    label_scalars = 20*np.zeros(n_rh_verts+n_lh_verts)\n",
    "\n",
    "    view_angle = {'Axial_LR': [0.0, 0.0],\n",
    "                  'Axial_RL': [0.0, 180.0],\n",
    "                  'Sag_PA': [0.0, 90.0],\n",
    "                  'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "    # Get all the electrodes\n",
    "    electrode_pixmap = {}\n",
    "    for subj_id in np.unique(df_trial['Subject_ID']):\n",
    "        print(subj_id)\n",
    "\n",
    "        node_coord = []\n",
    "        node_rgba = []\n",
    "        node_size = []\n",
    "\n",
    "        if len(channel_dict['Subject'][subj_id].keys()) == 0:\n",
    "            continue\n",
    "\n",
    "        subj_stim_anode = np.unique(df_trial[df_trial['Subject_ID'] == subj_id]['Stim_Anode'])\n",
    "        subj_stim_cathode = np.unique(df_trial[df_trial['Subject_ID'] == subj_id]['Stim_Cathode'])\n",
    "\n",
    "        if (len(subj_stim_anode) == 0) or (len(subj_stim_cathode) == 0):\n",
    "            continue\n",
    "\n",
    "        for jack_ii, jack in enumerate(channel_dict['Subject'][subj_id]['Jacksheet']):\n",
    "            node_coord.append(channel_dict['Subject'][subj_id]['MNI_Coord'][jack_ii, :])\n",
    "            if (jack in subj_stim_anode) or (jack in subj_stim_cathode):\n",
    "                node_rgba.append([1.0, 0.0, 0.0, 1.0])\n",
    "            else:\n",
    "                node_rgba.append([0.0, 0.0, 1.0, 1.0])\n",
    "            node_size.append(2.0)\n",
    "\n",
    "        node_coord = np.array(node_coord)\n",
    "        node_rgba = np.array(node_rgba)\n",
    "        node_size = np.array(node_size)\n",
    "\n",
    "        render_brain_connectivity.mlab.close(all=True)    \n",
    "        engine = render_brain_connectivity.draw(verts, trias, label_scalars, 'Greys', 196.0,\n",
    "                                                node_coords=node_coord, node_sizes=node_size, node_colors=node_rgba,\n",
    "                                                conn_list=None, conn_pct=None, conn_cmap=None)\n",
    "        pixmap = {}\n",
    "        for ang in view_angle.keys():\n",
    "            render_brain_connectivity.mlab.view(azimuth=view_angle[ang][0],\n",
    "                                                elevation=view_angle[ang][1])\n",
    "            pixmap['{}'.format(ang)] = render_brain_connectivity.mlab.screenshot(mode='rgba')\n",
    "        electrode_pixmap[subj_id] = pixmap\n",
    "\n",
    "        render_brain_connectivity.mlab.close(all=True)\n",
    "    pkl.dump(electrode_pixmap, open('{}/subject_electrode_pixmap.pkl'.format(path_ExpData), 'w'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "for subj_id in electrode_pixmap.keys():\n",
    "    plt.figure(figsize=(3,3), dpi=300)\n",
    "    for view_ii, view in enumerate(['Sag_AP', 'Sag_PA']):\n",
    "        ax = plt.subplot(1,2,view_ii+1)\n",
    "        ax.imshow(electrode_pixmap[subj_id][view])\n",
    "        ax.set_axis_off()\n",
    "    plt.suptitle(subj_id)\n",
    "    plt.savefig('{}/{}.electrode_pixmap.svg'.format(path_Figures, subj_id), dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot time-series from baseline --> stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_id = 'R1050M'\n",
    "sel_trial = df_trial[(df_trial['Subject_ID'] == subj_id) &\n",
    "                     (df_trial['Experiment_ID'] != 'PS1')]\n",
    "\n",
    "\"\"\"\n",
    "### Retrieve baseline clips\n",
    "for ii in xrange(10):\n",
    "    baseline_path = '{}/Baseline_Trials/{}.Baseline_{}.mat'.format(path_CoreData, subj_id, ii+1)\n",
    "    df = h5py.File(baseline_path, 'r')\n",
    "    if ii == 0:\n",
    "        evData = df['evData'][...]\n",
    "    else:\n",
    "        evData = np.vstack((evData, df['evData'][...]))\n",
    "df.close()\n",
    "\"\"\"\n",
    "\n",
    "### Retrieve First stim trial\n",
    "trial_id = sel_trial.iloc[np.random.permutation(sel_trial.shape[0])[0]]['Trial_ID']\n",
    "trial_path = glob.glob('{}/Stim_Trials/{}.*.Trial_{}.mat'.format(path_CoreData, subj_id, trial_id))[0]\n",
    "df = h5py.File(trial_path, 'r')\n",
    "#evData = np.vstack((evData, df['evData'][...]))\n",
    "evData = df['evData'][0:-1, :]\n",
    "samp_freq = int(np.ceil(df['samp_freq'][0, 0]))\n",
    "df.close()\n",
    "\n",
    "### Filter params\n",
    "wpass = [58.0, 62.0]\n",
    "wstop = [59.0, 61.0]\n",
    "gpass = 0.1\n",
    "gstop = 60.0\n",
    "evData = Echobase.Sigproc.filters.elliptic(evData, samp_freq,\n",
    "                                           wpass, wstop, gpass, gstop)\n",
    "### Generate the plot\n",
    "evData_norm = (evData - evData.mean(axis=0)) / (6*evData.std(axis=0))\n",
    "evData_norm = evData_norm[samp_freq/2:, :]\n",
    "n_samp, n_chan = evData_norm.shape\n",
    "sel_chan = np.random.randint(0, n_chan, size=(9))\n",
    "\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(np.arange(len(sel_chan))+evData_norm[:, sel_chan], lw=0.2, color='k')\n",
    "ax.fill_between([0, samp_freq/2], -1, len(sel_chan),\n",
    "                color=[0.1, 0.1, 1.0], alpha=0.1, lw=0)\n",
    "ax.fill_between([samp_freq/2, samp_freq], -1, len(sel_chan),\n",
    "                color=[1.0, 0.1, 0.1], alpha=0.1, lw=0)\n",
    "ax.fill_between([3/2*samp_freq, n_samp], -1, len(sel_chan),\n",
    "                color=[0.1, 0.1, 1.0], alpha=0.1, lw=0)\n",
    "\n",
    "ax.set_xticklabels(np.linspace(0, n_samp/samp_freq, 6))\n",
    "\n",
    "ax.vlines(samp_freq/2, -1, len(sel_chan), color=[1.0, 0.1, 0.1])\n",
    "ax.vlines(samp_freq, -1, len(sel_chan), color=[1.0, 0.1, 0.1])\n",
    "\n",
    "ax.set_ylim([-1, len(sel_chan)])\n",
    "ax.set_xlim([0, n_samp+1])\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Global Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/baseline_topology.pkl'.format(path_ExpData)):\n",
    "    df_base_topo = pd.read_pickle('{}/baseline_topology.pkl'.format(path_ExpData))\n",
    "else:\n",
    "    data_table = {'Subject_ID': [],\n",
    "                  'Coherence_ID': [],\n",
    "                  'Base_Delta_Cor': [],\n",
    "                  'Base_ZNodeStr': []}\n",
    "    coherence_id = ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']\n",
    "\n",
    "    for subj_id in np.unique(df_base['Subject_ID']):\n",
    "        sel_subj = df_base[df_base['Subject_ID'] == subj_id]\n",
    "\n",
    "        for coh_id in coherence_id:\n",
    "            cfg_vec = []       \n",
    "            ns = []\n",
    "\n",
    "            for base_ix, base_data in sel_subj.iterrows():\n",
    "                # Load Adjacency\n",
    "                df_adj = np.load(base_data['Adj_Path'])\n",
    "                adj = df_adj['adj'].item()   \n",
    "                df_adj.close()\n",
    "\n",
    "                # Grab adjacency matrices\n",
    "                adj_coh = adj['No_Stim'][coh_id]\n",
    "\n",
    "                # Compute node strength\n",
    "                ns.append(np.mean(adj_coh, axis=0))\n",
    "\n",
    "                # Get configuration vector\n",
    "                cfg_coh = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_coh, axis=0)).reshape(-1)\n",
    "\n",
    "                cfg_vec.append(cfg_coh)\n",
    "\n",
    "            # Average the node strengths across baseline events\n",
    "            ns = np.mean(np.array(ns), axis=0)\n",
    "\n",
    "            # Compute Z-Scored node strengths\n",
    "            zns = (ns - np.nanmean(ns)) / np.nanstd(ns)   \n",
    "\n",
    "            # Compute correlations between configurations of different baseline time points\n",
    "            cfg_vec = np.array(cfg_vec)\n",
    "\n",
    "            delta_cor = convert_adj_matr_to_cfg_matr(np.expand_dims(np.corrcoef(cfg_vec), axis=0)).mean()\n",
    "\n",
    "            # Add to Data Table\n",
    "            data_table['Subject_ID'].append(subj_id)\n",
    "            data_table['Coherence_ID'].append(coh_id)            \n",
    "\n",
    "            data_table['Base_Delta_Cor'].append(delta_cor)\n",
    "            data_table['Base_ZNodeStr'].append(zns)\n",
    "\n",
    "    # Save Data Tables for R-stats\n",
    "    df_base_topo = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    df_base_topo.to_pickle('{}/baseline_topology.pkl'.format(path_ExpData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/stim_topology.pkl'.format(path_ExpData)) :\n",
    "    df_stim_topo = pd.read_pickle('{}/stim_topology.pkl'.format(path_ExpData))\n",
    "else:\n",
    "    data_table = {'Subject_ID': [],\n",
    "                  'Experiment_ID': [],\n",
    "                  'Event_ID': [],\n",
    "                  'Trial_ID': [],\n",
    "                  'Coherence_ID': [],\n",
    "                  'Stim_Freq': [],\n",
    "                  'Stim_Amp': [],\n",
    "                  'Stim_Anode': [],\n",
    "                  'Stim_Cathode': [],\n",
    "\n",
    "                  'Delta_KSTest_dv': [],\n",
    "                  'Delta_KSTest_pv': [],\n",
    "                                    \n",
    "                  'Pre_MeanConnStr': [],\n",
    "                  'Post_MeanConnStr': [],\n",
    "                  'Delta_MeanConnStr': [],\n",
    "                  \n",
    "                  'Pre_VarConnStr': [],\n",
    "                  'Post_VarConnStr': [],\n",
    "                  'Delta_VarConnStr': [],\n",
    "\n",
    "                  'Delta_Cor': [],\n",
    "\n",
    "                  'Pre_NodeStr': [],\n",
    "                  'Post_NodeStr': [],\n",
    "                  'Delta_NodeStr': []}\n",
    "    coherence_id = ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']                  \n",
    "\n",
    "    for subj_id in np.unique(df_trial['Subject_ID']):\n",
    "        sel_subj = df_trial[df_trial['Subject_ID'] == subj_id]\n",
    "\n",
    "        for trial_ix, trial_data in sel_subj.iterrows():\n",
    "            if (trial_ix % 1000) == 0:\n",
    "                print(trial_ix)\n",
    "            \n",
    "            # Load Adjacency\n",
    "            df_adj = np.load(trial_data['Adj_Path'])\n",
    "            adj = df_adj['adj'].item()   \n",
    "            df_adj.close()\n",
    "\n",
    "            for coh_id in coherence_id:\n",
    "                # Grab adjacency matrices\n",
    "                adj_pre_coh = adj['Pre_Stim'][coh_id]\n",
    "                adj_post_coh = adj['Post_Stim'][coh_id]\n",
    "                adj_delta_coh = (adj_post_coh - adj_pre_coh)\n",
    "                adj_delta_coh[np.isnan(adj_delta_coh)] = 0\n",
    "\n",
    "                # Compute Pre/Post/Delta Configuration vectors\n",
    "                cfg_pre_coh = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre_coh, axis=0)).reshape(-1)\n",
    "                cfg_post_coh = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post_coh, axis=0)).reshape(-1)\n",
    "                cfg_delta_coh = (cfg_post_coh - cfg_pre_coh)\n",
    "                cfg_delta_coh[np.isnan(cfg_delta_coh)] = 0\n",
    "\n",
    "                # Compare the Pre/Post Configuration vector distributions\n",
    "                delta_ks_dv, delta_ks_pv = stats.ks_2samp(cfg_pre_coh, cfg_post_coh)\n",
    "                \n",
    "                # Compute pre/post/delta connection stats (mean / variance / Pearson)\n",
    "                pre_mcs_coh = np.mean(cfg_pre_coh)\n",
    "                post_mcs_coh = np.mean(cfg_post_coh)\n",
    "                delta_mcs_coh = np.mean(cfg_delta_coh)\n",
    "                \n",
    "                pre_vcs_coh = np.var(cfg_pre_coh)\n",
    "                post_vcs_coh = np.var(cfg_post_coh)\n",
    "                delta_vcs_coh = np.var(cfg_delta_coh)\n",
    "\n",
    "                delta_cor_coh = stats.pearsonr(cfg_pre_coh, cfg_post_coh)[0]\n",
    "\n",
    "                # Change in node strength (Post - Pre)\n",
    "                pre_ns_coh = np.mean(adj_pre_coh, axis=0)\n",
    "                post_ns_coh = np.mean(adj_post_coh, axis=0)\n",
    "                delta_ns_coh = np.mean(adj_delta_coh, axis=0)\n",
    "                                \n",
    "                # Add to Data Table 1\n",
    "                data_table['Subject_ID'].append(trial_data['Subject_ID'])\n",
    "                data_table['Experiment_ID'].append(trial_data['Experiment_ID'])                 \n",
    "                data_table['Event_ID'].append(trial_data['Event_ID'])                \n",
    "                data_table['Trial_ID'].append(trial_data['Trial_ID'])\n",
    "                data_table['Coherence_ID'].append(coh_id)                \n",
    "                data_table['Stim_Freq'].append(trial_data['Stim_Freq'])\n",
    "                data_table['Stim_Amp'].append(trial_data['Stim_Amp'])\n",
    "                data_table['Stim_Anode'].append(trial_data['Stim_Anode'])\n",
    "                data_table['Stim_Cathode'].append(trial_data['Stim_Cathode'])\n",
    "\n",
    "                data_table['Delta_KSTest_dv'].append(delta_ks_dv)\n",
    "                data_table['Delta_KSTest_pv'].append(delta_ks_pv)\n",
    "                \n",
    "                data_table['Pre_MeanConnStr'].append(pre_mcs_coh)\n",
    "                data_table['Post_MeanConnStr'].append(post_mcs_coh)\n",
    "                data_table['Delta_MeanConnStr'].append(delta_mcs_coh)\n",
    "                \n",
    "                data_table['Pre_VarConnStr'].append(pre_vcs_coh)\n",
    "                data_table['Post_VarConnStr'].append(post_vcs_coh)\n",
    "                data_table['Delta_VarConnStr'].append(delta_vcs_coh)\n",
    "\n",
    "                data_table['Delta_Cor'].append(delta_cor_coh)\n",
    "\n",
    "                data_table['Pre_NodeStr'].append(pre_ns_coh)\n",
    "                data_table['Post_NodeStr'].append(post_ns_coh)\n",
    "                data_table['Delta_NodeStr'].append(delta_ns_coh)\n",
    "        \n",
    "    # Save Data Tables for R-stats\n",
    "    df_stim_topo = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    df_stim_topo.to_pickle('{}/stim_topology.pkl'.format(path_ExpData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Stim Dataframe with Stim Node Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stim_topo['Stim_Anode_Base_ZNodeStr'] = np.nan\n",
    "df_stim_topo['Stim_Cathode_Base_ZNodeStr'] = np.nan\n",
    "\n",
    "\n",
    "for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                              df_stim_topo['Subject_ID']):\n",
    "    for coh_id in np.intersect1d(df_base_topo['Coherence_ID'],\n",
    "                                 df_stim_topo['Coherence_ID']):\n",
    "    \n",
    "        # Get the Baseline Node Strength Z-Scores\n",
    "        sel_subj_base = df_base_topo.loc[(df_base_topo.Subject_ID == subj_id) &\n",
    "                                         (df_base_topo.Coherence_ID == coh_id)]\n",
    "        base_zns = sel_subj_base['Base_ZNodeStr'].mean()\n",
    "\n",
    "        \n",
    "        # Get the stim anode or cathode\n",
    "        sel_subj_stim = df_stim_topo.loc[(df_stim_topo.Subject_ID == subj_id) &\n",
    "                                         (df_stim_topo.Coherence_ID == coh_id)]\n",
    "        \n",
    "        for stim_pol in ['Stim_Anode', 'Stim_Cathode']:\n",
    "            for stim_jack in np.unique(sel_subj_stim[stim_pol]):\n",
    "                stim_chan_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_jack)[0]\n",
    "                base_stim_zns = base_zns[stim_chan_ix]\n",
    "                \n",
    "                # Append to the df_stim_topo dataframe\n",
    "                df_stim_topo.loc[(df_stim_topo.Subject_ID == subj_id) &\n",
    "                                 (df_stim_topo.Coherence_ID == coh_id), stim_pol+'_Base_ZNodeStr'] = base_stim_zns\n",
    "                \n",
    "df_stim_topo['Stim_Base_ZNodeStr'] = (df_stim_topo['Stim_Anode_Base_ZNodeStr'] + \n",
    "                                      df_stim_topo['Stim_Cathode_Base_ZNodeStr']) / 2.0\n",
    "df_stim_topo_nn = df_stim_topo.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Alterations in Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stim_topo = df_stim_topo[df_stim_topo['Experiment_ID'] != 'PS1']\n",
    "\n",
    "sel_base_topo = df_base_topo.groupby(['Subject_ID', 'Coherence_ID']).mean().reset_index()\n",
    "sel_stim_topo = df_stim_topo.groupby(['Subject_ID', 'Coherence_ID']).mean().reset_index()\n",
    "\n",
    "subject_id = np.unique(df_stim_topo['Subject_ID'])\n",
    "coherence_id = ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']\n",
    "common_subject_id = np.intersect1d(df_base_topo['Subject_ID'], df_stim_topo['Subject_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Connection Strength\n",
    "The average node strength before stimulation predicts the average node strength after. There is a \"conservation of connectivity\" for Alpha/Theta, Beta, Low Gamma and High Gamma coherence networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_coh = sel_stim_topo[sel_stim_topo['Coherence_ID'] == coh_id]\n",
    "    \n",
    "    # Plot Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(sel_coh['Pre_MeanConnStr'],\n",
    "                                                    sel_coh['Post_MeanConnStr'])\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    ax.plot([0.0, 1.0], slope*np.array([0.0, 1.0])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(sel_coh['Pre_MeanConnStr'],\n",
    "               sel_coh['Post_MeanConnStr'],\n",
    "               s=2.0, color=[0.5, 0.5, 0.5], lw=0)\n",
    "    ax.text(0.5, 0.75, ' slope=%0.3f\\n rho=%0.3f\\n pv=%0.3f' % (slope, rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Post-Stim\\nMean Conn Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Pre-Stim\\nMean Conn Strength')      \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Pre_MeanConnStrength-Post_MeanConnStrength.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topological Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_base_coh = sel_base_topo[sel_base_topo['Coherence_ID'] == coh_id]\n",
    "    sel_stim_coh = sel_stim_topo[sel_stim_topo['Coherence_ID'] == coh_id]    \n",
    "    \n",
    "    subj_base_cor = []\n",
    "    subj_stim_cor = []\n",
    "    for subj_id in np.intersect1d(sel_base_coh['Subject_ID'], sel_stim_coh['Subject_ID']):\n",
    "        sel_base_subj = sel_base_coh[sel_base_coh['Subject_ID'] == subj_id]        \n",
    "        sel_stim_subj = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "\n",
    "        # Get Data\n",
    "        base_cor = 1-np.abs(sel_base_subj['Base_Delta_Cor'])\n",
    "        stim_cor = 1-np.abs(sel_stim_subj['Delta_Cor'])\n",
    "        \n",
    "        # Add to subject level data\n",
    "        subj_base_cor.append(base_cor.mean())\n",
    "        subj_stim_cor.append(stim_cor.mean())        \n",
    "\n",
    "    bp1 = ax.boxplot([subj_stim_cor], positions=[ii], patch_artist=True)\n",
    "    Echobase.Plotting.fig_format.set_box_color(bp1, 'k', [[0.00, 0.37, 1.00]])\n",
    "    \n",
    "    bp2 = ax.boxplot([subj_base_cor], positions=[ii+0.2], patch_artist=True)\n",
    "    Echobase.Plotting.fig_format.set_box_color(bp2, 'k', [[0.25, 0.25, 0.25]])\n",
    "    \n",
    "    print(stats.ttest_rel(subj_base_cor, subj_stim_cor))\n",
    "\n",
    "ax.set_xlim([-0.5, 4])\n",
    "ax.set_xticks(np.arange(len(coherence_id))+0.1)\n",
    "ax.set_xticklabels(coherence_id)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_ylim([-0.1, 1.1])\n",
    "ax.set_ylabel('Reorganization of Network Topology')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('./e02-Figures/Topological_Similarity-Pre_Post.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is Reorganization Driven By Shifts in Mean Connectivity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    # Get Trial Data\n",
    "    delta_conn_trial = np.abs(sel_stim_coh['Delta_MeanConnStr'])\n",
    "    delta_cor_trial = 1-np.abs(sel_stim_coh['Delta_Cor'])\n",
    "            \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(delta_conn_trial, delta_cor_trial)\n",
    "    ax.plot([0.0, 1.0], slope*np.array([0.0, 1.0])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(delta_conn_trial, delta_cor_trial, s=1.0,\n",
    "               color='r', alpha=0.5, lw=0)\n",
    "    ax.text(0.25, 0.0, ' slope=%0.3f\\n rho=%0.3f\\n pv=%0.3f' % (slope, rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([-0.1, 1.1])\n",
    "    ax.set_ylim([-0.1, 1.1])\n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Reorganization of Topology')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Magnitude Change in\\nMean Conn Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Delta_MeanConnStrength-Topological_Similarity.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does Pre-Stim State Predict Reorganization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "        \n",
    "    # Get Trial Data\n",
    "    pre_conn_trial = sel_stim_coh['Pre_MeanConnStr']\n",
    "    delta_cor_trial = 1-np.abs(sel_stim_coh['Delta_Cor'])\n",
    "            \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(pre_conn_trial, delta_cor_trial)\n",
    "    ax.plot([0.0, 1.0], slope*np.array([0.0, 1.0])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(pre_conn_trial, delta_cor_trial, s=1.0,\n",
    "               color='r', alpha=0.5, lw=0)\n",
    "    ax.text(0.0, -0.05, ' slope=%0.3f\\n rho=%0.3f\\n pv=%0.3f' % (slope, rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([-0.1, 1.1])\n",
    "    ax.set_ylim([-0.1, 1.1])\n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Reorganization of Topology')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Pre-Stim Mean Conn Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Pre_MeanConnStrength-Topological_Similarity.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Input Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Reorganization of Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_freqs = np.unique(df_stim_topo['Stim_Freq'])\n",
    "stim_amps = np.unique(df_stim_topo['Stim_Amp'])\n",
    "\n",
    "stim_freqs = np.array([sfreq if len(np.unique(df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq]['Subject_ID'])) > 2 else np.nan\n",
    "              for sfreq in stim_freqs])\n",
    "stim_freqs = stim_freqs[~np.isnan(stim_freqs)]\n",
    "\n",
    "stim_amps = np.array([samp if len(np.unique(df_stim_topo[df_stim_topo['Stim_Amp'] == samp]['Subject_ID'])) > 2 else np.nan\n",
    "              for samp in stim_amps])\n",
    "stim_amps = stim_amps[~np.isnan(stim_amps)]\n",
    "\n",
    "n_freq = len(stim_freqs)\n",
    "n_amp = len(stim_amps)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, coh_id in enumerate(coherence_id):  \n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    ### For the ANOVA\n",
    "    pop_stim_freq = {}\n",
    "    for sfreq in stim_freqs:\n",
    "        pop_stim_freq[sfreq] = 1-np.abs(sel_stim_coh[sel_stim_coh['Stim_Freq'] == sfreq]['Delta_Cor'].as_matrix())\n",
    "    print(coh_id, 'Stim Freq: ', stats.f_oneway(*pop_stim_freq.values()))\n",
    "        \n",
    "    pop_stim_amp = {}\n",
    "    for samp in stim_amps:\n",
    "        pop_stim_amp[samp] = 1-np.abs(sel_stim_coh[sel_stim_coh['Stim_Amp'] == samp]['Delta_Cor'].as_matrix())\n",
    "    print(coh_id, 'Stim Amp: ', stats.f_oneway(*pop_stim_amp.values()))\n",
    "    print\n",
    "    \n",
    "    ### For the heatmap\n",
    "    mean_evoke_map = np.nan*np.zeros((n_freq, n_amp))\n",
    "    err_evoke_map = np.nan*np.zeros((n_freq, n_amp))    \n",
    "    for sfreq_i, sfreq in enumerate(stim_freqs):\n",
    "        for samp_i, samp in enumerate(stim_amps):\n",
    "            \n",
    "            sel_freq = sel_stim_coh[sel_stim_coh['Stim_Freq'] == sfreq]\n",
    "            sel_amp = sel_freq[sel_freq['Stim_Amp'] == samp]\n",
    "            \n",
    "            mean_evoke_map[sfreq_i, samp_i] = np.mean(1-np.abs(sel_amp['Delta_Cor']))\n",
    "            err_evoke_map[sfreq_i, samp_i] = np.std(1-np.abs(sel_amp['Delta_Cor'])) / np.sqrt(sel_amp['Delta_Cor'].count())\n",
    "            \n",
    "    # Plot input energy landscape\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    mat = ax.matshow(mean_evoke_map, aspect=n_amp/float(n_freq), cmap='viridis', vmin=0.60, vmax=0.75)\n",
    "    plt.colorbar(mat, ax=ax)\n",
    "    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Stim Frequency (Hz)')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Amplitude (mA)')\n",
    "\n",
    "    ax.set_yticks(np.arange(0, n_freq))\n",
    "    ax.set_yticklabels(stim_freqs)\n",
    "    \n",
    "    ax.set_xticks(np.arange(0, n_amp, 3))\n",
    "    ax.set_xticklabels(stim_amps[::3])\n",
    "    \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Input_Energy-Topological_Similarity.svg')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Distance to Maximal Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stim_freqs = np.unique(df_stim_topo['Stim_Freq'])\n",
    "stim_amps = np.unique(df_stim_topo['Stim_Amp'])\n",
    "\n",
    "stim_freqs = np.array([sfreq if len(np.unique(df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq]['Subject_ID'])) > 2 else np.nan\n",
    "              for sfreq in stim_freqs])\n",
    "stim_freqs = stim_freqs[~np.isnan(stim_freqs)]\n",
    "\n",
    "stim_amps = np.array([samp if len(np.unique(df_stim_topo[df_stim_topo['Stim_Amp'] == samp]['Subject_ID'])) > 2 else np.nan\n",
    "              for samp in stim_amps])\n",
    "stim_amps = stim_amps[~np.isnan(stim_amps)]\n",
    "\n",
    "n_freq = len(stim_freqs)\n",
    "n_amp = len(stim_amps)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "loc_change = {}\n",
    "for ii, coh_id in enumerate(coherence_id):  \n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    ### Compute Distance\n",
    "    pop_stim_freq = {}\n",
    "    pop_stim_amp = {}\n",
    "    tot_evoke_map = np.zeros((n_freq, n_amp))\n",
    "    cnt_evoke_map = np.zeros((n_freq, n_amp))    \n",
    "    for rr in sel_stim_coh.iterrows():\n",
    "        subj_id = rr[1]['Subject_ID']\n",
    "        dist_matr = channel_dict['Subject'][subj_id]['Dist_Matr']\n",
    "        n_chan = dist_matr.shape[0]\n",
    "        \n",
    "        delta_ns = rr[1]['Delta_NodeStr']\n",
    "        \n",
    "        sfreq = rr[1]['Stim_Freq']\n",
    "        samp = rr[1]['Stim_Amp']\n",
    "        if sfreq not in stim_freqs:\n",
    "            continue\n",
    "        sfreq_ii = np.flatnonzero(stim_freqs == sfreq)[0]\n",
    "        if samp not in stim_amps:\n",
    "            continue\n",
    "        samp_ii = np.flatnonzero(stim_amps == samp)[0]\n",
    "        \n",
    "        anode_jack = rr[1]['Stim_Anode']\n",
    "        cathode_jack = rr[1]['Stim_Cathode']          \n",
    "        anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "        cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "        \n",
    "        non_stim_ix = np.setdiff1d(np.arange(n_chan), np.array([anode_ix, cathode_ix]))\n",
    "        avg_stim_dist = (dist_matr[anode_ix, non_stim_ix] +\n",
    "                         dist_matr[cathode_ix, non_stim_ix]) / 2.0\n",
    "        \n",
    "        assert len(avg_stim_dist) == len(delta_ns)\n",
    "        \n",
    "        dist_to_max = avg_stim_dist[np.argmax(np.abs(delta_ns))]\n",
    "        if np.isnan(dist_to_max):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            pop_stim_freq[sfreq]\n",
    "        except:\n",
    "            pop_stim_freq[sfreq] = []\n",
    "        pop_stim_freq[sfreq].append(dist_to_max)\n",
    "        \n",
    "\n",
    "        try:\n",
    "            pop_stim_amp[samp]\n",
    "        except:\n",
    "            pop_stim_amp[samp] = []\n",
    "        pop_stim_amp[samp].append(dist_to_max)\n",
    "        \n",
    "        try:\n",
    "            loc_change[coh_id]\n",
    "        except:\n",
    "            loc_change[coh_id] = []\n",
    "        loc_change[coh_id].append(dist_to_max)    \n",
    "        \n",
    "        tot_evoke_map[sfreq_ii, samp_ii] += dist_to_max\n",
    "        cnt_evoke_map[sfreq_ii, samp_ii] += 1\n",
    "        \n",
    "    print(coh_id, 'Stim Freq: ', stats.f_oneway(*pop_stim_freq.values()))\n",
    "    print(coh_id, 'Stim Amp: ', stats.f_oneway(*pop_stim_amp.values()))\n",
    "    print\n",
    "    \n",
    "    # Plot input energy landscape\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    mat = ax.matshow(tot_evoke_map / cnt_evoke_map, aspect=n_amp/float(n_freq), cmap='viridis', vmin=50, vmax=60)\n",
    "    plt.colorbar(mat, ax=ax)\n",
    "    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Stim Frequency (Hz)')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Amplitude (mA)')\n",
    "\n",
    "    ax.set_yticks(np.arange(0, n_freq))\n",
    "    ax.set_yticklabels(stim_freqs)\n",
    "    \n",
    "    ax.set_xticks(np.arange(0, n_amp))\n",
    "    ax.set_xticklabels(stim_amps)\n",
    "    \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "plt.savefig('./e02-Figures/Input_Energy-Distance_Max_DeltaNodeStr.svg')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "### Distance to Max Delta Changes with Connection Frequency\n",
    "print(stats.f_oneway(*loc_change.values()))\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "bp1 = ax.boxplot([loc_change[coh_id] for coh_id in coherence_id],\n",
    "                 positions=np.arange(len(coherence_id)),\n",
    "                 patch_artist=True)\n",
    "Echobase.Plotting.fig_format.set_box_color(bp1, 'k', [[0.00, 0.37, 1.00] \n",
    "                                                      for ii in xrange(len(coherence_id))])\n",
    "\n",
    "ax.set_xlim([-0.5, 3.5])\n",
    "ax.set_xticks(np.arange(len(coherence_id)))\n",
    "ax.set_xticklabels(coherence_id)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_ylabel('Distance to Maximum Evoked Node')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('./e02-Figures/Coherence-Distance_Max_DeltaNodeStr.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Stimulation Location (Functional Hubness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Mean Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_MeanConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_MeanConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_MeanConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_MeanConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_stim_mcs = []\n",
    "    subj_base_zns = []    \n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_zns = sel_subj_base[afreq[1]].mean()\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            base_zns_stim = 0.5*(base_zns[a_ix] + base_zns[c_ix])\n",
    "            subj_base_zns.append(base_zns_stim)            \n",
    "            \n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            subj_stim_mcs.append(sel_stim[afreq[0]].mean())\n",
    "            \n",
    "    subj_base_zns = np.array(subj_base_zns)\n",
    "    subj_stim_mcs = np.array(subj_stim_mcs)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_base_zns, subj_stim_mcs)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_base_zns, subj_stim_mcs, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_base_zns, subj_stim_mcs)\n",
    "    print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(1.0, 0.06, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([-0.08, 0.08])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Mean Evoked\\nConnection Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Variance of Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_VarConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_VarConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_VarConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_VarConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_stim_mcs = []\n",
    "    subj_base_zns = []    \n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_zns = sel_subj_base[afreq[1]].mean()\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            base_zns_stim = 0.5*(base_zns[a_ix] + base_zns[c_ix])\n",
    "            subj_base_zns.append(base_zns_stim)            \n",
    "            \n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            subj_stim_mcs.append(sel_stim[afreq[0]].mean())\n",
    "            \n",
    "    subj_base_zns = np.array(subj_base_zns)\n",
    "    subj_stim_mcs = np.array(subj_stim_mcs)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_base_zns, subj_stim_mcs)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_base_zns, subj_stim_mcs, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_base_zns, subj_stim_mcs)\n",
    "    print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(-3.0, 0.12, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([0.0, 0.15])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Variance Evoked\\nConnection Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect on Strongest of Changes in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig1 = plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_base_coh = df_base_topo[df_base_topo['Coherence_ID'] == coh_id]\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]    \n",
    "\n",
    "    subj_base_zns = []\n",
    "    subj_delta_ns = []    \n",
    "    for subj_id in np.intersect1d(sel_base_coh['Subject_ID'],\n",
    "                                  sel_stim_coh['Subject_ID']):\n",
    "        sel_subj_base = sel_base_coh[sel_base_coh['Subject_ID'] == subj_id]                    \n",
    "        sel_subj_stim = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]  \n",
    "\n",
    "        base_zns = sel_subj_base['Base_ZNodeStr'].mean()            \n",
    "\n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "\n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            base_zns_stim = 0.5*(base_zns[a_ix] + base_zns[c_ix])\n",
    "            subj_base_zns.append(base_zns_stim)            \n",
    "\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            arr = []\n",
    "            for trial in sel_stim['Delta_NodeStr']:\n",
    "                arr.append(np.percentile(trial, 5))\n",
    "            subj_delta_ns.append(np.mean(arr))\n",
    "\n",
    "    subj_base_zns = np.array(subj_base_zns)\n",
    "    subj_delta_ns = np.array(subj_delta_ns)\n",
    "\n",
    "    ### Correlation between baseline stim node strength and average desynchronized change in node strength\n",
    "    ax = fig1.add_subplot(2, 2, ii+1)    \n",
    "    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_base_zns, subj_delta_ns)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_base_zns, subj_delta_ns, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    rho, pv = stats.spearmanr(subj_base_zns, subj_delta_ns)\n",
    "    ax.text(-3, 0.0, 'rho=%0.2f\\npv=%0.2e' % (rho, pv), fontsize=4.0)\n",
    "\n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim(ymax=0.05)\n",
    "    ax.set_ylabel('5% -$\\Delta$ Node Strength')\n",
    "    ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)            \n",
    "\n",
    "    #fig1.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity of Evoked Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_Cor_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_Cor_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_Cor_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_Cor_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_stim_mcs = []\n",
    "    subj_base_zns = []    \n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_zns = sel_subj_base[afreq[1]].mean()\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            base_zns_stim = 0.5*(base_zns[a_ix] + base_zns[c_ix])\n",
    "            subj_base_zns.append(base_zns_stim)            \n",
    "            \n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            #subj_stim_mcs.append(sel_stim[afreq[0]].mean())\n",
    "            \n",
    "            arr = []\n",
    "            for trial in sel_stim[afreq[0]]:\n",
    "                arr.append(1-np.abs(trial))\n",
    "            subj_stim_mcs.append(np.mean(arr))    \n",
    "            \n",
    "    subj_base_zns = np.array(subj_base_zns)\n",
    "    subj_stim_mcs = np.array(subj_stim_mcs)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_base_zns, subj_stim_mcs)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_base_zns, subj_stim_mcs, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_base_zns, subj_stim_mcs)\n",
    "    print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(1.0, 0.25, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([0.0, 1.0])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Evoked Reorg. of\\nNetwork Topology')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Stimulation Location (Functional Region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Node Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['ZNodeStr_AlphaTheta',\n",
    "             'ZNodeStr_Beta',\n",
    "             'ZNodeStr_LowGamma',\n",
    "             'ZNodeStr_HighGamma']\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_zns = sel_subj_base[afreq].mean()\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(base_zns[a_ix])\n",
    "            \n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            c_loc = c_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(base_zns[c_ix])\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    #ax.set_xlim([-0.5, len(lbl)-0.5])\n",
    "    ax.set_ylim([-1.25, 1.25])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Baseline\\nFunctional Connectivity of\\nStimulated Electrode')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq.split('_')[-1], Fv, Pv))\n",
    "    \n",
    "    \n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Mean Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_MeanConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_MeanConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_MeanConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_MeanConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "            \n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            c_loc = c_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    ax.set_ylim([-0.004, 0.015])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Mean of Evoked\\nConnection Strength')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq[0].split('_')[-1], Fv, Pv))\n",
    "    \n",
    "    \n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Variance of Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_VarConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_VarConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_VarConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_VarConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "            \n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            c_loc = c_loc.split('_')[1]                \n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    ax.set_ylim([0.015, 0.05])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Variance of Evoked\\nConnection Strength')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq[0].split('_')[-1], Fv, Pv))\n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity of Evoked Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_Cor_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_Cor_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_Cor_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_Cor_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "\n",
    "            arr = []\n",
    "            for trial in sel_stim[afreq[0]]:\n",
    "                arr.append(1-np.abs(trial))            \n",
    "            \n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            #if len(a_loc.split('_')) == 3:\n",
    "            #    a_loc = '_'.join(a_loc.split('_')[0:2])\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(np.mean(arr))\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            #if len(c_loc.split('_')) == 3:\n",
    "            #    c_loc = '_'.join(c_loc.split('_')[0:2])     \n",
    "            c_loc = c_loc.split('_')[1]            \n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(np.mean(arr))\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    ax.set_ylim([0.4, 1.0])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Evoked Reorg. of\\nNetwork Topology')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq[0].split('_')[-1], Fv, Pv))\n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Modulated Hubness of Brain Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 'scale250'\n",
    "\n",
    "roi_lbl = np.sort(np.array(struct_dict['Atlas'][scale].keys()))\n",
    "roi_lbl = np.unique([roi.split('_')[1] for roi in roi_lbl])\n",
    "\n",
    "n_roi = len(roi_lbl)\n",
    "subj_lbl = []\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "evoke_map_coh = {}\n",
    "evoke_map_coh_cnt = {}\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    evoke_map_ns = np.zeros((n_roi, n_roi))\n",
    "    evoke_map_cnt = np.zeros((n_roi, n_roi))    \n",
    "\n",
    "    evoke_map_subj_ns = np.zeros((n_roi, n_roi))\n",
    "    evoke_map_subj_cnt = np.zeros((n_roi, n_roi))        \n",
    "    \n",
    "    evoke_ns_targ_ds = []\n",
    "    struct_conn_targ_ds = []    \n",
    "    for subj_id in subject_id:\n",
    "        sel_subj_stim = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "        atlas_lbl = np.array(channel_dict['Subject'][subj_id]['Atlas_Label'][scale])\n",
    "        n_chan = len(atlas_lbl)\n",
    "        \n",
    "        evoke_subj_ns = np.zeros((n_roi, n_roi))\n",
    "        evoke_subj_cnt = np.zeros((n_roi, n_roi))    \n",
    "\n",
    "        # Iterate over stimulation trials\n",
    "        for rr in sel_subj_stim.iterrows():\n",
    "            delta_ns = rr[1]['Post_NodeStr'] - rr[1]['Pre_NodeStr']\n",
    "\n",
    "            anode_jack = rr[1]['Stim_Anode']\n",
    "            cathode_jack = rr[1]['Stim_Cathode']          \n",
    "            a_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            c_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]        \n",
    "            atlas_lbl_nostim = atlas_lbl[np.setdiff1d(np.arange(n_chan), [a_ix, c_ix])]\n",
    "            atlas_lbl_nostim = np.array([roi.split('_')[1] for roi in atlas_lbl_nostim])\n",
    "            \n",
    "            # Get stim location\n",
    "            a_loc = atlas_lbl[a_ix]    \n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            a_roi_ix = np.flatnonzero(roi_lbl == a_loc)[0]\n",
    "\n",
    "            c_loc = atlas_lbl[c_ix]\n",
    "            c_loc = c_loc.split('_')[1]            \n",
    "            c_roi_ix = np.flatnonzero(roi_lbl == c_loc)[0]   \n",
    "            \n",
    "            # Get max pos and max neg evoke\n",
    "            for chan_ix in xrange(len(atlas_lbl_nostim)):\n",
    "                roi_lbl_ix = np.flatnonzero(roi_lbl == atlas_lbl_nostim[chan_ix])[0]\n",
    "                evoke_map_ns[a_roi_ix, roi_lbl_ix] += delta_ns[chan_ix]\n",
    "                evoke_map_ns[c_roi_ix, roi_lbl_ix] += delta_ns[chan_ix]\n",
    "                evoke_map_cnt[a_roi_ix, roi_lbl_ix] += 1\n",
    "                evoke_map_cnt[c_roi_ix, roi_lbl_ix] += 1\n",
    "\n",
    "                evoke_subj_ns[a_roi_ix, roi_lbl_ix] += delta_ns[chan_ix]\n",
    "                evoke_subj_ns[c_roi_ix, roi_lbl_ix] += delta_ns[chan_ix]\n",
    "                evoke_subj_cnt[a_roi_ix, roi_lbl_ix] += 1\n",
    "                evoke_subj_cnt[c_roi_ix, roi_lbl_ix] += 1  \n",
    "        \n",
    "        evoke_subj_mns = evoke_subj_ns / evoke_subj_cnt\n",
    "        evoke_subj_mns[np.isnan(evoke_subj_mns)] = 0\n",
    "        \n",
    "        evoke_map_subj_ns += evoke_subj_mns\n",
    "        evoke_subj_cnt[evoke_subj_cnt > 0] = 1\n",
    "        evoke_map_subj_cnt += evoke_subj_cnt\n",
    "                    \n",
    "        # Correlate Subject's evoked map to Structural Connectivity\n",
    "        if subj_id in struct_dict['Subject'].keys():\n",
    "            subj_lbl.append(subj_id)\n",
    "            \n",
    "            for ixx, iyy in zip(np.nonzero(evoke_subj_mns)[0],\n",
    "                                np.nonzero(evoke_subj_mns)[1]):\n",
    "                if ixx == iyy:\n",
    "                    continue\n",
    "                s_conn = struct_dict['Subject'][subj_id][scale]['QA']['adj'][ixx, iyy]\n",
    "                if s_conn == 0:\n",
    "                    continue\n",
    "                    \n",
    "                evoke_ns_targ_ds.append(evoke_subj_mns[ixx, iyy])\n",
    "                struct_conn_targ_ds.append(s_conn)\n",
    "    evoke_ns_targ_ds = np.array(evoke_ns_targ_ds)\n",
    "    struct_conn_targ_ds = np.array(struct_conn_targ_ds)\n",
    "    \n",
    "    # Aggregate population evoked map\n",
    "    #evoke_map_mns = evoke_map_ns / evoke_map_cnt\n",
    "    #evoke_map_mns[np.isnan(evoke_map_mns)] = 0\n",
    "    evoke_map_coh[coh_id] = evoke_map_subj_ns / len(subject_id)\n",
    "    evoke_map_coh_cnt[coh_id] = evoke_map_subj_cnt\n",
    "    \n",
    "    # Plot relationship between structural connectivity between stim site and target vs. the functional effect of stim\n",
    "    ax = plt.subplot(2,2,ii+1)\n",
    "\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(struct_conn_targ_ds, evoke_ns_targ_ds)\n",
    "    ax.plot([0.01, 0.20], slope*np.array([0.01, 0.20])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(struct_conn_targ_ds, evoke_ns_targ_ds, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    rho, pv = stats.spearmanr(struct_conn_targ_ds, evoke_ns_targ_ds)\n",
    "    ax.text(0.15, 0.015, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([0, 0.21])\n",
    "    ax.set_ylim([-0.02, 0.02])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Downstream Functional Effect')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Structural Connectivity\\n(Stim Target --> Downstream)')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/StructuralConn-DSFunctionalEffect.{}.png'.format(coh_id))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoke = evoke_map_coh['AlphaTheta'].copy()\n",
    "evoke[evoke == 0] = np.nan\n",
    "\n",
    "evoke_cnt = evoke_map_coh_cnt['AlphaTheta']\n",
    "evoke[evoke_cnt < 2] = np.nan\n",
    "\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "mat = ax.matshow(evoke, cmap='coolwarm', vmin=-0.0005, vmax=0.0005)\n",
    "plt.colorbar(mat, ax=ax)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_xticks(xrange(len(roi_lbl)))\n",
    "ax.set_yticks(xrange(len(roi_lbl)))\n",
    "ax.set_xticklabels(roi_lbl, fontsize=3.0, rotation=90)\n",
    "ax.set_yticklabels(roi_lbl, fontsize=3.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Electrode-Level Adjacency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scale_id = 'scale250'\n",
    "atlas_lbl = np.array(struct_dict['Atlas'][scale_id].keys())\n",
    "\n",
    "electrode_struct_adj = {}\n",
    "\n",
    "for subj_id in np.intersect1d(struct_dict['Subject'].keys(),\n",
    "                              channel_dict['Subject'].keys()):\n",
    "    \n",
    "    roi_adj = struct_dict['Subject'][subj_id][scale_id]['QA']['adj']\n",
    "    \n",
    "    chan_atlas_lbl = channel_dict['Subject'][subj_id]['Atlas_Label'][scale_id]\n",
    "    chan_lbl = channel_dict['Subject'][subj_id]['Channel_Label']\n",
    "    n_chan = len(chan_atlas_lbl)\n",
    "    assert n_chan == len(chan_lbl)\n",
    "    adj = np.zeros((n_chan, n_chan))\n",
    "    \n",
    "    for ch_ix, lbl_x in enumerate(chan_atlas_lbl):\n",
    "        for ch_iy, lbl_y in enumerate(chan_atlas_lbl):\n",
    "            ix = np.flatnonzero(atlas_lbl == lbl_x)[0]\n",
    "            iy = np.flatnonzero(atlas_lbl == lbl_y)[0]\n",
    "            \n",
    "            adj[ch_ix, ch_iy] = roi_adj[ix, iy]\n",
    "    adj[np.diag_indices_from(adj)] = 0\n",
    "    \n",
    "    electrode_struct_adj[subj_id] = {'adj': adj,\n",
    "                                     'channel_label': chan_lbl}\n",
    "pkl.dump(electrode_struct_adj, open('{}/lausanne_scale250_electrode.pkl'.format(path_ExpData), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Input Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stim_freqs = np.unique(df_memory['Stim_Freq'])\n",
    "stim_amps = np.unique(df_memory['Stim_Amp'])\n",
    "\n",
    "stim_freqs = np.array([sfreq if len(np.unique(df_memory[df_memory['Stim_Freq'] == sfreq]['Subject_ID'])) > 2 else np.nan\n",
    "                       for sfreq in stim_freqs])\n",
    "stim_freqs = stim_freqs[~np.isnan(stim_freqs)]\n",
    "\n",
    "stim_amps = np.array([samp if len(np.unique(df_memory[df_memory['Stim_Amp'] == samp]['Subject_ID'])) > 2 else np.nan\n",
    "                      for samp in stim_amps])\n",
    "stim_amps = stim_amps[~np.isnan(stim_amps)]\n",
    "\n",
    "n_freq = len(stim_freqs)\n",
    "n_amp = len(stim_amps)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Stimulation Frequency\n",
    "mem_freq = []\n",
    "for sfreq in stim_freqs:\n",
    "    sel_freq = df_memory[df_memory['Stim_Freq'] == sfreq]\n",
    "    \n",
    "    subj_freq = []\n",
    "    for subj_id in np.unique(df_memory['Subject_ID']):\n",
    "        sel_memory = sel_freq[sel_freq['Subject_ID'] == subj_id]\n",
    "        subj_freq.append((sel_memory['Post_Stim_Prob'] - sel_memory['Pre_Stim_Prob']).mean())\n",
    "    mem_freq.append(subj_freq)\n",
    "    \n",
    "print('All Freq: {}'.format(stats.pearsonr(stim_freqs,  np.nanmean(np.array(mem_freq), axis=1))))\n",
    "print(' > 10 Hz: {}'.format(stats.pearsonr(stim_freqs[1:],  np.nanmean(np.array(mem_freq), axis=1)[1:])))\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.errorbar(stim_freqs, np.nanmean(np.array(mem_freq), axis=1), yerr=np.nanstd(np.array(mem_freq), axis=1) / np.sqrt(86))\n",
    "ax.set_xlim([0, 210])\n",
    "ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "ax.set_xlabel('Stimulation Frequency (Hz)')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')        \n",
    "plt.show()\n",
    "\n",
    "### Stimulation Amplitude\n",
    "mem_amp = []\n",
    "for samp in stim_amps:\n",
    "    sel_amp = df_memory[df_memory['Stim_Amp'] == samp]\n",
    "    \n",
    "    subj_amp = []\n",
    "    for subj_id in np.unique(df_memory['Subject_ID']):\n",
    "        sel_memory = sel_amp[sel_amp['Subject_ID'] == subj_id]\n",
    "        subj_amp.append((sel_memory['Post_Stim_Prob'] > sel_memory['Pre_Stim_Prob']).mean())\n",
    "    mem_amp.append(subj_amp)\n",
    "    \n",
    "print('All Amp: {}'.format(stats.pearsonr(stim_amps,  np.nanmean(np.array(mem_amp), axis=1))))\n",
    "plt.figure(figsize=(3,3), dpi=300)  \n",
    "ax = plt.subplot(111)\n",
    "ax.errorbar(stim_amps/1000, np.nanmean(np.array(mem_amp), axis=1), yerr=np.nanstd(np.array(mem_amp), axis=1) / np.sqrt(86))\n",
    "ax.set_xlim([0, 2.125])\n",
    "ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "ax.set_xlabel('Stimulation Amplitude (mA)')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Stimulation Location (Structural Control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scale = 'scale250'\n",
    "trk = 'QA'\n",
    "atlas_lbl = np.array(struct_dict['Atlas'][scale].keys())\n",
    "\n",
    "subj_lbl = []\n",
    "roi_lbl = []\n",
    "subj_strc_avg_ctl = []\n",
    "subj_strc_mod_ctl = []\n",
    "subj_delta_mem = []\n",
    "\n",
    "for subj_id in np.unique(df_memory['Subject_ID']):\n",
    "    try:\n",
    "        avg_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['avg_ctl'])\n",
    "        mod_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['mod_ctl'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    avg_ctl = (avg_ctl-avg_ctl.mean()) / avg_ctl.std()\n",
    "    mod_ctl = (mod_ctl-mod_ctl.mean()) / mod_ctl.std()            \n",
    "\n",
    "    sel_memory = df_memory[df_memory['Subject_ID'] == subj_id]\n",
    "\n",
    "    # Get stim anode/cathode pairs\n",
    "    stim_ix = []\n",
    "    for anode_jack, cathode_jack in zip(sel_memory['Stim_Anode'],\n",
    "                                        sel_memory['Stim_Cathode']):\n",
    "        try:\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        except:\n",
    "            continue\n",
    "    stim_ix = list(set(stim_ix))\n",
    "    \n",
    "    # Iterate over all stim pairs\n",
    "    for a_ix, c_ix in stim_ix:\n",
    "        a_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "        c_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "\n",
    "        a_roi_ix = np.flatnonzero(atlas_lbl == a_roi)[0]\n",
    "        c_roi_ix = np.flatnonzero(atlas_lbl == c_roi)[0]        \n",
    "\n",
    "        roi_lbl.append((a_roi, c_roi))\n",
    "        subj_strc_avg_ctl.append(0.5*(avg_ctl[c_roi_ix] + avg_ctl[a_roi_ix]))\n",
    "        subj_strc_mod_ctl.append(0.5*(mod_ctl[c_roi_ix] + mod_ctl[a_roi_ix]))            \n",
    "\n",
    "        a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "        c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "        sel_stim = sel_memory[sel_memory['Stim_Anode'] == a_jack]\n",
    "        sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "        \n",
    "        subj_lbl.append(subj_id)\n",
    "        subj_delta_mem.append((sel_stim['Post_Stim_Prob'] - sel_stim['Pre_Stim_Prob']).mean())\n",
    "\n",
    "subj_delta_mem = np.array(subj_delta_mem) \n",
    "subj_strc_avg_ctl = np.array(subj_strc_avg_ctl)  \n",
    "subj_strc_mod_ctl = np.array(subj_strc_mod_ctl)\n",
    "roi_lbl = np.array(roi_lbl)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Average Controllability\n",
    "slope, yint, rho, pv, stderr = stats.linregress(subj_strc_avg_ctl,\n",
    "                                                subj_delta_mem)\n",
    "\n",
    "plt.figure(figsize=(2,2), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.plot([-3, 3], slope*np.array([-3, 3])+yint, 'k', alpha=0.5)    \n",
    "ax.scatter(subj_strc_avg_ctl, subj_delta_mem,\n",
    "           s=3.0, color=[0.5, 0.5, 0.5], lw=0)\n",
    "ax.text(1.0, 0.01, ' slope=%0.3f\\n rho=%0.3f\\n pv=%0.3f' % (slope, rho, pv), fontsize=4.0)\n",
    "\n",
    "#ax.set_xlim([-1.5, 1.5])\n",
    "ax.set_ylim([-0.03, 0.03])\n",
    "ax.set_xlabel('Average Controllability\\n(Z-Score)')      \n",
    "ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.show()\n",
    "print(roi_lbl[np.argsort(subj_strc_avg_ctl)])\n",
    "\n",
    "### Modal Controllability\n",
    "slope, yint, rho, pv, stderr = stats.linregress(subj_strc_mod_ctl,\n",
    "                                                subj_delta_mem)\n",
    "\n",
    "plt.figure(figsize=(2,2), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.plot([-4, 4], slope*np.array([-4, 4])+yint, 'k', alpha=0.5)    \n",
    "ax.scatter(subj_strc_mod_ctl, subj_delta_mem,\n",
    "           s=3.0, color=[0.5, 0.5, 0.5], lw=0)\n",
    "ax.text(-1.0, 0.02, ' rho=%0.2f\\n pv=%0.2e' % (rho, pv), fontsize=4.0)\n",
    "\n",
    "#ax.set_xlim([-1.5, 1.5])\n",
    "ax.set_ylim([-0.03, 0.03])\n",
    "ax.set_xlabel('Modal Controllability\\n(Z-Score)')      \n",
    "ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.show()\n",
    "print(roi_lbl[np.argsort(subj_strc_mod_ctl)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Effect of Network State on Memory State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig1 = plt.figure(figsize=(5,5), dpi=300)\n",
    "fig2 = plt.figure(figsize=(5,5), dpi=300)\n",
    "\n",
    "df_stim_topo_nn = df_stim_topo.dropna(axis=0)\n",
    "df_memory_nn = df_memory.dropna(axis=0)\n",
    "common_stim_mem_subject_id = np.intersect1d(df_stim_topo_nn['Subject_ID'],\n",
    "                                            df_memory_nn['Subject_ID'])\n",
    "\n",
    "opt_subj_id = []\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo_nn[df_stim_topo_nn['Coherence_ID'] == coh_id]\n",
    "\n",
    "    pop_base_zns = []\n",
    "    pop_pre_mcs_corr = []\n",
    "    pop_delta_mcs_corr = []    \n",
    "    pop_pre_mcs_pv = []\n",
    "    pop_delta_mcs_pv = []    \n",
    "    for subj_id in common_stim_mem_subject_id:\n",
    "        sel_subj_stim = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "        sel_subj_mem = df_memory_nn[df_memory_nn['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Iterate over stimulation trials\n",
    "        base_zns = []\n",
    "        pop_delta_mem_prob = []\n",
    "        pop_pre_mcs = []\n",
    "        pop_delta_mcs = []        \n",
    "        for rr in sel_subj_stim.iterrows():\n",
    "            ev_id = rr[1]['Event_ID']\n",
    "            sel_subj_mem_ev = sel_subj_mem[sel_subj_mem['Event_ID'] == ev_id]\n",
    "            \n",
    "            pre_mem_prob = sel_subj_mem_ev['Pre_Stim_Prob']\n",
    "            post_mem_prob = sel_subj_mem_ev['Post_Stim_Prob']\n",
    "            delta_mem_prob = (post_mem_prob-pre_mem_prob).mean()\n",
    "            \n",
    "            if not np.isnan(delta_mem_prob):\n",
    "                pop_delta_mem_prob.append(delta_mem_prob)\n",
    "                pop_pre_mcs.append(rr[1]['Pre_MeanConnStr'])\n",
    "                pop_delta_mcs.append(np.percentile(rr[1]['Delta_NodeStr'], 5)) \n",
    "                base_zns.append(rr[1]['Stim_Base_ZNodeStr'])\n",
    "        \n",
    "        pre_mcs_corr = stats.pearsonr(pop_pre_mcs, pop_delta_mem_prob)\n",
    "        delta_mcs_corr = stats.pearsonr(pop_delta_mcs, pop_delta_mem_prob)\n",
    "        \n",
    "        pop_pre_mcs_corr.append(pre_mcs_corr[0])\n",
    "        pop_delta_mcs_corr.append(delta_mcs_corr[0])\n",
    "        pop_pre_mcs_pv.append(pre_mcs_corr[1])\n",
    "        pop_delta_mcs_pv.append(delta_mcs_corr[1])\n",
    "        pop_base_zns.append(np.nanmean(base_zns))\n",
    "        \n",
    "    pop_pre_mcs_corr = np.array(pop_pre_mcs_corr)\n",
    "    pop_delta_mcs_corr = np.array(pop_delta_mcs_corr)\n",
    "    pop_pre_mcs_pv = np.array(pop_pre_mcs_pv)\n",
    "    pop_delta_mcs_pv = np.array(pop_delta_mcs_pv)\n",
    "    pop_base_zns = np.array(pop_base_zns)\n",
    "    \n",
    "    # Stats pre-proc\n",
    "    ord_subj_ix = np.argsort(pop_pre_mcs_corr)[::-1]\n",
    "    opt_subj_id.append(common_stim_mem_subject_id[ord_subj_ix[0]])\n",
    "    alpha = 0.05 / len(ord_subj_ix)\n",
    "    \n",
    "    \n",
    "    ### Correlation between pre stim network coherence and change in classifier likelihood\n",
    "    # on trial by trial basis\n",
    "    ax = fig1.add_subplot(4, 3, (3*ii)+1)\n",
    "    \n",
    "    colors = [[0.9, 0.3, 0.3] if pv < alpha else [0.3, 0.3, 0.9]\n",
    "              for pv in pop_pre_mcs_pv[ord_subj_ix]]    \n",
    "    ax.bar(xrange(len(ord_subj_ix)), pop_pre_mcs_corr[ord_subj_ix],\n",
    "           width=0.5, lw=0, color=colors)\n",
    "    ax.set_xlim([-0.5, len(ord_subj_ix)])\n",
    "    ax.set_ylabel('PearsonR(\\nPre-Stim Mean Conn.,\\n$\\Delta$Memory Classifier)')\n",
    "    ax.set_xlabel('RAM Subjects (PS2)')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)        \n",
    "    \n",
    "    \n",
    "    ### Correlation between change in network coherence and change in classifier likelihood\n",
    "    # on trial by trial basis\n",
    "    ax = fig1.add_subplot(4, 3, (3*ii)+2)\n",
    "    \n",
    "    colors = [[0.9, 0.3, 0.3] if pv < alpha else [0.3, 0.3, 0.9]\n",
    "              for pv in pop_delta_mcs_pv[ord_subj_ix]]\n",
    "    ax.bar(xrange(len(ord_subj_ix)), pop_delta_mcs_corr[ord_subj_ix],\n",
    "           width=0.5, lw=0, color=colors)\n",
    "    ax.set_xlim([-0.5, len(ord_subj_ix)])\n",
    "    ax.set_ylabel('PearsonR(\\n5% -$\\Delta$ Node Strength,\\n$\\Delta$Memory Classifier)')\n",
    "    ax.set_xlabel('RAM Subjects (PS2)')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "\n",
    "    ### Correlation between delta network coherence and change in classifier likelihood\n",
    "    # on trial by trial basis\n",
    "    ax = fig1.add_subplot(4, 3, (3*ii)+3)\n",
    "   \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(pop_base_zns[ord_subj_ix], pop_delta_mcs_corr[ord_subj_ix])\n",
    "    ax.plot([-2, 2], slope*np.array([-1, 1])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(pop_base_zns[ord_subj_ix], pop_delta_mcs_corr[ord_subj_ix], s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.pearsonr(pop_base_zns[ord_subj_ix], pop_delta_mcs_corr[ord_subj_ix])\n",
    "    ax.text(-2, 0.2, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    #ax.set_xlim([-4, 4])\n",
    "    #ax.set_ylim([-4, 4])    \n",
    "    ax.set_ylabel('PearsonR(\\n5% -$\\Delta$ Node Strength,\\n$\\Delta$Memory Classifier)')\n",
    "    ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "fig1.savefig('./e02-Figures/FunctionalConn-Memory_State.svg')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df_stim_topo_nn = df_stim_topo.dropna(axis=0)\n",
    "df_memory_nn = df_memory.dropna(axis=0)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo_nn[df_stim_topo_nn['Coherence_ID'] == coh_id]\n",
    "    subj_id = common_stim_mem_subject_id[opt_subj_id[ii]]\n",
    "    \n",
    "    sel_subj_stim = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "    sel_subj_mem = df_memory_nn[df_memory_nn['Subject_ID'] == subj_id]\n",
    "\n",
    "    # Iterate over stimulation trials\n",
    "    pop_delta_mem_prob = []\n",
    "    pop_pre_mcs = []\n",
    "    pop_delta_mcs = []        \n",
    "    for rr in sel_subj_stim.iterrows():\n",
    "        ev_id = rr[1]['Event_ID']\n",
    "        sel_subj_mem_ev = sel_subj_mem[sel_subj_mem['Event_ID'] == ev_id]\n",
    "\n",
    "        pre_mem_prob = sel_subj_mem_ev['Pre_Stim_Prob']\n",
    "        post_mem_prob = sel_subj_mem_ev['Post_Stim_Prob']\n",
    "        delta_mem_prob = (post_mem_prob-pre_mem_prob).mean()\n",
    "\n",
    "        if not np.isnan(delta_mem_prob):\n",
    "            pop_delta_mem_prob.append(delta_mem_prob)\n",
    "            pop_pre_mcs.append(rr[1]['Pre_MeanConnStr'])\n",
    "            pop_delta_mcs.append(np.percentile(rr[1]['Delta_NodeStr'], 5))\n",
    "    \n",
    "    ### Correlation between pre stim network coherence and change in classifier likelihood\n",
    "    # on trial by trial basis\n",
    "    fig1 = plt.figure(figsize=(3,3), dpi=300)\n",
    "    ax = fig1.add_subplot(111)\n",
    "    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(pop_pre_mcs, pop_delta_mem_prob)\n",
    "    ax.plot([0.1, 0.45], slope*np.array([0.1, 0.45])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(pop_pre_mcs, pop_delta_mem_prob, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    ax.text(0.05, 0.3, 'rho=%0.2f\\np=%0.2e' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([0.0, 0.5])\n",
    "    ax.set_ylim([-0.5, 0.5])    \n",
    "    ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "    ax.set_xlabel('Pre-Stim Mean Coherence')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\n{}'.format(subj_id, coh_id))\n",
    "    fig1.savefig('./e02-Figures/Pre_MeanConnStr-Memory_State.{}.{}.svg'.format(subj_id, coh_id))\n",
    "    \n",
    "    ### Correlation between most weakened nodes and change in classifier likelihood\n",
    "    # on trial by trial basis\n",
    "    fig2 = plt.figure(figsize=(3,3), dpi=300)\n",
    "    ax = fig2.add_subplot(111)\n",
    "    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(pop_delta_mcs, pop_delta_mem_prob)\n",
    "    ax.plot([-0.45, 0.05], slope*np.array([-0.45, 0.05])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(pop_delta_mcs, pop_delta_mem_prob, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    ax.text(-0.05, 0.35, 'rho=%0.2f\\np=%0.2e' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-0.5, 0.1])\n",
    "    ax.set_ylim([-0.5, 0.5])    \n",
    "    ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "    ax.set_xlabel('Bottom 5% $\\Delta$ Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\n{}'.format(subj_id, coh_id))\n",
    "    fig2.savefig('./e02-Figures/Delta_NodeStr-Memory_State.{}.{}.svg'.format(subj_id, coh_id))    \n",
    "    \n",
    "    plt.show() \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for trajectory analysis (for Jeni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stim_topo_nn = df_stim_topo.dropna(axis=0)\n",
    "df_memory_nn = df_memory.dropna(axis=0)\n",
    "\n",
    "common_stim_mem_subject_id = np.intersect1d(np.intersect1d(df_stim_topo_nn['Subject_ID'],\n",
    "                                                           df_memory_nn['Subject_ID']),\n",
    "                                            electrode_struct_adj.keys())\n",
    "\n",
    "for subj_id in common_stim_mem_subject_id:\n",
    "    sel_subj_stim = df_stim_topo_nn[df_stim_topo_nn['Subject_ID'] == subj_id]\n",
    "    sel_subj_mem = df_memory_nn[df_memory_nn['Subject_ID'] == subj_id]\n",
    "    \n",
    "    m_dict = {}\n",
    "    \n",
    "    m_dict['Struct_Adj'] = electrode_struct_adj[subj_id]['adj']\n",
    "    \n",
    "    m_dict['Stim_Anode_Idx'] = []\n",
    "    m_dict['Stim_Cathode_Idx'] = []    \n",
    "    m_dict['Stim_Freq'] = []\n",
    "    m_dict['Stim_Amp'] = []  \n",
    "    m_dict['Pre_Stim_Prob'] = []\n",
    "    m_dict['Post_Stim_Prob'] = []    \n",
    "    for ev_id in np.unique(sel_subj_stim['Event_ID']):\n",
    "        sel_subj_stim_ev = sel_subj_stim[sel_subj_stim['Event_ID'] == ev_id]\n",
    "        sel_subj_mem_ev = sel_subj_mem[sel_subj_mem['Event_ID'] == ev_id]\n",
    "        if len(sel_subj_mem_ev) == 1:\n",
    "            m_dict['Stim_Freq'].append(sel_subj_mem_ev['Stim_Freq'].ravel()[0])\n",
    "            m_dict['Stim_Amp'].append(sel_subj_mem_ev['Stim_Amp'].ravel()[0])\n",
    "            m_dict['Pre_Stim_Prob'].append(sel_subj_mem_ev['Pre_Stim_Prob'].ravel()[0])\n",
    "            m_dict['Post_Stim_Prob'].append(sel_subj_mem_ev['Post_Stim_Prob'].ravel()[0])\n",
    "            m_dict['Stim_Anode_Idx'].append(np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == sel_subj_mem_ev['Stim_Anode'].ravel()[0])[0]+1)\n",
    "            m_dict['Stim_Cathode_Idx'].append(np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == sel_subj_mem_ev['Stim_Cathode'].ravel()[0])[0]+1)\n",
    "            \n",
    "        \n",
    "            for coh_id in coherence_id:\n",
    "                sel_subj_stim_ev_coh = sel_subj_stim_ev[sel_subj_stim_ev['Coherence_ID'] == coh_id]\n",
    "\n",
    "                str_key = 'Pre_NodeStr_{}'.format(coh_id)\n",
    "                if  str_key not in m_dict.keys():\n",
    "                    m_dict[str_key] = []\n",
    "                m_dict[str_key].append(list(sel_subj_stim_ev_coh['Pre_NodeStr'].ravel()[0]))\n",
    "\n",
    "                str_key = 'Post_NodeStr_{}'.format(coh_id)\n",
    "                if  str_key not in m_dict.keys():\n",
    "                    m_dict[str_key] = []\n",
    "                m_dict[str_key].append(list(sel_subj_stim_ev_coh['Post_NodeStr'].ravel()[0]))\n",
    "            \n",
    "    io.savemat('{}/Trajectory_Data.{}.mat'.format(path_ExpData, subj_id), mdict=m_dict)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "336px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "853px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "432px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "655px",
   "left": "1562.08px",
   "right": "20px",
   "top": "129px",
   "width": "340px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
