{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev1 toc-item\"><a href=\"#Load-meta-data\" data-toc-modified-id=\"Load-meta-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load meta data</a></div><div class=\"lev1 toc-item\"><a href=\"#Measure-Evoked-Topology\" data-toc-modified-id=\"Measure-Evoked-Topology-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Measure Evoked Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Define-network-measurements\" data-toc-modified-id=\"Define-network-measurements-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Define network measurements</a></div><div class=\"lev2 toc-item\"><a href=\"#Baseline-Topology\" data-toc-modified-id=\"Baseline-Topology-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Baseline Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Stim-Topology\" data-toc-modified-id=\"Stim-Topology-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Stim Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Pre-analysis-Data-Handling\" data-toc-modified-id=\"Pre-analysis-Data-Handling-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Pre-analysis Data Handling</a></div><div class=\"lev1 toc-item\"><a href=\"#Modulation-of-Network-Topology\" data-toc-modified-id=\"Modulation-of-Network-Topology-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modulation of Network Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Stimulation-to-Baseline\" data-toc-modified-id=\"Compare-Stimulation-to-Baseline-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Compare Stimulation to Baseline</a></div><div class=\"lev3 toc-item\"><a href=\"#Pre-Post-Coherence\" data-toc-modified-id=\"Pre-Post-Coherence-411\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Pre-Post Coherence</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Linear-Regression\" data-toc-modified-id=\"Plot-Linear-Regression-4111\"><span class=\"toc-item-num\">4.1.1.1&nbsp;&nbsp;</span>Plot Linear Regression</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-4112\"><span class=\"toc-item-num\">4.1.1.2&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Modes-of-Functional-Control\" data-toc-modified-id=\"Plot-Modes-of-Functional-Control-4113\"><span class=\"toc-item-num\">4.1.1.3&nbsp;&nbsp;</span>Plot Modes of Functional Control</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Stimulation-Energy-and-Location\" data-toc-modified-id=\"Compare-Stimulation-Energy-and-Location-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Compare Stimulation Energy and Location</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Stimulation-Energy-Grid\" data-toc-modified-id=\"Plot-Stimulation-Energy-Grid-421\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Plot Stimulation Energy Grid</a></div><div class=\"lev3 toc-item\"><a href=\"#Pre-Post-Coherence\" data-toc-modified-id=\"Pre-Post-Coherence-422\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Pre-Post Coherence</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Linear-Regression-for-Energy\" data-toc-modified-id=\"Plot-Linear-Regression-for-Energy-4221\"><span class=\"toc-item-num\">4.2.2.1&nbsp;&nbsp;</span>Plot Linear Regression for Energy</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Linear-Regression-for-Location\" data-toc-modified-id=\"Plot-Linear-Regression-for-Location-4222\"><span class=\"toc-item-num\">4.2.2.2&nbsp;&nbsp;</span>Plot Linear Regression for Location</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Stimulation-Locs-(MNI)\" data-toc-modified-id=\"Plot-Stimulation-Locs-(MNI)-4223\"><span class=\"toc-item-num\">4.2.2.3&nbsp;&nbsp;</span>Plot Stimulation Locs (MNI)</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Stimulation-to-Structural\" data-toc-modified-id=\"Compare-Stimulation-to-Structural-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Compare Stimulation to Structural</a></div><div class=\"lev3 toc-item\"><a href=\"#Pre-Post-Coherence\" data-toc-modified-id=\"Pre-Post-Coherence-431\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Pre-Post Coherence</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Linear-Regression-for-Location\" data-toc-modified-id=\"Plot-Linear-Regression-for-Location-432\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Plot Linear Regression for Location</a></div><div class=\"lev1 toc-item\"><a href=\"#Predicting-Node-Modulation\" data-toc-modified-id=\"Predicting-Node-Modulation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Predicting Node Modulation</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Stimulation-to-Baseline\" data-toc-modified-id=\"Compare-Stimulation-to-Baseline-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Compare Stimulation to Baseline</a></div><div class=\"lev3 toc-item\"><a href=\"#Baseline-Coherence-with-Evoked-Nodes\" data-toc-modified-id=\"Baseline-Coherence-with-Evoked-Nodes-511\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Baseline Coherence with Evoked Nodes</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-5111\"><span class=\"toc-item-num\">5.1.1.1&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Stimulation-to-Structural\" data-toc-modified-id=\"Compare-Stimulation-to-Structural-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Compare Stimulation to Structural</a></div><div class=\"lev3 toc-item\"><a href=\"#Structural-Connectivity-with-Evoked-Nodes\" data-toc-modified-id=\"Structural-Connectivity-with-Evoked-Nodes-521\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Structural Connectivity with Evoked Nodes</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-5211\"><span class=\"toc-item-num\">5.2.1.1&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev1 toc-item\"><a href=\"#Relating-Structural-Control-and-Structural-Topology\" data-toc-modified-id=\"Relating-Structural-Control-and-Structural-Topology-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Relating Structural Control and Structural Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Controllability-and-connectivity-of-stim-location\" data-toc-modified-id=\"Controllability-and-connectivity-of-stim-location-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Controllability and connectivity of stim location</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Linear-Regression\" data-toc-modified-id=\"Plot-Linear-Regression-611\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Plot Linear Regression</a></div><div class=\"lev1 toc-item\"><a href=\"#Modulation-Map\" data-toc-modified-id=\"Modulation-Map-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Modulation Map</a></div><div class=\"lev2 toc-item\"><a href=\"#Compute-the-map\" data-toc-modified-id=\"Compute-the-map-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Compute the map</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-the-Map\" data-toc-modified-id=\"Plot-the-Map-711\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Plot the Map</a></div><div class=\"lev1 toc-item\"><a href=\"#Behavioral-States\" data-toc-modified-id=\"Behavioral-States-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Behavioral States</a></div><div class=\"lev1 toc-item\"><a href=\"#Memory-Classifier-States\" data-toc-modified-id=\"Memory-Classifier-States-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Memory Classifier States</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Baseline-to-Memory-Classifier\" data-toc-modified-id=\"Compare-Baseline-to-Memory-Classifier-91\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Compare Baseline to Memory Classifier</a></div><div class=\"lev3 toc-item\"><a href=\"#Baseline-Node-Strength-with-Average-Memory-Classifier\" data-toc-modified-id=\"Baseline-Node-Strength-with-Average-Memory-Classifier-911\"><span class=\"toc-item-num\">9.1.1&nbsp;&nbsp;</span>Baseline Node Strength with Average Memory Classifier</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Comparative-Distributions\" data-toc-modified-id=\"Plot-Comparative-Distributions-9111\"><span class=\"toc-item-num\">9.1.1.1&nbsp;&nbsp;</span>Plot Comparative Distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Compare-Structural-Control-to-Memory-Classifier\" data-toc-modified-id=\"Compare-Structural-Control-to-Memory-Classifier-92\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Compare Structural Control to Memory Classifier</a></div><div class=\"lev3 toc-item\"><a href=\"#Controllability-with-Average-Memory-Classifier\" data-toc-modified-id=\"Controllability-with-Average-Memory-Classifier-921\"><span class=\"toc-item-num\">9.2.1&nbsp;&nbsp;</span>Controllability with Average Memory Classifier</a></div><div class=\"lev4 toc-item\"><a href=\"#Plot-Linear-Regression-for-Location\" data-toc-modified-id=\"Plot-Linear-Regression-for-Location-9211\"><span class=\"toc-item-num\">9.2.1.1&nbsp;&nbsp;</span>Plot Linear Regression for Location</a></div><div class=\"lev2 toc-item\"><a href=\"#Modal-Controllability-Distribution-(MNI)\" data-toc-modified-id=\"Modal-Controllability-Distribution-(MNI)-93\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Modal Controllability Distribution (MNI)</a></div><div class=\"lev1 toc-item\"><a href=\"#Artificial-Energy-Landscape\" data-toc-modified-id=\"Artificial-Energy-Landscape-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Artificial Energy Landscape</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "def write(txt):\n",
    "    sys.stdout.write(txt)\n",
    "    sys.stdout.flush()\n",
    "nb_stdout = sys.stdout    \n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import scipy.linalg as scialg\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import structural_control\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "rcParams.update(rcParams)\n",
    "\n",
    "path_CoreData = '/Users/akhambhati/Remotes/CORE.PS_Stim'\n",
    "path_PeriphData = '/Users/akhambhati/Remotes/RSRCH.PS_Stim'\n",
    "path_AtlasData = '/Users/akhambhati/Remotes/CORE.MRI_Atlases'\n",
    "\n",
    "path_Data = {'Input_Meta': {},\n",
    "             'Input_Stim': {},\n",
    "             'Input_Baseline': {},\n",
    "             'Output': {},\n",
    "             'Figure': {}}\n",
    "path_Data['Input_Meta'] = path_PeriphData + '/e00-Multimodal_Mapping'\n",
    "path_Data['Input_Stim'] = path_PeriphData + '/e02-FuncNetw.CommonAverage.Stim'\n",
    "path_Data['Input_Baseline'] = path_PeriphData + '/e02-FuncNetw.CommonAverage.Baseline'\n",
    "path_Data['Output'] = path_PeriphData + '/e02-GlobalTopo.CommonAverage'\n",
    "path_Data['Output'] = path_PeriphData + '/e02-GlobalTopo.CommonAverage'\n",
    "path_Data['Figure'] = './Figures-e02-GlobalTopo.CommonAverage'\n",
    "\n",
    "for path_type in path_Data.keys():\n",
    "    path = path_Data[path_type]\n",
    "    if not os.path.exists(path_Data[path_type]):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)\n",
    "            \n",
    "from sklearn.externals.joblib import Memory\n",
    "memory = Memory(cachedir=path_Data['Output'], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_dict = {}\n",
    "\n",
    "meta_dict['subject_list'] = np.load('{}/Meta.Electrode_Loc.npz'.format(path_Data['Input_Meta']))['subj_list']\n",
    "meta_dict['electrode_loc'] = np.load('{}/Meta.Electrode_Loc.npz'.format(path_Data['Input_Meta']))['channel_info'][()]\n",
    "meta_dict['atlas_info'] = np.load('{}/Meta.Electrode_Loc.npz'.format(path_Data['Input_Meta']))['lausanne_label_mni'][()]\n",
    "meta_dict['struct_adj'] = np.load('{}/Meta.Electrode_Loc.npz'.format(path_Data['Input_Meta']))['structadj_dict'][()]\n",
    "meta_dict['memory_info'] = pd.read_pickle('{}/Meta.Memory_Info.pkl'.format(path_Data['Input_Meta']))\n",
    "meta_dict['baseline_info'] = pd.read_pickle('{}/Meta.Baseline_Info.pkl'.format(path_Data['Input_Meta']))\n",
    "meta_dict['stim_info'] = pd.read_pickle('{}/Meta.Stim_Info.pkl'.format(path_Data['Input_Meta']))\n",
    "meta_dict['behavior_info'] = pd.read_pickle('{}/Meta.Behavior_Info.pkl'.format(path_Data['Input_Meta']))\n",
    "meta_dict['LTC_info'] = ['inferiortemporal', 'middletemporal', 'superiortemporal',\n",
    "                         'temporalpole', 'parahippocampal', 'entorhinal', 'lingual',\n",
    "                         'fusiform','transversetemporal', 'bankssts']\n",
    "\n",
    "meta_dict['coherence_info'] = ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']\n",
    "meta_dict['coherence_freq'] = ['5-15 Hz', '15-25 Hz', '30-40 Hz', '95-105 Hz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Evoked Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cohens_d(dist1, dist2):\n",
    "    m1 = np.mean(dist1)\n",
    "    m2 = np.mean(dist2)\n",
    "    s12 = np.std(np.concatenate((dist1, dist2)).reshape(-1))\n",
    "    return (m1-m2)/s12\n",
    "\n",
    "\n",
    "def measure_cfg_str(adj):\n",
    "    cfg_vec = convert_adj_matr_to_cfg_matr(np.expand_dims(adj, axis=0))[0, :]\n",
    "    cfg_mean = np.mean(cfg_vec)\n",
    "    cfg_var = np.var(cfg_vec)\n",
    "    return cfg_mean, cfg_var\n",
    "\n",
    "\n",
    "def measure_node_str(adj):\n",
    "    node_str = np.nanmean(adj, axis=0)\n",
    "    node_str_z = (node_str - np.nanmean(node_str)) / np.nanstd(node_str)    \n",
    "    return node_str, node_str_z\n",
    "\n",
    "\n",
    "def measure_node_str_delta(adj_pre, adj_post, n_perm=1000):\n",
    "    cfg_pre = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre, axis=0))[0, :]\n",
    "    cfg_post = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post, axis=0))[0, :]\n",
    "    cfg_delta = cfg_post - cfg_pre\n",
    "    \n",
    "    # True delta node_str\n",
    "    node_str_delta = measure_node_str(convert_conn_vec_to_adj_matr(cfg_delta))[0]\n",
    "    \n",
    "    # Permutation test for delta node_str\n",
    "    node_str_delta_null = np.array([\n",
    "        measure_node_str(\n",
    "            convert_conn_vec_to_adj_matr(\n",
    "                np.random.permutation(cfg_delta)))[0]\n",
    "        for p_ii in xrange(n_perm)])\n",
    "    node_str_delta_pv = np.mean(np.abs(node_str_delta_null) > np.abs(node_str_delta), axis=0)\n",
    "    \n",
    "    return node_str_delta, node_str_delta_pv\n",
    "\n",
    "\n",
    "def measure_cfg_sim(adj_pre, adj_post):\n",
    "    cfg_pre = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre, axis=0))[0, :]\n",
    "    cfg_post = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post, axis=0))[0, :]\n",
    "    cfg_sim = np.corrcoef(cfg_pre, cfg_post)[0, 1]\n",
    "    return cfg_sim\n",
    "\n",
    "\n",
    "def measure_dist_node_corr(node_str_del, dist, stim_ix):\n",
    "    dist_to_stim = np.mean(dist[stim_ix, :], axis=0)\n",
    "    dist_to_stim = np.delete(dist_to_stim, stim_ix)\n",
    "    rv, pv = stats.pearsonr(dist_to_stim, node_str_del)\n",
    "    \n",
    "    return rv, pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fdf['adj'][()]['LIHG3_LIHG4'][500][2]['Post_Stim_1']['Beta']\n",
    "# Structure of baseline files\n",
    "\n",
    "def generate_globaltopo_baseline(proc_id):\n",
    "    print(proc_id)\n",
    "    meta_base = meta_dict['baseline_info'].ix[proc_id]\n",
    "\n",
    "    subj_id = meta_base['Subject_ID']\n",
    "    base_id = meta_base['Base_ID'] \n",
    "    path_input_base = path_Data['Input_Baseline']    \n",
    "    prev_n_win = 60\n",
    "    \n",
    "    write('{}-{}\\n'.format(subj_id, base_id))\n",
    "    \n",
    "    data_table = {'Subject_ID': [],\n",
    "                  'Base_ID': [],\n",
    "                  'Coherence_ID': [],\n",
    "                  'Stim_Anode': [],\n",
    "                  'Stim_Cathode': [],\n",
    "                  'Stim_Duration': [],\n",
    "                  \n",
    "                  'Pre_Cfg_Str_Mean': [],\n",
    "                  'Pre_Cfg_Str_Var': [],\n",
    "                  'Post1_Cfg_Str_Mean': [],\n",
    "                  'Post1_Cfg_Str_Var': [],\n",
    "                  'Post2_Cfg_Str_Mean': [],\n",
    "                  'Post2_Cfg_Str_Var': [],\n",
    "                  \n",
    "                  'Pre_Node_Str': [],\n",
    "                  'Pre_Node_Str_Z': [],                  \n",
    "                  'Post1_Node_Str': [],\n",
    "                  'Post1_Node_Str_Z': [],                  \n",
    "                  'Post2_Node_Str': [],\n",
    "                  'Post2_Node_Str_Z': [],                  \n",
    "                  \n",
    "                  'Stim_Node_Str_Delta1': [],\n",
    "                  'Stim_Node_Str_Delta1_pv': [],\n",
    "                  'Stim_Node_Str_Delta2': [],\n",
    "                  'Stim_Node_Str_Delta2_pv': [],\n",
    "                                    \n",
    "                  'Stim_Cfg_Sim1': [],\n",
    "                  'Stim_Cfg_Sim2': [],   \n",
    "                  \n",
    "                  'Mean_Adj': []}\n",
    "    \n",
    "    # Load \n",
    "    df_base = np.load('{}/Adjacency.{}.Base_Event.{}.npz'.format(path_input_base, subj_id, base_id))\n",
    "\n",
    "    for stim_pair_tag in df_base['adj'][()].keys():\n",
    "        for stim_duration in df_base['adj'][()][stim_pair_tag].keys():\n",
    "            for ep_ii, ep in enumerate(df_base['adj'][()][stim_pair_tag][stim_duration][-prev_n_win:]):\n",
    "                for coh_id in meta_dict['coherence_info']:\n",
    "\n",
    "                    try:\n",
    "                        adj_pre = ep['Pre_Stim'][coh_id]\n",
    "                    except:\n",
    "                        continue\n",
    "                    N, N = adj_pre.shape\n",
    "\n",
    "                    try:\n",
    "                        adj_post1 = ep['Post_Stim_1'][coh_id]\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        adj_post2 = ep['Post_Stim_2'][coh_id]\n",
    "                    except:\n",
    "                        adj_post2 = np.nan*np.zeros((N, N))\n",
    "\n",
    "                    # Add to Data Table                      \n",
    "                    data_table['Subject_ID'].append(subj_id)\n",
    "                    data_table['Base_ID'].append(ep_ii)\n",
    "                    data_table['Coherence_ID'].append(coh_id)\n",
    "                    data_table['Stim_Anode'].append(stim_pair_tag.split('_')[0])\n",
    "                    data_table['Stim_Cathode'].append(stim_pair_tag.split('_')[1])\n",
    "                    data_table['Stim_Duration'].append(stim_duration)\n",
    "\n",
    "                    data_table['Pre_Cfg_Str_Mean'].append(measure_cfg_str(adj_pre)[0])\n",
    "                    data_table['Pre_Cfg_Str_Var'].append(measure_cfg_str(adj_pre)[1])\n",
    "                    data_table['Post1_Cfg_Str_Mean'].append(measure_cfg_str(adj_post1)[0])\n",
    "                    data_table['Post1_Cfg_Str_Var'].append(measure_cfg_str(adj_post1)[1])\n",
    "                    data_table['Post2_Cfg_Str_Mean'].append(measure_cfg_str(adj_post2)[0])\n",
    "                    data_table['Post2_Cfg_Str_Var'].append(measure_cfg_str(adj_post2)[1])\n",
    "\n",
    "                    data_table['Pre_Node_Str'].append(measure_node_str(adj_pre)[0])\n",
    "                    data_table['Pre_Node_Str_Z'].append(measure_node_str(adj_pre)[1]) \n",
    "                    data_table['Post1_Node_Str'].append(measure_node_str(adj_post1)[0])\n",
    "                    data_table['Post1_Node_Str_Z'].append(measure_node_str(adj_post1)[1]) \n",
    "                    data_table['Post2_Node_Str'].append(measure_node_str(adj_post2)[0])\n",
    "                    data_table['Post2_Node_Str_Z'].append(measure_node_str(adj_post2)[1])\n",
    "\n",
    "                    ns_del = measure_node_str_delta(adj_pre, adj_post1)\n",
    "                    data_table['Stim_Node_Str_Delta1'].append(ns_del[0])\n",
    "                    data_table['Stim_Node_Str_Delta1_pv'].append(ns_del[1])                        \n",
    "\n",
    "                    ns_del = measure_node_str_delta(adj_pre, adj_post2)\n",
    "                    data_table['Stim_Node_Str_Delta2'].append(ns_del[0])\n",
    "                    data_table['Stim_Node_Str_Delta2_pv'].append(ns_del[1])                        \n",
    "\n",
    "                    cfg_sim = measure_cfg_sim(adj_pre, adj_post1)\n",
    "                    data_table['Stim_Cfg_Sim1'].append(cfg_sim)\n",
    "\n",
    "                    cfg_sim = measure_cfg_sim(adj_pre, adj_post2)\n",
    "                    data_table['Stim_Cfg_Sim2'].append(cfg_sim)\n",
    "\n",
    "                    data_table['Mean_Adj'].append(adj_pre)                        \n",
    "\n",
    "    globaltopo_base = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    return globaltopo_base\n",
    "\n",
    "################################\n",
    "output_path = '{}/GlobalTopo.Baseline.pkl'.format(path_Data['Output'])\n",
    "if not os.path.exists(output_path):\n",
    "    sys.stdout = open('{}/GlobalTopo.Baseline.ProcJob'.format(path_Data['Output']), 'w')    \n",
    "    write('Mapping jobs...\\n')\n",
    "    \n",
    "    args_list = range(len(meta_dict['baseline_info']))\n",
    "    res = map(generate_globaltopo_baseline, args_list)\n",
    "    #pool = Pool(7)\n",
    "    #res = pool.map(generate_globaltopo_baseline, args_list)\n",
    "\n",
    "\n",
    "    write('\\nReducing jobs...\\n')\n",
    "    df_globaltopo_base = pd.concat(res, ignore_index=True)\n",
    "    df_globaltopo_base.to_pickle(output_path)\n",
    "    sys.stdout = nb_stdout\n",
    "else:\n",
    "    df_globaltopo_base = pd.read_pickle(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_globaltopo_stim(proc_id):\n",
    "    meta_stim = meta_dict['stim_info'].ix[proc_id]\n",
    "    \n",
    "    subj_id = meta_stim['Subject_ID']\n",
    "    event_id = meta_stim['Event_ID']    \n",
    "    path_input_stim = path_Data['Input_Stim']\n",
    "    \n",
    "    write('{}-{}\\n'.format(subj_id, event_id))    \n",
    "    \n",
    "    data_table = {'Subject_ID': [],\n",
    "                  'Event_ID': [],\n",
    "                  'Coherence_ID': [],\n",
    "                  \n",
    "                  'Pre_Cfg_Str_Mean': [],\n",
    "                  'Pre_Cfg_Str_Var': [],\n",
    "                  'Post1_Cfg_Str_Mean': [],\n",
    "                  'Post1_Cfg_Str_Var': [],\n",
    "                  'Post2_Cfg_Str_Mean': [],\n",
    "                  'Post2_Cfg_Str_Var': [],\n",
    "                  \n",
    "                  'Pre_Node_Str': [],\n",
    "                  'Pre_Node_Str_Z': [],                  \n",
    "                  'Post1_Node_Str': [],\n",
    "                  'Post1_Node_Str_Z': [],                  \n",
    "                  'Post2_Node_Str': [],\n",
    "                  'Post2_Node_Str_Z': [],                  \n",
    "                  \n",
    "                  'Stim_Node_Str_Delta1': [],\n",
    "                  'Stim_Node_Str_Delta1_pv': [],\n",
    "                  'Stim_Node_Str_Delta2': [],\n",
    "                  'Stim_Node_Str_Delta2_pv': [],\n",
    "                                    \n",
    "                  'Stim_Cfg_Sim1': [],\n",
    "                  'Stim_Cfg_Sim2': []}\n",
    "    \n",
    "    # Load\n",
    "    try:\n",
    "        df_stim = np.load('{}/Adjacency.{}.Stim_Event.{}.npz'.format(path_input_stim, subj_id, event_id))\n",
    "    except IOError:\n",
    "        globaltopo_stim = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "        return globaltopo_stim\n",
    "    \n",
    "    for coh_id in meta_dict['coherence_info']:\n",
    "\n",
    "        try:\n",
    "            adj_pre = df_stim['adj'][()]['Pre_Stim'][coh_id]\n",
    "        except:\n",
    "            continue\n",
    "        N, N = adj_pre.shape\n",
    "\n",
    "        try:\n",
    "            adj_post1 = df_stim['adj'][()]['Post_Stim_1'][coh_id]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            adj_post2 = df_stim['adj'][()]['Post_Stim_2'][coh_id]\n",
    "        except:\n",
    "            adj_post2 = np.nan*np.zeros((N, N))\n",
    "\n",
    "        # Add to Data Table                      \n",
    "        data_table['Subject_ID'].append(subj_id)\n",
    "        data_table['Event_ID'].append(event_id)\n",
    "        data_table['Coherence_ID'].append(coh_id)\n",
    "\n",
    "        data_table['Pre_Cfg_Str_Mean'].append(measure_cfg_str(adj_pre)[0])\n",
    "        data_table['Pre_Cfg_Str_Var'].append(measure_cfg_str(adj_pre)[1])\n",
    "        data_table['Post1_Cfg_Str_Mean'].append(measure_cfg_str(adj_post1)[0])\n",
    "        data_table['Post1_Cfg_Str_Var'].append(measure_cfg_str(adj_post1)[1])\n",
    "        data_table['Post2_Cfg_Str_Mean'].append(measure_cfg_str(adj_post2)[0])\n",
    "        data_table['Post2_Cfg_Str_Var'].append(measure_cfg_str(adj_post2)[1])\n",
    "\n",
    "        data_table['Pre_Node_Str'].append(measure_node_str(adj_pre)[0])\n",
    "        data_table['Pre_Node_Str_Z'].append(measure_node_str(adj_pre)[1]) \n",
    "        data_table['Post1_Node_Str'].append(measure_node_str(adj_post1)[0])\n",
    "        data_table['Post1_Node_Str_Z'].append(measure_node_str(adj_post1)[1]) \n",
    "        data_table['Post2_Node_Str'].append(measure_node_str(adj_post2)[0])\n",
    "        data_table['Post2_Node_Str_Z'].append(measure_node_str(adj_post2)[1])\n",
    "\n",
    "        ns_del = measure_node_str_delta(adj_pre, adj_post1)\n",
    "        data_table['Stim_Node_Str_Delta1'].append(ns_del[0])\n",
    "        data_table['Stim_Node_Str_Delta1_pv'].append(ns_del[1])                        \n",
    "\n",
    "        ns_del = measure_node_str_delta(adj_pre, adj_post2)\n",
    "        data_table['Stim_Node_Str_Delta2'].append(ns_del[0])\n",
    "        data_table['Stim_Node_Str_Delta2_pv'].append(ns_del[1])                        \n",
    "\n",
    "        cfg_sim = measure_cfg_sim(adj_pre, adj_post1)\n",
    "        data_table['Stim_Cfg_Sim1'].append(cfg_sim)\n",
    "\n",
    "        cfg_sim = measure_cfg_sim(adj_pre, adj_post2)\n",
    "        data_table['Stim_Cfg_Sim2'].append(cfg_sim)                     \n",
    "            \n",
    "    globaltopo_stim = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    return globaltopo_stim\n",
    "\n",
    "################################\n",
    "output_path = '{}/GlobalTopo.Stimulation.pkl'.format(path_Data['Output'])\n",
    "if not os.path.exists(output_path):\n",
    "    sys.stdout = open('{}/GlobalTopo.Stimulation.ProcJob'.format(path_Data['Output']), 'w')\n",
    "    write('Mapping jobs...\\n')\n",
    "\n",
    "    args_list = range(len(meta_dict['stim_info']))\n",
    "    pool = Pool(7)\n",
    "    res = pool.map(generate_globaltopo_stim, args_list)\n",
    "    \n",
    "    write('\\nReducing jobs...\\n')\n",
    "    df_globaltopo_stim = pd.concat(res, ignore_index=True)\n",
    "    df_globaltopo_stim.to_pickle(output_path)\n",
    "    write('Done.\\n')\n",
    "    sys.stdout = nb_stdout\n",
    "else:\n",
    "    df_globaltopo_stim = pd.read_pickle(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-analysis Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First merge df_globaltopo_stim with meta_ps\n",
    "df_globaltopo_stim = pd.merge(meta_dict['stim_info'],\n",
    "                              df_globaltopo_stim,                              \n",
    "                              on=['Subject_ID', 'Event_ID'])\n",
    "\n",
    "# Get common subjects\n",
    "common_subject_list = np.intersect1d(np.unique(df_globaltopo_base['Subject_ID']),\n",
    "                                     np.unique(df_globaltopo_stim['Subject_ID']))\n",
    "df_globaltopo_stim = df_globaltopo_stim.loc[df_globaltopo_stim.Subject_ID.isin(common_subject_list)]\n",
    "df_globaltopo_base = df_globaltopo_base.loc[df_globaltopo_base.Subject_ID.isin(common_subject_list)]\n",
    "\n",
    "# Make sure Base and Stim have common column names\n",
    "df_globaltopo_base = df_globaltopo_base.rename(\n",
    "    columns={'Stim_Duration': 'Stim_Dur'})\n",
    "print('Common Column Fields')\n",
    "common_cols = list(np.intersect1d(df_globaltopo_base.keys(),\n",
    "                                  df_globaltopo_stim.keys()))\n",
    "print(common_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulation of Network Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stimulation to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key = ['Subject_ID', 'Stim_Anode', 'Stim_Cathode', 'Stim_Dur',\n",
    "                   'Coherence_ID']\n",
    "\n",
    "df_stim_sel = df_globaltopo_stim.loc[df_globaltopo_stim.Stim_Type == 'stimulating']\n",
    "df_stim_sel = df_stim_sel.groupby(unique_stim_key).indices\n",
    "df_base_sel = df_globaltopo_base.groupby(unique_stim_key).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Post Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def compute_prepost_coherence(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    if cfg_measure in ['Cfg_Sim', 'Node_Str_Delta']:\n",
    "        vals = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 1)),\n",
    "                'sham': np.nan*np.zeros((len(meta_sham_lut), len(meta_dict['coherence_info']), 1)),\n",
    "                'base': np.nan*np.zeros((len(meta_base_lut), len(meta_dict['coherence_info']), 1))}\n",
    "    else:     \n",
    "        vals = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 2)),\n",
    "                'sham': np.nan*np.zeros((len(meta_sham_lut), len(meta_dict['coherence_info']), 2)),\n",
    "                'base': np.nan*np.zeros((len(meta_base_lut), len(meta_dict['coherence_info']), 2))}\n",
    "    luts = {'stim': meta_stim_lut,\n",
    "            'sham': meta_sham_lut,\n",
    "            'base': meta_base_lut}\n",
    "    \n",
    "    for tp in vals.keys():\n",
    "        tp_vals = vals[tp]\n",
    "        meta_lut = luts[tp]\n",
    "        \n",
    "        if tp in ['stim', 'sham']:\n",
    "            sel_globaltopo = df_globaltopo_stim\n",
    "        else:\n",
    "            sel_globaltopo = df_globaltopo_base\n",
    "    \n",
    "        # Iterate over coherence\n",
    "        for c_ii, coh_id in enumerate(meta_dict['coherence_info']):\n",
    "            sel_coh = sel_globaltopo[sel_globaltopo['Coherence_ID'] == coh_id]\n",
    "\n",
    "            # Iterate over unique stim parameters\n",
    "            for s_ii, (meta_key, ev_ids) in enumerate(meta_lut.iteritems()):\n",
    "                if tp in ['stim', 'sham']:\n",
    "                    key_dict = dict(zip(unique_stim_key, [meta_key]))\n",
    "                    sel_key_subj = sel_coh.loc[sel_coh.Subject_ID == key_dict['Subject_ID']]\n",
    "                    sel_key_ev = sel_key_subj.loc[sel_key_subj.Event_ID.isin(ev_ids)]\n",
    "                    \n",
    "                    if cfg_measure == 'Cfg_Sim':\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nanmean(sel_key_ev['Stim_' + cfg_measure])\n",
    "                    elif cfg_measure == 'Node_Str_Delta':\n",
    "                        delta_pv = sel_key_ev['Stim_' + cfg_measure + '_pv']\n",
    "                        evoked_node_cnt = np.mean([np.mean(ev < (0.05/len(ev)))\n",
    "                                                   for ev in delta_pv])\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nan_to_num(evoked_node_cnt)\n",
    "                    else:\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nanmean(sel_key_ev['Pre_' + cfg_measure])\n",
    "                        tp_vals[s_ii, c_ii, 1] = np.nanmean(sel_key_ev['Post_' + cfg_measure])\n",
    "                else:\n",
    "                    key_dict = dict(zip(unique_stim_key, [meta_key]))\n",
    "                    sel_key_subj = sel_coh.loc[sel_coh.Subject_ID == key_dict['Subject_ID']]\n",
    "                    sel_key_ev = sel_key_subj.loc[sel_key_subj.Base_ID.isin(ev_ids)]\n",
    "                    \n",
    "                    if cfg_measure == 'Cfg_Sim':\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nanmean(sel_key_ev['Base_' + cfg_measure].iloc[0][0::2])\n",
    "                    elif cfg_measure == 'Node_Str_Delta':\n",
    "                        delta_pv = sel_key_ev['Base_' + cfg_measure + '_pv'].iloc[0][0::2, :]\n",
    "                        evoked_node_cnt = np.mean([np.mean(ev < (0.05/len(ev)))\n",
    "                                                   for ev in delta_pv])\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nan_to_num(evoked_node_cnt)\n",
    "                    else:\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nanmean(sel_key_ev['Base_' + cfg_measure].iloc[0][0::2])\n",
    "                        tp_vals[s_ii, c_ii, 1] = np.nanmean(sel_key_ev['Base_' + cfg_measure].iloc[0][1::2])\n",
    "    \n",
    "        # Remove invalid observations\n",
    "        tp_vals = tp_vals[np.unique(np.nonzero(~np.isnan(tp_vals))[0]), :, :]\n",
    "        \n",
    "        vals[tp] = tp_vals\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean': {'xlabel': 'Pre-Stim Mean Coherence',\n",
    "                             'ylabel': 'Post_Stim Mean Coherence',\n",
    "                             'xlim': [0.0, 1.0],\n",
    "                             'ylim': [0.0, 1.0],\n",
    "                             'stim': {'color': [1.0, 0.3, 0.3]},\n",
    "                             'sham': {'color': [0.2, 0.2, 0.2]},\n",
    "                             'base': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Cfg_Str_Var':  {'xlabel': 'Pre-Stim Var Coherence',\n",
    "                             'ylabel': 'Post_Stim Var Coherence',\n",
    "                             'xlim': [0.0, 1e-1],\n",
    "                             'ylim': [0.0, 1e-1],                             \n",
    "                             'stim': {'color': [1.0, 0.3, 0.3]},\n",
    "                             'sham': {'color': [0.2, 0.2, 0.2]},\n",
    "                             'base': {'color': [0.2, 0.2, 0.2]}}}\n",
    "            \n",
    "for meas in analysis.keys():\n",
    "    prepost_meas_coh = compute_prepost_coherence(meas)\n",
    "    \n",
    "    plt.figure(figsize=(1,4), dpi=300.0)\n",
    "    for ii in xrange(len(meta_dict['coherence_info'])):\n",
    "        write('{}-{}\\n'.format(meas, meta_dict['coherence_info'][ii]))\n",
    "        \n",
    "        ax = plt.subplot(4,1,ii+1)\n",
    "        ax.set_xlim(analysis[meas]['xlim'])\n",
    "        ax.set_ylim(analysis[meas]['ylim'])\n",
    "        ax.set_title(meta_dict['coherence_freq'][ii])\n",
    "        if ii == 3:\n",
    "            ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "        if ii == 1:\n",
    "            ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "        ax.locator_params(nbins=3, axis='both')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "        for tp in ['stim', 'base']: #prepost_meas_coh.keys():\n",
    "            vals = prepost_meas_coh[tp]\n",
    "            ax = sns.regplot(x=vals[:,ii,0], y=vals[:,ii,1],\n",
    "                             color=analysis[meas][tp]['color'],\n",
    "                             scatter_kws={'s':1.0}, ci=68, ax=ax)\n",
    "            \n",
    "            slp, yint, rv, pv, stdr = stats.linregress(vals[:,ii,0],\n",
    "                                                       vals[:,ii,1])\n",
    "            write('{}: rv={:2.2f}, pv={:2.2e}\\n'.format(tp, rv, pv))\n",
    "        write('\\n')\n",
    "    write('\\n\\n')\n",
    "    plt.savefig('{}/Pre_Post-{}.LinReg.svg'.format(path_Data['Figure'][reref], meas))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean':     {'xlabel': 'Frequency Range',\n",
    "                                 'ylabel': 'Delta Mean Coherence',\n",
    "                                 'xlim': [-0.5, len(meta_dict['coherence_info'])-0.5],\n",
    "                                 'ylim': [-0.05, 0.05],\n",
    "                                 'stim': {'color': [1.0, 0.3, 0.3]},\n",
    "                                 'sham': {'color': [0.2, 0.2, 0.2]},\n",
    "                                 'base': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Cfg_Str_Var':      {'xlabel': 'Frequency Range',\n",
    "                                 'ylabel': 'Delta Var Coherence',\n",
    "                                 'xlim': [-0.5, len(meta_dict['coherence_info'])-0.5],\n",
    "                                 'ylim': [-0.005, 0.005],                             \n",
    "                                 'stim': {'color': [1.0, 0.3, 0.3]},\n",
    "                                 'sham': {'color': [0.2, 0.2, 0.2]},\n",
    "                                 'base': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Cfg_Sim':          {'xlabel': 'Frequency Range',\n",
    "                                 'ylabel': 'Edge Correlation (r-to-z)',\n",
    "                                 'xlim': [-0.5, len(meta_dict['coherence_info'])-0.5],\n",
    "                                 'ylim': [0.0, 0.6001],                             \n",
    "                                 'stim': {'color': [1.0, 0.3, 0.3]},\n",
    "                                 'sham': {'color': [0.2, 0.2, 0.2]},\n",
    "                                 'base': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Node_Str_Delta':   {'xlabel': 'Frequency Range',\n",
    "                                 'ylabel': 'Fraction of Nodes Evoked',\n",
    "                                 'xlim': [-0.5, len(meta_dict['coherence_info'])-0.5],\n",
    "                                 'ylim': [0.0, 0.4],                             \n",
    "                                 'stim': {'color': [1.0, 0.3, 0.3]},\n",
    "                                 'sham': {'color': [0.2, 0.2, 0.2]},\n",
    "                                 'base': {'color': [0.2, 0.2, 0.2]}}}\n",
    "n_grp = len(meta_dict['coherence_freq'])            \n",
    "\n",
    "for meas in analysis.keys():\n",
    "    write('{}\\n'.format(meas))\n",
    "    prepost_meas_coh = compute_prepost_coherence(meas)\n",
    "        \n",
    "    all_delta = []\n",
    "    all_mean = []\n",
    "    all_serr = []\n",
    "    all_color = []\n",
    "    all_pos = []\n",
    "    for tp_ii, tp in enumerate(['stim', 'base']):\n",
    "        if meas =='Cfg_Sim':\n",
    "            delta = np.arctanh(np.nan_to_num(prepost_meas_coh[tp][:,:,0]))\n",
    "        elif meas == 'Node_Str_Delta': \n",
    "            delta = np.nan_to_num(prepost_meas_coh[tp][:,:,0])            \n",
    "        else:\n",
    "            delta = prepost_meas_coh[tp][:,:,1]-prepost_meas_coh[tp][:,:,0]\n",
    "        all_delta.append(delta)\n",
    "        for nn in xrange(delta.shape[1]):\n",
    "            all_mean.append(np.nanmean(delta[:, nn]))\n",
    "            all_serr.append(np.nanstd(delta[:, nn]) / np.sqrt(delta.shape[0]))\n",
    "            all_color.append(analysis[meas][tp]['color'])\n",
    "            all_pos.append(nn + 0.2*tp_ii)\n",
    "        \n",
    "    plt.figure(figsize=(2,1.5), dpi=300.0)\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    ax.bar(left=all_pos, height=all_mean, yerr=all_serr,\n",
    "           width=0.2, color=all_color, lw=0.0)\n",
    "    \n",
    "    ax.set_xlim(analysis[meas]['xlim'])\n",
    "    ax.set_ylim(analysis[meas]['ylim'])\n",
    "    ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "    ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "    ax.xaxis.set_ticks(np.arange(n_grp)+0.2)\n",
    "    ax.xaxis.set_ticklabels(meta_dict['coherence_freq']) \n",
    "    if meas == 'Cfg_Sim':\n",
    "        ax.locator_params(nbins=4, axis='y')    \n",
    "    else:\n",
    "        ax.locator_params(nbins=3, axis='y')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    plt.savefig('{}/Delta-{}.BarPlot.svg'.format(path_Data['Figure'][reref], meas))\n",
    "    plt.close()\n",
    "    \n",
    "    for ff in xrange(len(meta_dict['coherence_freq'])):\n",
    "        write('{}\\n'.format(meta_dict['coherence_freq'][ff]))\n",
    "        write('df: {}\\n'.format(len(all_delta[0][:, ff])))\n",
    "        write('t-test: {}\\n'.format(stats.ttest_rel(all_delta[0][:, ff], all_delta[1][:, ff])))\n",
    "        write('cohens: {}\\n\\n'.format(cohens_d(all_delta[0][:, ff], all_delta[1][:, ff])))\n",
    "    write('Anova: {}\\n'.format(stats.f_oneway(*all_delta[0].T)))\n",
    "    write('Anova: {}\\n'.format(stats.f_oneway(*all_delta[1].T))) \n",
    "    write('t-test: {}\\n'.format(stats.ttest_rel(all_delta[0].mean(axis=1), all_delta[1].mean(axis=1))))\n",
    "    write('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Modes of Functional Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Sim':          {'xlabel': 'Edge Correlation (r-to-z)',\n",
    "                                 'xlim': [0.0, 1.2],\n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Node_Str_Delta':   {'ylabel': 'Fraction of Nodes Evoked',\n",
    "                                 'ylim': [0.0, 0.601],                             \n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}}}\n",
    "n_grp = len(meta_dict['coherence_freq'])            \n",
    "        \n",
    "measures = {}\n",
    "for meas in analysis.keys():\n",
    "    measures[meas] = compute_prepost_coherence(meas)\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(1,4), dpi=300.0)\n",
    "for ii in xrange(len(meta_dict['coherence_info'])):\n",
    "    write('{}-{}\\n'.format(meas, meta_dict['coherence_info'][ii]))\n",
    "\n",
    "    ax = plt.subplot(4,1,ii+1)\n",
    "    ax.set_xlim(analysis['Cfg_Sim']['xlim'])\n",
    "    ax.set_ylim(analysis['Node_Str_Delta']['ylim'])\n",
    "    ax.set_title(meta_dict['coherence_freq'][ii])\n",
    "    if ii == 3:\n",
    "        ax.set_xlabel(analysis['Cfg_Sim']['xlabel'])\n",
    "    if ii == 1:\n",
    "        ax.set_ylabel(analysis['Node_Str_Delta']['ylabel'])\n",
    "    ax.locator_params(nbins=3, axis='x')        \n",
    "    ax.locator_params(nbins=4, axis='y')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    for tp_ii, tp in enumerate(['stim']):\n",
    "        vals_cfg_sim = np.arctanh(measures['Cfg_Sim'][tp][:, ii, 0])\n",
    "        vals_node_str_delta = measures['Node_Str_Delta'][tp][:, ii, 0]     \n",
    "        ax = sns.regplot(x=vals_cfg_sim, y=vals_node_str_delta,\n",
    "                         color=analysis['Cfg_Sim'][tp]['color'],\n",
    "                         scatter_kws={'s':1.0}, ci=68, ax=ax)\n",
    "\n",
    "        slp, yint, rv, pv, stdr = stats.linregress(vals_cfg_sim,\n",
    "                                                   vals_node_str_delta)\n",
    "        write('{}: rv={:2.2f}, pv={:2.2e}\\n'.format(tp, rv, pv))\n",
    "    write('\\n')\n",
    "plt.savefig('{}/Cfg_Sim-Node_Str_Delta.LinReg.svg'.format(path_Data['Figure'][reref], meas))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(2,2), dpi=300.0)\n",
    "write('{}-{}\\n'.format(meas, 'All Freqs'))\n",
    "ax = plt.subplot(111)\n",
    "ax.set_xlim([0.0, 0.701])\n",
    "ax.set_ylim([0.0, 0.4])\n",
    "ax.set_xlabel(analysis['Cfg_Sim']['xlabel'])\n",
    "ax.set_ylabel(analysis['Node_Str_Delta']['ylabel'])\n",
    "ax.locator_params(nbins=4, axis='x')        \n",
    "ax.locator_params(nbins=4, axis='y')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "vals_cfg_sim = np.arctanh(measures['Cfg_Sim']['stim']).mean(axis=1).ravel()\n",
    "vals_node_str_delta = measures['Node_Str_Delta']['stim'].mean(axis=1).ravel()\n",
    "\n",
    "ax = sns.regplot(x=vals_cfg_sim, y=vals_node_str_delta,\n",
    "                 color=analysis['Cfg_Sim'][tp]['color'],\n",
    "                 scatter_kws={'s':1.0}, ci=68, ax=ax)\n",
    "\n",
    "slp, yint, rv, pv, stdr = stats.linregress(vals_cfg_sim,\n",
    "                                           vals_node_str_delta)\n",
    "write('{}: rv={:2.2f}, pv={:2.2e}\\n'.format('stim', rv, pv))\n",
    "write('\\n')\n",
    "plt.savefig('{}/Cfg_Sim-Node_Str_Delta-All_Freq.LinReg.svg'.format(path_Data['Figure'][reref], meas))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stimulation Energy and Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key =['Subject_ID',\n",
    "                  'Stim_Freq',\n",
    "                  'Stim_Amp',\n",
    "                  'Stim_Dur',\n",
    "                  'Stim_Anode',\n",
    "                  'Stim_Cathode']\n",
    "meta_stim_type = meta_ps.loc[meta_ps.Stim_Type == 'stimulating']\n",
    "meta_sham_type = meta_ps.loc[meta_ps.Stim_Type == 'sham']\n",
    "\n",
    "meta_stim_lut = meta_stim_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_sham_lut = meta_sham_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_base_lut = meta_base.groupby(['Subject_ID'])['Base_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Stimulation Energy Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Required import for following computations.\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.pyplot import figure, show\n",
    "\n",
    "\n",
    "def quad(plane='xy', origin=None, width=1, height=1, depth=0):\n",
    "    u, v = (0, 0) if origin is None else origin\n",
    "\n",
    "    plane = plane.lower()\n",
    "    if plane == 'xy':\n",
    "        vertices = ((u, v, depth),\n",
    "                    (u + width, v, depth),\n",
    "                    (u + width, v + height, depth),\n",
    "                    (u, v + height, depth))\n",
    "    elif plane == 'xz':\n",
    "        vertices = ((u, depth, v),\n",
    "                    (u + width, depth, v),\n",
    "                    (u + width, depth, v + height),\n",
    "                    (u, depth, v + height))\n",
    "    elif plane == 'yz':\n",
    "        vertices = ((depth, u, v),\n",
    "                    (depth, u + width, v),\n",
    "                    (depth, u + width, v + height),\n",
    "                    (depth, u, v + height))\n",
    "    else:\n",
    "        raise ValueError('\"{0}\" is not a supported plane!'.format(plane))\n",
    "\n",
    "    return np.array(vertices)\n",
    "\n",
    "\n",
    "def grid(plane='xy',\n",
    "         origin=None,\n",
    "         width=1,\n",
    "         height=1,\n",
    "         depth=0,\n",
    "         width_segments=1,\n",
    "         height_segments=1):\n",
    "    u, v = (0, 0) if origin is None else origin\n",
    "\n",
    "    w_x, h_y = width / width_segments, height / height_segments\n",
    "\n",
    "    quads = []\n",
    "    for i in range(width_segments):\n",
    "        for j in range(height_segments):\n",
    "            quads.append(\n",
    "                quad(plane, (i * w_x + u, j * h_y + v), w_x, h_y, depth))\n",
    "\n",
    "    return np.array(quads)\n",
    "\n",
    "\n",
    "def cube(plane=None,\n",
    "         origin=None,\n",
    "         width=1,\n",
    "         height=1,\n",
    "         depth=1,\n",
    "         width_segments=1,\n",
    "         height_segments=1,\n",
    "         depth_segments=1):\n",
    "    plane = (('+x', '-x', '+y', '-y', '+z', '-z')\n",
    "             if plane is None else\n",
    "             [p.lower() for p in plane])\n",
    "    u, v, w = (0, 0, 0) if origin is None else origin\n",
    "\n",
    "    w_s, h_s, d_s = width_segments, height_segments, depth_segments\n",
    "\n",
    "    grids = []\n",
    "    if '-z' in plane:\n",
    "        grids.extend(grid('xy', (u, w), width, depth, v, w_s, d_s))\n",
    "    if '+z' in plane:\n",
    "        grids.extend(grid('xy', (u, w), width, depth, v + height, w_s, d_s))\n",
    "\n",
    "    if '-y' in plane:\n",
    "        grids.extend(grid('xz', (u, v), width, height, w, w_s, h_s))\n",
    "    if '+y' in plane:\n",
    "        grids.extend(grid('xz', (u, v), width, height, w + depth, w_s, h_s))\n",
    "\n",
    "    if '-x' in plane:\n",
    "        grids.extend(grid('yz', (w, v), depth, height, u, d_s, h_s))\n",
    "    if '+x' in plane:\n",
    "        grids.extend(grid('yz', (w, v), depth, height, u + width, d_s, h_s))\n",
    "\n",
    "    return np.array(grids)\n",
    "\n",
    "\n",
    "stim_amp = np.sort(meta_ps['Stim_Amp'].unique())[1:] / 1000.\n",
    "stim_freq = np.sort(meta_ps['Stim_Freq'].unique())[1:]\n",
    "stim_dur = np.sort(meta_ps['Stim_Dur'].unique()) / 1000.\n",
    "\n",
    "n_amp = len(stim_amp)\n",
    "n_freq = len(stim_freq)\n",
    "n_dur = len(stim_dur)\n",
    "\n",
    "canvas = figure(figsize=(6,6), dpi=300.0)\n",
    "axes = Axes3D(canvas)\n",
    "quads = cube(width=stim_amp.max(), width_segments=n_amp,\n",
    "             height=stim_freq.max(), height_segments=n_freq,\n",
    "             depth=stim_dur.max(), depth_segments=n_dur)\n",
    "\n",
    "# define the colormap\n",
    "cmap = plt.get_cmap('magma')\n",
    "max_vals = stim_amp.max()*stim_freq.max()*stim_dur.max()\n",
    "vals = np.max(quads, axis=-2)\n",
    "vals = vals[:,0] * vals[:,1] * vals[:,2]\n",
    "\n",
    "\n",
    "# You can replace the following line by whatever suits you. Here, we compute\n",
    "# each quad colour by averaging its vertices positions.\n",
    "RGB = cmap(vals / max_vals)[:, :3]\n",
    "RGBA = np.hstack((RGB, np.full((RGB.shape[0], 1), .75)))\n",
    "\n",
    "collection = Poly3DCollection(quads, linewidths=0.0)\n",
    "collection.set_color(RGBA)\n",
    "axes.add_collection3d(collection)\n",
    "axes.set_xlim([0, stim_amp.max()])\n",
    "axes.set_ylim([0, stim_dur.max()])\n",
    "axes.set_zlim([0, stim_freq.max()])\n",
    "axes.view_init(azim=45)\n",
    "\n",
    "plt.savefig('{}/Stim_Energy.Cubed.svg'.format(path_Data['Figure'][reref]))\n",
    "\n",
    "show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Post Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def compute_prepost_coherence_stimparam(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    if cfg_measure == 'Cfg_Sim':\n",
    "        vals = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 1))}\n",
    "    else:     \n",
    "        vals = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 2))}\n",
    "    energy = {'stim': np.nan*np.zeros(len(meta_stim_lut))}\n",
    "    mni_coords = {'stim': np.nan*np.zeros((len(meta_stim_lut), 3))}    \n",
    "    location = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 1))}\n",
    "    luts = {'stim': meta_stim_lut}\n",
    "    \n",
    "    for tp in vals.keys():\n",
    "        tp_vals = vals[tp]\n",
    "        meta_lut = luts[tp]\n",
    "        stim_energy = energy[tp]\n",
    "        stim_location = location[tp]\n",
    "        stim_mni = mni_coords[tp]\n",
    "        \n",
    "        sel_globaltopo = df_globaltopo_stim\n",
    "    \n",
    "        # Iterate over coherence\n",
    "        for c_ii, coh_id in enumerate(meta_dict['coherence_info']):\n",
    "            sel_coh = sel_globaltopo[sel_globaltopo['Coherence_ID'] == coh_id]\n",
    "            sel_coh_base = df_globaltopo_base[df_globaltopo_base['Coherence_ID'] == coh_id]\n",
    "\n",
    "            # Iterate over unique stim parameters\n",
    "            for s_ii, (meta_key, ev_ids) in enumerate(meta_lut.iteritems()):\n",
    "                if tp in ['stim']:\n",
    "                    key_dict = dict(zip(unique_stim_key, meta_key))\n",
    "                    sel_key_subj = sel_coh.loc[sel_coh.Subject_ID == key_dict['Subject_ID']]\n",
    "                    sel_key_ev = sel_key_subj.loc[sel_key_subj.Event_ID.isin(ev_ids)]\n",
    "                    \n",
    "                    if cfg_measure == 'Cfg_Sim':\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nanmean(sel_key_ev['Stim_' + cfg_measure])\n",
    "                    elif cfg_measure == 'Node_Str_Delta':\n",
    "                        delta_pv = sel_key_ev['Stim_' + cfg_measure +'_pv']\n",
    "                        evoked_node_cnt = np.mean([np.mean(ev < (0.05/len(ev)))\n",
    "                                                   for ev in delta_pv])\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nan_to_num(evoked_node_cnt)\n",
    "                    else:\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nanmean(sel_key_ev['Pre_' + cfg_measure])\n",
    "                        tp_vals[s_ii, c_ii, 1] = np.nanmean(sel_key_ev['Post_' + cfg_measure])\n",
    "                stim_energy[s_ii] = key_dict['Stim_Freq']*(key_dict['Stim_Dur'] / 1000.)*(key_dict['Stim_Amp'] / 1000.)\n",
    "\n",
    "                # Get the channel indices involved in stimulation\n",
    "                jacksheet = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Jacksheet']\n",
    "                if reref == 'CommonAverage':\n",
    "                    stim_ix = []\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Anode']))\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Cathode']))    \n",
    "                    stim_ix = np.unique([iyy for ixx in stim_ix for iyy in ixx])            \n",
    "                else:\n",
    "                    raise Exception('reref currently supports CommonAverage')\n",
    "                sel_base_subj = sel_coh_base.loc[sel_coh_base.Subject_ID == key_dict['Subject_ID']]\n",
    "                stim_location[s_ii, c_ii, 0] = sel_base_subj['Base_Node_Str'].iloc[0][:, stim_ix].mean()\n",
    "                stim_mni[s_ii, :] = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['MNI_Coord'][stim_ix, :].mean(axis=0)              \n",
    "    \n",
    "        # Remove invalid observations\n",
    "        stim_energy = stim_energy[np.unique(np.nonzero(~np.isnan(tp_vals))[0])]\n",
    "        stim_location = stim_location[np.unique(np.nonzero(~np.isnan(tp_vals))[0]), : ,:]\n",
    "        stim_mni = stim_mni[np.unique(np.nonzero(~np.isnan(tp_vals))[0]), :]\n",
    "        tp_vals = tp_vals[np.unique(np.nonzero(~np.isnan(tp_vals))[0]), :, :]        \n",
    "        \n",
    "        vals[tp] = tp_vals\n",
    "        energy[tp] = stim_energy\n",
    "        location[tp] = stim_location\n",
    "        mni_coords[tp] = stim_mni\n",
    "    return vals, energy, location, mni_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Linear Regression for Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean':     {'xlabel': 'Stim. Energy (amp-cycles)',\n",
    "                                 'ylabel': 'Delta Mean Coherence',\n",
    "                                 'xlim': [0.0, 1.0],\n",
    "                                 'ylim': [-0.05, 0.05],\n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Cfg_Str_Var':      {'xlabel': 'Stim. Energy (amp-cycles)',\n",
    "                                 'ylabel': 'Delta Var Coherence',\n",
    "                                 'xlim': [0.0, 1.0],\n",
    "                                 'ylim': [-0.005, 0.005],\n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Cfg_Sim':          {'xlabel': 'Stim. Energy (amp-cycles)',\n",
    "                                 'ylabel': 'Edge Correlation (r-to-z)',\n",
    "                                 'xlim': [0.0, 1.0],\n",
    "                                 'ylim': [0.0, 0.601],                             \n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Node_Str_Delta':   {'xlabel': 'Stim. Energy (amp-cycles)',\n",
    "                                 'ylabel': 'Fraction of Nodes Evoked',\n",
    "                                 'xlim': [0.0, 1.0],\n",
    "                                 'ylim': [0.0, 0.601],                             \n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}}}            \n",
    "for meas in analysis.keys():\n",
    "    prepost_meas_coh, energy, _, _ = compute_prepost_coherence_stimparam(meas)\n",
    "    \n",
    "    plt.figure(figsize=(1.5, 4), dpi=300.0)\n",
    "    for ii in xrange(len(meta_dict['coherence_info'])):\n",
    "        write('{}-{}\\n'.format(meas, meta_dict['coherence_info'][ii]))\n",
    "        \n",
    "        ax = plt.subplot(4,1,ii+1)\n",
    "        ax.set_xlim(analysis[meas]['xlim'])\n",
    "        ax.set_ylim(analysis[meas]['ylim'])\n",
    "        ax.set_title(meta_dict['coherence_freq'][ii])\n",
    "        if ii == 3:\n",
    "            ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "        if ii == 1:\n",
    "            ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "        ax.locator_params(nbins=3, axis='both')\n",
    "        if (meas in ['Cfg_Sim', 'Node_Str_Delta']):\n",
    "            ax.locator_params(nbins=3, axis='x')\n",
    "            ax.locator_params(nbins=4, axis='y')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "            \n",
    "        for tp in ['stim']:\n",
    "            vals = prepost_meas_coh[tp]\n",
    "            all_energy = energy[tp]\n",
    "            unique_energy = np.unique(all_energy)\n",
    "            \n",
    "            mean = np.nan*np.zeros(len(unique_energy))\n",
    "            serr = np.nan*np.zeros(len(unique_energy))\n",
    "            for ei, ee in enumerate(unique_energy):\n",
    "                ix = np.flatnonzero(all_energy == ee)\n",
    "                if meas == 'Cfg_Sim':\n",
    "                    delta = np.arctanh(vals[ix, ii, 0])\n",
    "                    delta = delta[~np.isinf(delta)]\n",
    "                elif meas == 'Node_Str_Delta':\n",
    "                    delta = vals[ix, ii, 0]\n",
    "                else:\n",
    "                    delta = vals[ix, ii, 1]-vals[ix, ii, 0]\n",
    "                mean[ei] = delta.mean()\n",
    "                serr[ei] = delta.std() / np.sqrt(len(ix))\n",
    "            \n",
    "            ax = sns.regplot(x=unique_energy, y=mean,\n",
    "                             color=analysis[meas][tp]['color'],\n",
    "                             scatter_kws={'s':1.0}, ci=68, ax=ax)\n",
    "            \n",
    "            slp, yint, rv, pv, stdr = stats.linregress(unique_energy,\n",
    "                                                       mean)\n",
    "            rv, pv = stats.spearmanr(unique_energy, mean)\n",
    "            write('{}: rv={:2.2f}, pv={:2.2e}\\n'.format(tp, rv, pv))\n",
    "        write('\\n')\n",
    "    write('\\n\\n')\n",
    "\n",
    "    plt.savefig('{}/{}-Stim_Energy.LinReg.svg'.format(path_Data['Figure'][reref], meas))\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(2, 2), dpi=300.0)\n",
    "ax = plt.subplot(111)\n",
    "ax.set_xlim([0.0, 0.601])\n",
    "ax.set_ylim([0.0, 3000.0])\n",
    "ax.set_xlabel('Stim. Energy (amp-cycles)')\n",
    "ax.set_ylabel('Stim. Trials')\n",
    "ax.locator_params(nbins=4, axis='both')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "sns.distplot(energy['stim'], kde=True, hist=False, ax=ax)\n",
    "\n",
    "plt.savefig('{}/Stim_Energy.Histogram.svg'.format(path_Data['Figure'][reref]))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Linear Regression for Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean':     {'xlabel': 'Func. Stim. Location (wgt. degree)',\n",
    "                                 'ylabel': 'Delta Mean Coherence',\n",
    "                                 'xlim': [0.0, 1.0],\n",
    "                                 'ylim': [-0.05, 0.05],\n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Cfg_Str_Var':      {'xlabel': 'Func. Stim. Location (wgt. degree)',\n",
    "                                 'ylabel': 'Delta Var Coherence',\n",
    "                                 'xlim': [0.0, 1.0],\n",
    "                                 'ylim': [-0.005, 0.005],\n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Cfg_Sim':          {'xlabel': 'Func. Stim. Location (wgt. degree)',\n",
    "                                 'ylabel': 'Edge Correlation (r-to-z)',\n",
    "                                 'xlim': [0.0, 1.0],\n",
    "                                 'ylim': [0.0, 2.0],                             \n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Node_Str_Delta':   {'xlabel': 'Func. Stim. Location (wgt. degree)',\n",
    "                                 'ylabel': 'Fraction of Nodes Evoked',\n",
    "                                 'xlim': [0.0, 1.0],\n",
    "                                 'ylim': [0.0, 0.601],                             \n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}}}            \n",
    "for meas in analysis.keys():\n",
    "    prepost_meas_coh, _, location, mni_coords = compute_prepost_coherence_stimparam(meas)\n",
    "    \n",
    "    plt.figure(figsize=(1.5,4), dpi=300.0)\n",
    "    for ii in xrange(len(meta_dict['coherence_info'])):\n",
    "        write('{}-{}\\n'.format(meas, meta_dict['coherence_info'][ii]))\n",
    "        \n",
    "        \n",
    "        ax = plt.subplot(4,1,ii+1)\n",
    "        ax.set_xlim(analysis[meas]['xlim'])\n",
    "        ax.set_ylim(analysis[meas]['ylim'])\n",
    "        ax.set_title(meta_dict['coherence_freq'][ii])\n",
    "        if ii == 3:\n",
    "            ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "        if ii == 1:\n",
    "            ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "        ax.locator_params(nbins=3, axis='both')\n",
    "        if (meas == 'Node_Str_Delta'):\n",
    "            ax.locator_params(nbins=3, axis='x')\n",
    "            ax.locator_params(nbins=4, axis='y')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "            \n",
    "        for tp in ['stim']:\n",
    "            vals = prepost_meas_coh[tp]\n",
    "            all_location = location[tp][:, ii, 0]\n",
    "            unique_location = np.unique(all_location)\n",
    "            \n",
    "            mean = np.nan*np.zeros(len(unique_location))\n",
    "            serr = np.nan*np.zeros(len(unique_location))\n",
    "            for li, ll in enumerate(unique_location):\n",
    "                ix = np.flatnonzero(all_location == ll)\n",
    "                if meas == 'Cfg_Sim':\n",
    "                    delta = np.arctanh(vals[ix, ii, 0])\n",
    "                    delta = delta[~np.isinf(delta)]\n",
    "                elif meas == 'Node_Str_Delta': \n",
    "                    delta = vals[ix, ii, 0]\n",
    "                else:\n",
    "                    delta = vals[ix, ii, 1]-vals[ix, ii, 0]\n",
    "                mean[li] = np.nan_to_num(np.nanmean(delta))\n",
    "                serr[li] = np.nan_to_num(np.nanstd(delta)) / np.sqrt(len(ix))\n",
    "            \n",
    "            ax = sns.regplot(x=unique_location, y=mean,\n",
    "                             color=analysis[meas][tp]['color'],\n",
    "                             scatter_kws={'s':1.0}, ci=68, ax=ax)\n",
    "            \n",
    "            slp, yint, rv, pv, stdr = stats.linregress(unique_location,\n",
    "                                                       mean)\n",
    "            rv, pv = stats.spearmanr(unique_location, mean)\n",
    "            write('{}: n={:2.2f}, rv={:2.2f}, pv={:2.2e}\\n'.format(tp, len(unique_location), rv, pv))\n",
    "        write('\\n')\n",
    "    write('\\n\\n')\n",
    "\n",
    "    #plt.savefig('{}/{}-Func_Stim_Loc.LinReg.svg'.format(path_Data['Figure'][reref], meas))\n",
    "    plt.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Stimulation Locs (MNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, _, node_str, node_coord = compute_prepost_coherence_stimparam('Node_Str_Delta')\n",
    "\n",
    "def plot_sensors(node_coord, node_vals):\n",
    "    from Echobase.Plotting import render_brain_connectivity\n",
    "\n",
    "    ### Collect surface data\n",
    "    # Vertices and triangles\n",
    "    verts_rh, trias_rh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/rh.pial'.format(path_AtlasData))\n",
    "    verts_lh, trias_lh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/lh.pial'.format(path_AtlasData))\n",
    "\n",
    "    n_rh_verts = verts_rh.shape[0]\n",
    "    n_lh_verts = verts_lh.shape[0]\n",
    "\n",
    "    verts = np.vstack((verts_rh, verts_lh))\n",
    "    trias = np.vstack((trias_rh, trias_lh+n_rh_verts))\n",
    "\n",
    "    label_scalars = 20*np.zeros(n_rh_verts+n_lh_verts)\n",
    "\n",
    "    view_angle = {'Cor_RL': [90.0, 90.0],\n",
    "                  'Sag_PA': [0.0, 90.0],\n",
    "                  'Sag_AP': [180.0, 90.0]}\n",
    "    \n",
    "    cmap = plt.get_cmap('coolwarm')\n",
    "    node_rgba = np.array([cmap(nn) for nn in node_vals])\n",
    "    node_size= np.array([4.0 for nn in node_coord])\n",
    "\n",
    "    render_brain_connectivity.mlab.close(all=True)    \n",
    "    engine = render_brain_connectivity.draw(verts, trias, label_scalars, 'binary', 10.0,\n",
    "                                            node_coords=node_coord, node_sizes=node_size, node_colors=node_rgba,\n",
    "                                            conn_list=None, conn_cmap=None)\n",
    "    pixmap = {}\n",
    "    for ang in view_angle.keys():\n",
    "        render_brain_connectivity.mlab.view(azimuth=view_angle[ang][0],\n",
    "                                            elevation=view_angle[ang][1])\n",
    "        pixmap['{}'.format(ang)] = render_brain_connectivity.mlab.screenshot(mode='rgba')\n",
    "    render_brain_connectivity.mlab.close(all=True)\n",
    "    \n",
    "    return pixmap\n",
    "\n",
    "\n",
    "unique_node_coord = []\n",
    "unique_node_str = []\n",
    "for ii in xrange(node_coord['stim'].shape[0]):\n",
    "    nc = tuple(node_coord['stim'][ii, :])\n",
    "    if np.linalg.norm(nc) > 150:\n",
    "        continue\n",
    "    if nc in unique_node_coord:\n",
    "        continue        \n",
    "        \n",
    "    unique_node_coord.append(nc)\n",
    "    unique_node_str.append(node_str['stim'][ii, :, :])\n",
    "node_coord = np.array(unique_node_coord)\n",
    "node_str = np.array(unique_node_str)\n",
    "\n",
    "\"\"\"\n",
    "sensor_pixmap = plot_sensors(node_coord, np.ones((node_coord.shape[0])))   \n",
    "plt.figure(figsize=(4.5,1.5), dpi=600.0)\n",
    "for jj, key in enumerate(['Sag_PA', 'Cor_RL', 'Sag_AP']):\n",
    "    ax = plt.subplot(1,3,jj+1)\n",
    "    ax.imshow(sensor_pixmap[key])\n",
    "    ax.set_axis_off()\n",
    "plt.savefig('{}/Stim_Location.freesurfer.svg'.format(path_Data['Figure'][reref]))\n",
    "plt.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stimulation to Structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key =['Subject_ID',\n",
    "                  'Stim_Anode',\n",
    "                  'Stim_Cathode']\n",
    "meta_stim_type = meta_ps.loc[meta_ps.Stim_Type == 'stimulating']\n",
    "meta_sham_type = meta_ps.loc[meta_ps.Stim_Type == 'sham']\n",
    "\n",
    "meta_stim_lut = meta_stim_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_sham_lut = meta_sham_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_base_lut = meta_base.groupby(['Subject_ID'])['Base_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Post Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def compute_structural_prepost_coherence_stimparam(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    if cfg_measure == 'Cfg_Sim':\n",
    "        vals = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 1))}\n",
    "    else:     \n",
    "        vals = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 2))}\n",
    "    location = {'stim': np.nan*np.zeros(len(meta_stim_lut))}    \n",
    "    luts = {'stim': meta_stim_lut}\n",
    "    \n",
    "    for tp in vals.keys():\n",
    "        tp_vals = vals[tp]\n",
    "        meta_lut = luts[tp]\n",
    "        stim_location = location[tp]        \n",
    "        \n",
    "        sel_globaltopo = df_globaltopo_stim\n",
    "    \n",
    "        # Iterate over coherence\n",
    "        for c_ii, coh_id in enumerate(meta_dict['coherence_info']):\n",
    "            sel_coh = sel_globaltopo[sel_globaltopo['Coherence_ID'] == coh_id]\n",
    "            sel_coh_base = df_globaltopo_base[df_globaltopo_base['Coherence_ID'] == coh_id]\n",
    "\n",
    "            # Iterate over unique stim parameters\n",
    "            for s_ii, (meta_key, ev_ids) in enumerate(meta_lut.iteritems()):\n",
    "                if tp in ['stim']:\n",
    "                    key_dict = dict(zip(unique_stim_key, meta_key))\n",
    "                    sel_key_subj = sel_coh.loc[sel_coh.Subject_ID == key_dict['Subject_ID']]\n",
    "                    sel_key_ev = sel_key_subj.loc[sel_key_subj.Event_ID.isin(ev_ids)]\n",
    "                    \n",
    "                    if cfg_measure == 'Cfg_Sim':\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nanmean(sel_key_ev['Stim_' + cfg_measure])\n",
    "                    elif cfg_measure == 'Node_Str_Delta':\n",
    "                        delta_pv = sel_key_ev['Stim_' + cfg_measure +'_pv']\n",
    "                        evoked_node_cnt = np.mean([np.mean(ev < (0.05/len(ev)))\n",
    "                                                   for ev in delta_pv])\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nan_to_num(evoked_node_cnt)\n",
    "                    else:\n",
    "                        tp_vals[s_ii, c_ii, 0] = np.nanmean(sel_key_ev['Pre_' + cfg_measure])\n",
    "                        tp_vals[s_ii, c_ii, 1] = np.nanmean(sel_key_ev['Post_' + cfg_measure])\n",
    "\n",
    "                # Get the channel indices involved in stimulation\n",
    "                jacksheet = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Jacksheet']\n",
    "                if reref == 'CommonAverage':\n",
    "                    stim_ix = []\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Anode']))\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Cathode']))    \n",
    "                    stim_ix = np.unique([iyy for ixx in stim_ix for iyy in ixx])            \n",
    "                else:\n",
    "                    raise Exception('reref currently supports CommonAverage')\n",
    "                    \n",
    "                \n",
    "                if not (key_dict['Subject_ID'] in meta_dict['struct_adj'][reref].keys()):\n",
    "                    continue\n",
    "                    \n",
    "                scale_id = 'scale500'\n",
    "                atlas_index = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Atlas_Index'][scale_id]\n",
    "                adj_struct = meta_dict['struct_adj'][reref][key_dict['Subject_ID']][scale_id]['GFA']['adj']\n",
    "                struct_degree = np.mean(adj_struct, axis=0)\n",
    "                el_degree = struct_degree[atlas_index]\n",
    "                stim_location[s_ii] = np.nan_to_num(np.nanmean(el_degree[stim_ix]))\n",
    "    \n",
    "        # Remove invalid observations\n",
    "        tp_vals = tp_vals[np.unique(np.nonzero(~np.isnan(tp_vals))[0]), :, :]\n",
    "        stim_location = stim_location[np.unique(np.nonzero(~np.isnan(tp_vals))[0])]\n",
    "        \n",
    "        tp_vals = tp_vals[~np.isnan(stim_location), :, :]\n",
    "        stim_location = stim_location[~np.isnan(stim_location)]\n",
    "        \n",
    "        vals[tp] = tp_vals\n",
    "        location[tp] = stim_location\n",
    "    return vals, location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Linear Regression for Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Cfg_Str_Mean':     {'xlabel': 'Struct. Stim. Location (wgt. degree)',\n",
    "                                 'ylabel': 'Delta Mean Coherence',\n",
    "                                 'xlim': [0.0, 0.01],\n",
    "                                 'ylim': [-0.05, 0.05],\n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Cfg_Str_Var':      {'xlabel': 'Struct. Stim. Location (wgt. degree)',\n",
    "                                 'ylabel': 'Delta Var Coherence',\n",
    "                                 'xlim': [0.0, 0.005],\n",
    "                                 'ylim': [-0.01, 0.01],\n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Cfg_Sim':          {'xlabel': 'Struct. Stim. Location (wgt. degree)',\n",
    "                                 'ylabel': 'Edge Correlation (r-to-z)',\n",
    "                                 'xlim': [0.0, 0.01],\n",
    "                                 'ylim': [0.0, 1.0],                             \n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}},\n",
    "            'Node_Str_Delta':   {'xlabel': 'Struct. Stim. Location (wgt. degree)',\n",
    "                                 'ylabel': 'Fraction of Nodes Evoked',\n",
    "                                 'xlim': [0.0, 0.01],\n",
    "                                 'ylim': [0.0, 0.601],                             \n",
    "                                 'stim': {'color': [0.2, 0.2, 0.2]}}}            \n",
    "for meas in analysis.keys():\n",
    "    prepost_meas_coh, location = compute_structural_prepost_coherence_stimparam(meas)\n",
    "    \n",
    "    plt.figure(figsize=(1.5,4), dpi=300.0)\n",
    "    for ii in xrange(len(meta_dict['coherence_info'])):\n",
    "        write('{}-{}\\n'.format(meas, meta_dict['coherence_info'][ii]))\n",
    "        \n",
    "        ax = plt.subplot(4,1,ii+1)\n",
    "        ax.set_xlim(analysis[meas]['xlim'])\n",
    "        ax.set_ylim(analysis[meas]['ylim'])\n",
    "        ax.set_title(meta_dict['coherence_freq'][ii])\n",
    "        if ii == 3:\n",
    "            ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "        if ii == 1:\n",
    "            ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "        ax.locator_params(nbins=3, axis='both')\n",
    "        if meas == 'Node_Str_Delta':\n",
    "            ax.locator_params(nbins=3, axis='x')\n",
    "            ax.locator_params(nbins=4, axis='y')\n",
    "            \n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "            \n",
    "        for tp in ['stim']:\n",
    "            vals = prepost_meas_coh[tp]\n",
    "            all_location = location[tp]\n",
    "            unique_location = np.unique(all_location)\n",
    "            \n",
    "            mean = np.nan*np.zeros(len(unique_location))\n",
    "            serr = np.nan*np.zeros(len(unique_location))\n",
    "            for li, ll in enumerate(unique_location):\n",
    "                ix = np.flatnonzero(all_location == ll)\n",
    "                if meas == 'Cfg_Sim':\n",
    "                    delta = np.arctanh(vals[ix, ii, 0])\n",
    "                    delta = delta[~np.isnan(delta)]\n",
    "                elif meas == 'Node_Str_Delta':\n",
    "                    delta = vals[ix, ii, 0]\n",
    "                else:\n",
    "                    delta = vals[ix, ii, 1]-vals[ix, ii, 0]\n",
    "                mean[li] = np.nan_to_num(np.nanmean(delta))\n",
    "                serr[li] = np.nan_to_num(np.nanstd(delta)) / np.sqrt(len(ix))\n",
    "            \n",
    "            ax = sns.regplot(x=unique_location, y=mean,\n",
    "                             color=analysis[meas][tp]['color'],\n",
    "                             scatter_kws={'s':1.0}, ci=68, ax=ax)\n",
    "            \n",
    "            slp, yint, rv, pv, stdr = stats.linregress(unique_location, mean)\n",
    "            rv, pv = stats.spearmanr(unique_location, mean)\n",
    "            write('{}: rv={:2.2f}, pv={:2.2e}\\n'.format(tp, rv, pv))\n",
    "        write('\\n')\n",
    "    write('\\n\\n')\n",
    "\n",
    "    plt.savefig('{}/{}-Struct_Stim_Loc.GFA.LinReg.svg'.format(path_Data['Figure'][reref], meas))\n",
    "    plt.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Node Modulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stimulation to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key =['Subject_ID',\n",
    "                  'Stim_Anode',\n",
    "                  'Stim_Cathode']\n",
    "meta_stim_type = meta_ps.loc [meta_ps.Stim_Type == 'stimulating']\n",
    "meta_sham_type = meta_ps.loc[meta_ps.Stim_Type == 'sham']\n",
    "\n",
    "meta_stim_lut = meta_stim_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_sham_lut = meta_sham_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_base_lut = meta_base.groupby(['Subject_ID'])['Base_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Coherence with Evoked Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def compute_baseline_coherence_evoked(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    vals = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 2))}\n",
    "    luts = {'stim': meta_stim_lut}\n",
    "    \n",
    "    for tp in vals.keys():\n",
    "        tp_vals = vals[tp]\n",
    "        meta_lut = luts[tp]\n",
    "        \n",
    "        sel_globaltopo = df_globaltopo_stim\n",
    "    \n",
    "        # Iterate over coherence\n",
    "        for c_ii, coh_id in enumerate(meta_dict['coherence_info']):\n",
    "            sel_coh = sel_globaltopo[sel_globaltopo['Coherence_ID'] == coh_id]\n",
    "            sel_coh_base = df_globaltopo_base[df_globaltopo_base['Coherence_ID'] == coh_id]\n",
    "\n",
    "            # Iterate over unique stim parameters\n",
    "            for s_ii, (meta_key, ev_ids) in enumerate(meta_lut.iteritems()):\n",
    "                if tp in ['stim']:\n",
    "                    key_dict = dict(zip(unique_stim_key, meta_key))\n",
    "                    sel_key_subj = sel_coh.loc[sel_coh.Subject_ID == key_dict['Subject_ID']]\n",
    "                    sel_key_ev = sel_key_subj.loc[sel_key_subj.Event_ID.isin(ev_ids)]\n",
    "                    \n",
    "                    delta_pv = sel_key_ev['Stim_' + cfg_measure + '_pv']\n",
    "                    evoked_node_cnt = np.array([ev < (0.05/len(ev))\n",
    "                                                for ev in delta_pv])\n",
    "                    evoked_node_pct = np.mean(evoked_node_cnt, axis=0)\n",
    "                    \n",
    "                # Get the channel indices involved in stimulation\n",
    "                jacksheet = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Jacksheet']\n",
    "                if reref == 'CommonAverage':\n",
    "                    stim_ix = []\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Anode']))\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Cathode']))    \n",
    "                    stim_ix = np.unique([iyy for ixx in stim_ix for iyy in ixx])            \n",
    "                else:\n",
    "                    raise Exception('reref currently supports CommonAverage')\n",
    "                \n",
    "                sel_base_subj = sel_coh_base.loc[sel_coh_base.Subject_ID == key_dict['Subject_ID']]\n",
    "                adj = sel_base_subj['Base_Adj_Matr_Mean'].iloc[0]\n",
    "                stim_coh = np.delete(np.nanmean(adj[stim_ix, :], axis=0), stim_ix)\n",
    "                                \n",
    "                try:                    \n",
    "                    rv, pv = stats.pearsonr(stim_coh, evoked_node_pct)\n",
    "                    tp_vals[s_ii, c_ii, 0] = np.arctanh(rv)\n",
    "\n",
    "                    rvs = []\n",
    "                    for perm_ii in xrange(1000):\n",
    "                        stim_null_ix = np.random.permutation(len(evoked_node_pct))[:len(stim_ix)]\n",
    "                        stim_coh_null = np.delete(np.nanmean(adj[stim_null_ix, :], axis=0), stim_null_ix)\n",
    "                        rv, pv = stats.pearsonr(stim_coh_null, evoked_node_pct)\n",
    "                        rvs.append(np.arctanh(np.nan_to_num(rv)))\n",
    "                    tp_vals[s_ii, c_ii, 1] = np.nan_to_num(np.mean(rvs))\n",
    "                except Exception as E:\n",
    "                    tp_vals[s_ii, c_ii, 0] = np.nan\n",
    "                    tp_vals[s_ii, c_ii, 1] = np.nan                    \n",
    "                \n",
    "        # Remove invalid observations\n",
    "        tp_vals = tp_vals[np.unique(np.nonzero(~np.isnan(tp_vals))[0]), :, :]\n",
    "        \n",
    "        vals[tp] = tp_vals\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Node_Str_Delta':   {'xlabel': 'Frequency Range',\n",
    "                                 'ylabel': 'Coherence with Evoked Nodes (r-to-z)',\n",
    "                                 'xlim': [-0.5, len(meta_dict['coherence_info'])-0.5],\n",
    "                                 'ylim': [0.0, 0.4],\n",
    "                                 'stim': {'color': [1.0, 0.3, 0.3]},\n",
    "                                 'null': {'color': [0.2, 0.2, 0.2]}}}\n",
    "n_grp = len(meta_dict['coherence_freq'])            \n",
    "\n",
    "for meas in analysis.keys():\n",
    "    baseline_coh_corr = compute_baseline_coherence_evoked(meas)\n",
    "        \n",
    "    all_corr = []\n",
    "    all_mean = []\n",
    "    all_serr = []\n",
    "    all_color = []\n",
    "    all_pos = []\n",
    "    for tp_ii, tp in enumerate(['stim', 'null']):\n",
    "        corr = baseline_coh_corr['stim'][:, :, tp_ii]\n",
    "        all_corr.append(corr)\n",
    "        for nn in xrange(corr.shape[1]):\n",
    "            all_mean.append(np.nanmean(corr[:, nn]))\n",
    "            all_serr.append(np.nanstd(corr[:, nn]) / np.sqrt(corr.shape[0]))\n",
    "            all_color.append(analysis[meas][tp]['color'])\n",
    "            all_pos.append(nn + 0.2*tp_ii)\n",
    "        \n",
    "    plt.figure(figsize=(2,1.5), dpi=300.0)\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    ax.bar(left=all_pos, height=all_mean, yerr=all_serr,\n",
    "           width=0.2, color=all_color, lw=0.0)\n",
    "    \n",
    "    ax.set_xlim(analysis[meas]['xlim'])\n",
    "    ax.set_ylim(analysis[meas]['ylim'])\n",
    "    ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "    ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "    ax.xaxis.set_ticks(np.arange(n_grp)+0.2)\n",
    "    ax.xaxis.set_ticklabels(meta_dict['coherence_freq'])\n",
    "    ax.locator_params(nbins=4, axis='y')    \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    plt.savefig('{}/Evoked_Nodes-Func_Coherence.BarPlot.svg'.format(path_Data['Figure'][reref]))\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    for ff in xrange(len(meta_dict['coherence_freq'])):\n",
    "        write('{}\\n'.format(meta_dict['coherence_freq'][ff]))\n",
    "        write('t-test: {}\\n'.format(stats.ttest_rel(all_corr[0][:, ff], all_corr[1][:, ff])))\n",
    "        write('cohens: {}\\n\\n'.format(cohens_d(all_corr[0][:, ff], all_corr[1][:, ff])))\n",
    "        write('df: {}\\n'.format(len(all_corr[0][:, ff])))\n",
    "    write('Anova: {}\\n'.format(stats.f_oneway(*all_corr[0].T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stimulation to Structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key =['Subject_ID',\n",
    "                  'Stim_Anode',\n",
    "                  'Stim_Cathode']\n",
    "meta_stim_type = meta_ps.loc[meta_ps.Stim_Type == 'stimulating']\n",
    "meta_sham_type = meta_ps.loc[meta_ps.Stim_Type == 'sham']\n",
    "\n",
    "meta_stim_lut = meta_stim_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_sham_lut = meta_sham_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_base_lut = meta_base.groupby(['Subject_ID'])['Base_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural Connectivity with Evoked Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def compute_structural_evoked(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    vals = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 2))}\n",
    "    luts = {'stim': meta_stim_lut}\n",
    "    \n",
    "    for tp in vals.keys():\n",
    "        tp_vals = vals[tp]\n",
    "        meta_lut = luts[tp]\n",
    "        \n",
    "        sel_globaltopo = df_globaltopo_stim\n",
    "    \n",
    "        # Iterate over coherence\n",
    "        for c_ii, coh_id in enumerate(meta_dict['coherence_info']):\n",
    "            sel_coh = sel_globaltopo[sel_globaltopo['Coherence_ID'] == coh_id]\n",
    "            sel_coh_base = df_globaltopo_base[df_globaltopo_base['Coherence_ID'] == coh_id]\n",
    "\n",
    "            # Iterate over unique stim parameters\n",
    "            for s_ii, (meta_key, ev_ids) in enumerate(meta_lut.iteritems()):\n",
    "                if tp in ['stim']:\n",
    "                    key_dict = dict(zip(unique_stim_key, meta_key))\n",
    "                    sel_key_subj = sel_coh.loc[sel_coh.Subject_ID == key_dict['Subject_ID']]\n",
    "                    sel_key_ev = sel_key_subj.loc[sel_key_subj.Event_ID.isin(ev_ids)]\n",
    "                    \n",
    "                    delta_pv = sel_key_ev['Stim_' + cfg_measure + '_pv']\n",
    "                    evoked_node_cnt = np.array([ev < (0.05/len(ev))\n",
    "                                                for ev in delta_pv])\n",
    "                    evoked_node_pct = np.mean(evoked_node_cnt, axis=0)\n",
    "                    \n",
    "                # Get the channel indices involved in stimulation\n",
    "                jacksheet = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Jacksheet']\n",
    "                if reref == 'CommonAverage':\n",
    "                    stim_ix = []\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Anode']))\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Cathode']))    \n",
    "                    stim_ix = np.unique([iyy for ixx in stim_ix for iyy in ixx])            \n",
    "                else:\n",
    "                    raise Exception('reref currently supports CommonAverage')\n",
    "                nsstim_ix = np.setdiff1d(np.arange(len(jacksheet)), stim_ix)\n",
    "                    \n",
    "                if not (key_dict['Subject_ID'] in meta_dict['struct_adj'][reref].keys()):\n",
    "                    continue\n",
    "                    \n",
    "                scale_id = 'scale60'\n",
    "                atlas_index = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Atlas_Index'][scale_id]\n",
    "                adj_struct = meta_dict['struct_adj'][reref][key_dict['Subject_ID']][scale_id]['QA']['adj']\n",
    "                adj = adj_struct[atlas_index, :][:, atlas_index]\n",
    "                             \n",
    "                stim_coh = np.delete(np.nanmean(adj[stim_ix, :], axis=0), stim_ix)\n",
    "                rv, pv = stats.pearsonr(stim_coh, evoked_node_pct)\n",
    "                tp_vals[s_ii, c_ii, 0] = np.arctanh(np.nan_to_num(rv))\n",
    "\n",
    "                rvs = []\n",
    "                for perm_ii in xrange(1000):\n",
    "                    null_stim_ix = np.random.permutation(nsstim_ix)[:len(stim_ix)]\n",
    "                    stim_coh_null = np.delete(np.nanmean(adj[null_stim_ix, :], axis=0), stim_ix)\n",
    "                    rv, pv = stats.pearsonr(stim_coh_null, evoked_node_pct)\n",
    "                    rvs.append(np.arctanh(np.nan_to_num(rv)))\n",
    "                tp_vals[s_ii, c_ii, 1] = np.nan_to_num(np.nanmean(rvs))\n",
    "                \n",
    "        # Remove invalid observations\n",
    "        tp_vals = tp_vals[np.unique(np.nonzero(~np.isnan(tp_vals))[0]), :, :]\n",
    "        \n",
    "        vals[tp] = tp_vals\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Node_Str_Delta':   {'xlabel': 'Frequency Range',\n",
    "                                 'ylabel': 'Connectivity with Evoked Nodes (r-to-z)',\n",
    "                                 'xlim': [-0.5, len(meta_dict['coherence_info'])-0.5],\n",
    "                                 'ylim': [-0.1, 0.1],\n",
    "                                 'stim': {'color': [1.0, 0.3, 0.3]},\n",
    "                                 'null': {'color': [0.2, 0.2, 0.2]}}}\n",
    "n_grp = len(meta_dict['coherence_freq'])            \n",
    "\n",
    "for meas in analysis.keys():\n",
    "    baseline_coh_corr = compute_structural_evoked(meas)\n",
    "        \n",
    "    all_corr = []\n",
    "    all_mean = []\n",
    "    all_serr = []\n",
    "    all_color = []\n",
    "    all_pos = []\n",
    "    for tp_ii, tp in enumerate(['stim', 'null']):\n",
    "        corr = baseline_coh_corr['stim'][:, :, tp_ii]\n",
    "        all_corr.append(corr)\n",
    "        for nn in xrange(corr.shape[1]):\n",
    "            all_mean.append(np.nanmean(corr[:, nn]))\n",
    "            all_serr.append(np.nanstd(corr[:, nn]) / np.sqrt(corr.shape[0]))\n",
    "            all_color.append(analysis[meas][tp]['color'])\n",
    "            all_pos.append(nn + 0.2*tp_ii)\n",
    "        \n",
    "    plt.figure(figsize=(2,1.5), dpi=300.0)\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    ax.bar(left=all_pos, height=all_mean, yerr=all_serr,\n",
    "           width=0.2, color=all_color, lw=0.0)\n",
    "    \n",
    "    ax.set_xlim(analysis[meas]['xlim'])\n",
    "    ax.set_ylim(analysis[meas]['ylim'])\n",
    "    ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "    ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "    ax.xaxis.set_ticks(np.arange(n_grp)+0.2)\n",
    "    ax.xaxis.set_ticklabels(meta_dict['coherence_freq'])   \n",
    "    ax.locator_params(nbins=4, axis='y')    \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    plt.savefig('{}/Evoked_Nodes-Struct_Connectivity.GFA.BarPlot.svg'.format(path_Data['Figure'][reref]))\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    for ff in xrange(len(meta_dict['coherence_freq'])):\n",
    "        write('{}\\n'.format(meta_dict['coherence_freq'][ff]))\n",
    "        write('t-test: {}\\n'.format(stats.ttest_rel(all_corr[0][:, ff], all_corr[1][:, ff])))\n",
    "        write('cohens: {}\\n\\n'.format(cohens_d(all_corr[0][:, ff], all_corr[1][:, ff])))\n",
    "    write('Anova: {}\\n'.format(stats.f_oneway(*all_corr[0].T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relating Structural Control and Structural Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key =['Subject_ID',\n",
    "                  'Stim_Anode',\n",
    "                  'Stim_Cathode']\n",
    "meta_stim_type = meta_ps.loc[meta_ps.Stim_Type == 'stimulating']\n",
    "meta_sham_type = meta_ps.loc[meta_ps.Stim_Type == 'sham']\n",
    "\n",
    "meta_stim_lut = meta_stim_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_sham_lut = meta_sham_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_base_lut = meta_base.groupby(['Subject_ID'])['Base_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllability and connectivity of stim location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def compute_structural_control():\n",
    "    print('Processing: {}'.format('Structural Control'))\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    vals = {'stim': np.nan*np.zeros((len(meta_stim_lut), len(meta_dict['coherence_info']), 4))}\n",
    "    luts = {'stim': meta_stim_lut}\n",
    "    \n",
    "    for tp in vals.keys():\n",
    "        tp_vals = vals[tp]\n",
    "        meta_lut = luts[tp]\n",
    "\n",
    "        # Iterate over coherence\n",
    "        for c_ii, coh_id in enumerate(meta_dict['coherence_info']):\n",
    "            sel_coh_base = df_globaltopo_base[df_globaltopo_base['Coherence_ID'] == coh_id]            \n",
    "            \n",
    "            # Iterate over unique stim parameters\n",
    "            for s_ii, (meta_key, ev_ids) in enumerate(meta_lut.iteritems()):\n",
    "                key_dict = dict(zip(unique_stim_key, meta_key))\n",
    "\n",
    "                # Get the channel indices involved in stimulation\n",
    "                jacksheet = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Jacksheet']\n",
    "                if reref == 'CommonAverage':\n",
    "                    stim_ix = []\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Anode']))\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Cathode']))    \n",
    "                    stim_ix = np.unique([iyy for ixx in stim_ix for iyy in ixx])            \n",
    "                else:\n",
    "                    raise Exception('reref currently supports CommonAverage')\n",
    "                nsstim_ix = np.setdiff1d(np.arange(len(jacksheet)), stim_ix)\n",
    "                \n",
    "                sel_base_subj = sel_coh_base.loc[sel_coh_base.Subject_ID == key_dict['Subject_ID']]                \n",
    "                adj = sel_base_subj['Base_Adj_Matr_Mean'].iloc[0]                \n",
    "                \n",
    "                func_degr = np.nanmean(adj[:, stim_ix])                \n",
    "\n",
    "                if (key_dict['Subject_ID'] in meta_dict['struct_adj'][reref].keys()):\n",
    "                    scale_id = 'scale250'\n",
    "                    atlas_index = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Atlas_Index'][scale_id]\n",
    "                    adj_struct = meta_dict['struct_adj'][reref][key_dict['Subject_ID']][scale_id]['QA']['adj']\n",
    "\n",
    "                    struct_degr = np.mean(adj_struct, axis=0) \n",
    "                    struct_average = structural_control.average_control(adj_struct)\n",
    "                    struct_modal = structural_control.modal_control(adj_struct)            \n",
    "\n",
    "                    tp_vals[s_ii, c_ii, 0] = func_degr\n",
    "                    tp_vals[s_ii, c_ii, 1] = np.nanmean(struct_degr[atlas_index][stim_ix])\n",
    "                    tp_vals[s_ii, c_ii, 2] = np.nanmean(struct_average[atlas_index][stim_ix])\n",
    "                    tp_vals[s_ii, c_ii, 3] = np.nanmean(struct_modal[atlas_index][stim_ix])\n",
    "\n",
    "        # Remove invalid observations\n",
    "        tp_vals = tp_vals[np.unique(np.nonzero(~np.isnan(tp_vals))[0]), :]\n",
    "        \n",
    "        vals[tp] = tp_vals\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Baseline':     {'xlabel': 'Frequency Range',\n",
    "                             'ylabel': 'Corr(Modal, Baseline)',\n",
    "                             'xlim': [-0.5, len(meta_dict['coherence_info'])-0.5],\n",
    "                             'ylim': [0.0, 0.601],\n",
    "                             'color': [0.2, 0.2, 0.2]},  \n",
    "            'Average_Cntl': {'xlabel': 'Stim. Location (wgt. degree)',\n",
    "                             'ylabel': 'Controllability',\n",
    "                             'xlim': [0.0, 0.01],\n",
    "                             'ylim': [1.0, 1.1],\n",
    "                             'color': [0.2, 0.2, 0.2]},\n",
    "            'Modal_Cntl':   {'xlabel': 'Stim. Location (wgt. degree)',\n",
    "                             'ylabel': 'Controllability',\n",
    "                             'xlim': [0.0, 0.01],\n",
    "                             'ylim': [0.96, 1.00],                             \n",
    "                             'color': [0.2, 0.2, 0.2]}}\n",
    "            \n",
    "structural_meas_coh = compute_structural_control()\n",
    "\n",
    "# Plot Structure to Baseline\n",
    "meas = 'Baseline'\n",
    "plt.figure(figsize=(1.5,4), dpi=300.0)\n",
    "for ii in xrange(len(meta_dict['coherence_info'])):\n",
    "    write('{}-{}\\n'.format(meas, meta_dict['coherence_info'][ii]))\n",
    "\n",
    "    ax = plt.subplot(4,1,ii+1)    \n",
    "    ax.set_xlim(analysis[meas]['xlim'])\n",
    "    ax.set_ylim(analysis[meas]['ylim'])\n",
    "    if ii == 3:\n",
    "        ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "    if ii == 1:\n",
    "        ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "    ax.locator_params(nbins=3, axis='both')\n",
    "    ax.set_title(meta_dict['coherence_freq'][ii])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = sns.regplot(x=structural_meas_coh['stim'][:, ii, 1],\n",
    "                     y=structural_meas_coh['stim'][:, ii, 0],\n",
    "                     color=analysis[meas]['color'],\n",
    "                     scatter_kws={'s':1.0}, ci=68, ax=ax)\n",
    "\n",
    "    slp, yint, rv, pv, stdr = stats.linregress(structural_meas_coh['stim'][:, ii, 1],\n",
    "                                               structural_meas_coh['stim'][:, ii, 0])\n",
    "    rv, pv = stats.spearmanr(structural_meas_coh['stim'][:, ii, 1],\n",
    "                             structural_meas_coh['stim'][:, ii, 0])\n",
    "    write('rv={:2.2f}, pv={:2.2e}\\n'.format(rv, pv))\n",
    "write('\\n\\n')\n",
    "plt.savefig('{}/Struct_Stim_Loc-Func_Stim_Loc.QA.LinReg.svg'.format(path_Data['Figure'][reref]))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot Structure to Baseline\n",
    "meas = 'Baseline'\n",
    "all_pos = []\n",
    "all_corr = []\n",
    "all_color = []\n",
    "for ii in xrange(len(meta_dict['coherence_info'])):\n",
    "    write('{}-{}\\n'.format(meas, meta_dict['coherence_info'][ii]))\n",
    "    \n",
    "    rv, pv = stats.spearmanr(structural_meas_coh['stim'][:, ii, 0],\n",
    "                             structural_meas_coh['stim'][:, 0, 3])            \n",
    "\n",
    "    all_pos.append(ii)    \n",
    "    all_corr.append(rv)\n",
    "    if pv < (0.05 / 4):\n",
    "        all_color.append([1.0, 0.0, 0.0])\n",
    "    else:\n",
    "        all_color.append(analysis[meas]['color'])\n",
    "    write('rv={:2.2f}, pv={:2.2e}\\n'.format(rv, pv))\n",
    "write('\\n\\n')\n",
    "\n",
    "plt.figure(figsize=(2,1.5), dpi=300.0)\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(left=all_pos, height=all_corr,\n",
    "       width=0.3, color=all_color, lw=0.0)    \n",
    "ax.set_xlim(analysis[meas]['xlim'])\n",
    "ax.set_ylim(analysis[meas]['ylim'])\n",
    "ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "ax.xaxis.set_ticks(np.arange(len(meta_dict['coherence_info']))+0.15)\n",
    "ax.xaxis.set_ticklabels(meta_dict['coherence_freq'])   \n",
    "ax.locator_params(nbins=4, axis='y')    \n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.savefig('{}/Funct_Stim_Loc-Controllability.QA.LinReg.svg'.format(path_Data['Figure'][reref]))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot Controllability to Structure\n",
    "plt.figure(figsize=(1.5,4), dpi=300.0)\n",
    "for m_ii, meas in enumerate(['Average_Cntl', 'Modal_Cntl']):\n",
    "    write('{}\\n'.format(meas))\n",
    "    \n",
    "    ax = plt.subplot(4,1,m_ii+1)    \n",
    "    ax.set_xlim(analysis[meas]['xlim'])\n",
    "    ax.set_ylim(analysis[meas]['ylim'])\n",
    "    if m_ii == 1:\n",
    "        ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "    if m_ii == 0:\n",
    "        ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "    ax.set_title(meas)\n",
    "    ax.locator_params(nbins=3, axis='both')        \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = sns.regplot(x=structural_meas_coh['stim'][:, 0, 1],\n",
    "                     y=structural_meas_coh['stim'][:, 0, m_ii+2],\n",
    "                     color=analysis[meas]['color'],\n",
    "                     scatter_kws={'s':1.0}, ci=68, ax=ax)\n",
    "\n",
    "    slp, yint, rv, pv, stdr = stats.linregress(structural_meas_coh['stim'][:, 0, 1],\n",
    "                                               structural_meas_coh['stim'][:, 0, m_ii+2])\n",
    "    rv, pv = stats.spearmanr(structural_meas_coh['stim'][:, 0, 1],\n",
    "                             structural_meas_coh['stim'][:, 0, m_ii+2])    \n",
    "    write('rv={:2.2f}, pv={:2.2e}\\n'.format(rv, pv))\n",
    "write('\\n\\n')\n",
    "plt.savefig('{}/Struct_Stim_Loc-Controllability.QA.LinReg.svg'.format(path_Data['Figure'][reref]))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key =['Subject_ID',\n",
    "                  'Stim_Anode',\n",
    "                  'Stim_Cathode']\n",
    "meta_stim_type = meta_ps.loc[meta_ps.Stim_Type == 'stimulating']\n",
    "meta_sham_type = meta_ps.loc[meta_ps.Stim_Type == 'sham']\n",
    "\n",
    "meta_stim_lut = meta_stim_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_sham_lut = meta_sham_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_base_lut = meta_base.groupby(['Subject_ID'])['Base_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def compute_evoked_map(cfg_measure):\n",
    "    print('Processing: {}'.format(cfg_measure))\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    evoke_map = {}\n",
    "    for scale_id in meta_dict['atlas_info'][reref].keys():\n",
    "        evoke_map[scale_id] = {}\n",
    "        \n",
    "        atlas_label = meta_dict['atlas_info'][reref][scale_id].keys()\n",
    "    \n",
    "        # Iterate over coherence\n",
    "        for c_ii, coh_id in enumerate(meta_dict['coherence_info']):\n",
    "            evoke_map[scale_id][coh_id] = {'stim': np.zeros((len(atlas_label), len(atlas_label))),\n",
    "                                           'count': np.zeros((len(atlas_label), len(atlas_label)))}\n",
    "            \n",
    "            sel_coh = df_globaltopo_stim[df_globaltopo_stim['Coherence_ID'] == coh_id]\n",
    "\n",
    "            # Iterate over unique stim parameters\n",
    "            for s_ii, (meta_key, ev_ids) in enumerate(meta_stim_lut.iteritems()):\n",
    "                key_dict = dict(zip(unique_stim_key, meta_key))\n",
    "                sel_key_subj = sel_coh.loc[sel_coh.Subject_ID == key_dict['Subject_ID']]\n",
    "                sel_key_ev = sel_key_subj.loc[sel_key_subj.Event_ID.isin(ev_ids)]\n",
    "\n",
    "                delta_pv = sel_key_ev['Stim_' + cfg_measure + '_pv']\n",
    "                evoked_pv = np.array([(ev < 0.05/len(ev)) for ev in delta_pv])\n",
    "                if len(evoked_pv) == 0:\n",
    "                    continue\n",
    "                evoked_pv_mean = np.mean(evoked_pv, axis=0)\n",
    "\n",
    "                # Get the channel indices involved in stimulation\n",
    "                jacksheet = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Jacksheet']\n",
    "                if reref == 'CommonAverage':\n",
    "                    stim_ix = []\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Anode']))\n",
    "                    stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Cathode']))    \n",
    "                    stim_ix = np.unique([iyy for ixx in stim_ix for iyy in ixx])            \n",
    "                else:\n",
    "                    raise Exception('reref currently supports CommonAverage')\n",
    "                    meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]\n",
    "                nonstim_ix = np.setdiff1d(np.arange(len(jacksheet)), stim_ix)\n",
    "\n",
    "                eloc_atlas_idx = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Atlas_Index'][scale_id]\n",
    "                stim_atlas_idx = eloc_atlas_idx[stim_ix]\n",
    "                nonstim_atlas_idx = eloc_atlas_idx[nonstim_ix]\n",
    "\n",
    "                for s_idx in stim_atlas_idx:\n",
    "                    for ns_ii, ns_idx in enumerate(nonstim_atlas_idx):\n",
    "                        evoke_map[scale_id][coh_id]['stim'][s_idx, ns_idx] = evoked_pv_mean[ns_ii]\n",
    "                        evoke_map[scale_id][coh_id]['count'][s_idx, ns_idx] += 1.0\n",
    "    return evoke_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emap = compute_evoked_map('Node_Str_Delta')\n",
    "\n",
    "plt.matshow(emap['scale500']['AlphaTheta']['stim'] / \\\n",
    "            emap['scale500']['AlphaTheta']['count'], cmap='inferno')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key =['Subject_ID',\n",
    "                  'Stim_Anode',\n",
    "                  'Stim_Cathode']\n",
    "meta_stim_type = meta_ps.loc[meta_ps.Stim_Type == 'stimulating']\n",
    "meta_sham_type = meta_ps.loc[meta_ps.Stim_Type == 'sham']\n",
    "\n",
    "meta_stim_lut = meta_stim_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_sham_lut = meta_sham_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_base_lut = meta_base.groupby(['Subject_ID'])['Base_ID'].unique()\n",
    "\n",
    "beh_dict = meta_dict['behavior_info'][reref]\n",
    "#beh_dict = beh_dict[beh_dict.Experiment_ID.isin(['FR2/catFR2', 'FR3/catFR3', 'FR5/catFR5'])]\n",
    "#beh_dict = beh_dict[beh_dict.Experiment_ID.isin(['PAL2', 'PAL3', 'PAL5'])]                  \n",
    "meta_behv_lut = beh_dict.groupby(unique_stim_key)['Delta_Behavior'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@memory.cache\n",
    "def compute_baseline_behavior():\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    vals = np.nan*np.zeros((len(meta_behv_lut), len(meta_dict['coherence_info']), 2))\n",
    "    null_vals = np.nan*np.zeros((len(meta_behv_lut), len(meta_dict['coherence_info']), 10000))\n",
    "    \n",
    "    # Iterate over coherence\n",
    "    for c_ii, coh_id in enumerate(meta_dict['coherence_info']):\n",
    "        sel_coh_base = df_globaltopo_base[df_globaltopo_base['Coherence_ID'] == coh_id]\n",
    "        \n",
    "        # Iterate over unique stim parameters\n",
    "        for s_ii, (meta_key, del_behs) in enumerate(meta_behv_lut.iteritems()):\n",
    "            key_dict = dict(zip(unique_stim_key, meta_key))\n",
    "              \n",
    "            # Get the channel indices involved in stimulation\n",
    "            jacksheet = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Jacksheet']\n",
    "            if reref == 'CommonAverage':\n",
    "                stim_ix = []\n",
    "                stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Anode']))\n",
    "                stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Cathode']))    \n",
    "                stim_ix = np.unique([iyy for ixx in stim_ix for iyy in ixx])            \n",
    "            else:\n",
    "                raise Exception('reref currently supports CommonAverage')\n",
    "            nsstim_ix = np.setdiff1d(np.arange(len(jacksheet)), stim_ix)\n",
    "            \n",
    "            if not (key_dict['Subject_ID'] in sel_coh_base.Subject_ID.tolist()):\n",
    "                continue\n",
    "                \n",
    "            sel_base_subj = sel_coh_base.loc[sel_coh_base.Subject_ID == key_dict['Subject_ID']]\n",
    "            vals[s_ii, c_ii, 0] = sel_base_subj['Base_Node_Str'].iloc[0][:, stim_ix].mean()    \n",
    "            vals[s_ii, c_ii, 1] = np.nan_to_num(np.nanmean(del_behs))\n",
    "            \n",
    "            #for perm_ii in xrange(10000):\n",
    "            #    sel_nsstim_ix = np.random.permutation(nsstim_ix)[:len(stim_ix)]\n",
    "            #    null_vals[s_ii, c_ii, perm_ii] = sel_base_subj['Base_Node_Str'].iloc[0][:, sel_nsstim_ix].mean()    \n",
    "    \n",
    "    # Remove invalid observations\n",
    "    #null_vals = null_vals[np.unique(np.nonzero(~np.isnan(vals))[0]), :, :]        \n",
    "    vals = vals[np.unique(np.nonzero(~np.isnan(vals))[0]), :, :]\n",
    "\n",
    "    return vals, null_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Classifier States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Baseline to Memory Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key =['Subject_ID',\n",
    "                  'Stim_Anode',\n",
    "                  'Stim_Cathode']\n",
    "meta_stim_type = meta_ps.loc[meta_ps.Stim_Type == 'stimulating']\n",
    "meta_sham_type = meta_ps.loc[meta_ps.Stim_Type == 'sham']\n",
    "\n",
    "meta_stim_lut = meta_stim_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_sham_lut = meta_sham_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_base_lut = meta_base.groupby(['Subject_ID'])['Base_ID'].unique()\n",
    "\n",
    "meta_memr = meta_dict['memory_info'][reref]\n",
    "meta_memr['Delta_Prob'] = meta_memr['Post_Stim_Prob'] - meta_memr['Pre_Stim_Prob']\n",
    "meta_memr_lut = meta_memr.groupby(unique_stim_key)['Delta_Prob'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Node Strength with Average Memory Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def compute_baseline_memclass():\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    vals = {'stim': np.nan*np.zeros((len(meta_memr_lut), len(meta_dict['coherence_info']), 2)),\n",
    "            'null': np.nan*np.zeros((len(meta_memr_lut), len(meta_dict['coherence_info']), 10000))}\n",
    "    \n",
    "    # Iterate over coherence\n",
    "    for c_ii, coh_id in enumerate(meta_dict['coherence_info']):\n",
    "        sel_coh_base = df_globaltopo_base[df_globaltopo_base['Coherence_ID'] == coh_id]\n",
    "        \n",
    "        # Iterate over unique stim parameters\n",
    "        for s_ii, (meta_key, del_behs) in enumerate(meta_memr_lut.iteritems()):\n",
    "            key_dict = dict(zip(unique_stim_key, meta_key))\n",
    "              \n",
    "            # Get the channel indices involved in stimulation\n",
    "            jacksheet = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Jacksheet']\n",
    "            if reref == 'CommonAverage':\n",
    "                stim_ix = []\n",
    "                stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Anode']))\n",
    "                stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Cathode']))    \n",
    "                stim_ix = np.unique([iyy for ixx in stim_ix for iyy in ixx])            \n",
    "            else:\n",
    "                raise Exception('reref currently supports CommonAverage')\n",
    "            nsstim_ix = np.setdiff1d(np.arange(len(jacksheet)), stim_ix)\n",
    "            \n",
    "            if not (key_dict['Subject_ID'] in sel_coh_base.Subject_ID.tolist()):\n",
    "                continue\n",
    "\n",
    "            if (len(stim_ix) == 0) or (len(nsstim_ix) == 0):\n",
    "                continue\n",
    "                                \n",
    "            sel_base_subj = sel_coh_base.loc[sel_coh_base.Subject_ID == key_dict['Subject_ID']]\n",
    "            vals['stim'][s_ii, c_ii, 0] = sel_base_subj['Base_Node_Str'].iloc[0][:, stim_ix].mean()    \n",
    "            vals['stim'][s_ii, c_ii, 1] = np.nan_to_num(np.nanmean(del_behs))\n",
    "            \n",
    "            for perm_ii in xrange(10000):\n",
    "                sel_nsstim_ix = np.random.permutation(nsstim_ix)[:len(stim_ix)]\n",
    "                vals['null'][s_ii, c_ii, perm_ii] = sel_base_subj['Base_Node_Str'].iloc[0][:, sel_nsstim_ix].mean()\n",
    "\n",
    "    # Remove invalid observations\n",
    "    vals['null'] = vals['null'][np.unique(np.nonzero(~np.isnan(vals['stim']))[0]), :, :]        \n",
    "    vals['stim'] = vals['stim'][np.unique(np.nonzero(~np.isnan(vals['stim']))[0]), :, :]\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Comparative Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Node_Str_Delta':   {'xlabel': 'Frequency Range',\n",
    "                                 'ylabel': 'Corr. Baseline, Mem. Enc. State ',\n",
    "                                 'xlim': [-0.5, len(meta_dict['coherence_info'])-0.5],\n",
    "                                 'ylim': [0.0, 0.15],\n",
    "                                 'stim': {'color': [1.0, 0.3, 0.3]},\n",
    "                                 'null': {'color': [0.2, 0.2, 0.2]}}}\n",
    "n_grp = len(meta_dict['coherence_freq'])            \n",
    "\n",
    "for meas in analysis.keys():\n",
    "    vals = compute_baseline_memclass()\n",
    "        \n",
    "    all_corr = []\n",
    "    all_mean = []\n",
    "    all_serr = []\n",
    "    all_color = []\n",
    "    all_pos = []\n",
    "    all_pv = []\n",
    "    for c_ii in xrange(n_grp):\n",
    "        true_rho = stats.spearmanr(vals['stim'][:, c_ii, 0], vals['stim'][:, c_ii, 1])[0]\n",
    "        \n",
    "        null_rho = []\n",
    "        for n_ii in xrange(vals['null'].shape[2]):\n",
    "            null_rho.append(np.arctanh(stats.spearmanr(vals['null'][:, c_ii, n_ii], vals['stim'][:, c_ii, 1])[0]))\n",
    "        null_rho = np.array(null_rho)\n",
    "        \n",
    "        all_pv.append(np.mean(null_rho > true_rho))\n",
    "        \n",
    "        for corr in [[true_rho], null_rho]:\n",
    "            all_mean.append(np.nanmean(corr))\n",
    "            all_serr.append(np.nanstd(corr) / np.sqrt(len(corr)))\n",
    "            all_color.append(analysis[meas][tp]['color'])\n",
    "            all_pos.append(c_ii + 0.2*tp_ii)\n",
    "        \n",
    "    plt.figure(figsize=(2,1.5), dpi=300.0)\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    ax.bar(left=all_pos, height=all_mean, yerr=all_serr,\n",
    "           width=0.2, color=all_color, lw=0.0)\n",
    "    \n",
    "    ax.set_xlim(analysis[meas]['xlim'])\n",
    "    ax.set_ylim(analysis[meas]['ylim'])\n",
    "    ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "    ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "    ax.xaxis.set_ticks(np.arange(n_grp)+0.2)\n",
    "    ax.xaxis.set_ticklabels(meta_dict['coherence_freq'])\n",
    "    ax.locator_params(nbins=4, axis='y')    \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    #plt.savefig('{}/Evoked_Nodes-Func_Coherence.BarPlot.svg'.format(path_Data['Figure'][reref]))\n",
    "    #plt.close()\n",
    "\n",
    "    \"\"\"\n",
    "    for ff in xrange(len(meta_dict['coherence_freq'])):\n",
    "        write('{}\\n'.format(meta_dict['coherence_freq'][ff]))\n",
    "        write('t-test: {}\\n'.format(stats.ttest_rel(all_corr[0][:, ff], all_corr[1][:, ff])))\n",
    "        write('cohens: {}\\n\\n'.format(cohens_d(all_corr[0][:, ff], all_corr[1][:, ff])))\n",
    "    write('Anova: {}\\n'.format(stats.f_oneway(*all_corr[0].T)))\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Structural Control to Memory Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find unique stimulation parameter sets\n",
    "# Criteria: Subject_ID, Stim_Freq, Stim_Amp, Stim_Dur, Stim_Anode, Stim_Cathode\n",
    "unique_stim_key =['Subject_ID',\n",
    "                  'Stim_Anode',\n",
    "                  'Stim_Cathode']\n",
    "meta_stim_type = meta_ps.loc[meta_ps.Stim_Type == 'stimulating']\n",
    "meta_sham_type = meta_ps.loc[meta_ps.Stim_Type == 'sham']\n",
    "\n",
    "meta_stim_lut = meta_stim_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_sham_lut = meta_sham_type.groupby(unique_stim_key)['Event_ID'].unique()\n",
    "meta_base_lut = meta_base.groupby(['Subject_ID'])['Base_ID'].unique()\n",
    "\n",
    "meta_memr = meta_dict['memory_info'][reref]\n",
    "meta_memr['Delta_Prob'] = meta_memr['Post_Stim_Prob'] - meta_memr['Pre_Stim_Prob']\n",
    "meta_memr_lut = meta_memr.groupby(unique_stim_key)['Delta_Prob'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controllability with Average Memory Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@memory.cache\n",
    "def compute_structural_memclass(loc_type):\n",
    "    \n",
    "    # Initialize the measurement buckets\n",
    "    vals = np.nan*np.zeros((len(meta_memr_lut), 2))\n",
    "    locs = {}\n",
    "            \n",
    "    # Iterate over unique stim parameters\n",
    "    for s_ii, (meta_key, del_behs) in enumerate(meta_memr_lut.iteritems()):\n",
    "        key_dict = dict(zip(unique_stim_key, meta_key))\n",
    "\n",
    "        # Get the channel indices involved in stimulation\n",
    "        jacksheet = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Jacksheet']\n",
    "        if reref == 'CommonAverage':\n",
    "            stim_ix = []\n",
    "            stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Anode']))\n",
    "            stim_ix.append(np.flatnonzero(jacksheet == key_dict['Stim_Cathode']))    \n",
    "            stim_ix = np.unique([iyy for ixx in stim_ix for iyy in ixx])            \n",
    "        else:\n",
    "            raise Exception('reref currently supports CommonAverage')\n",
    "        nsstim_ix = np.setdiff1d(np.arange(len(jacksheet)), stim_ix)\n",
    "\n",
    "        if (len(stim_ix) == 0) or (len(nsstim_ix) == 0):\n",
    "            continue\n",
    "            \n",
    "        if not (key_dict['Subject_ID'] in meta_dict['struct_adj'][reref].keys()):\n",
    "            continue\n",
    "\n",
    "        scale_id = 'scale125'\n",
    "        atlas_index = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Atlas_Index'][scale_id]\n",
    "        atlas_label = meta_dict['electrode_loc'][reref][key_dict['Subject_ID']][reref]['Atlas_Label'][scale_id]        \n",
    "        adj_struct = meta_dict['struct_adj'][reref][key_dict['Subject_ID']][scale_id]['QA']['adj']\n",
    "        \n",
    "        if loc_type == 'Struct_Degree':\n",
    "            struct_val = np.mean(adj_struct, axis=0)\n",
    "        \n",
    "        if loc_type == 'Struct_Avg_Cntl':\n",
    "            struct_val = structural_control.average_control(adj_struct)\n",
    "        \n",
    "        if loc_type == 'Struct_Mod_Cntl':\n",
    "            struct_val = structural_control.modal_control(adj_struct)            \n",
    "        \n",
    "        struct_val = (struct_val - struct_val.mean()) / struct_val.std()\n",
    "        \n",
    "        \n",
    "        not_LTC = True\n",
    "        for s_ix in stim_ix:\n",
    "            stim_lbl = atlas_label[s_ix]\n",
    "            if stim_lbl.split('_')[1] in meta_dict['LTC_info']:\n",
    "                not_LTC = False\n",
    "                if not stim_lbl in locs.keys():\n",
    "                    locs[stim_lbl] = []\n",
    "                locs[stim_lbl].append(struct_val[atlas_index][s_ix])\n",
    "        if not_LTC:\n",
    "            continue\n",
    "        \n",
    "        vals[s_ii, 0] = np.nan_to_num(np.nanmean(del_behs))\n",
    "        vals[s_ii, 1] = np.nanmean(struct_val[atlas_index][stim_ix])\n",
    "            \n",
    "    # Remove invalid observations\n",
    "    vals = vals[np.unique(np.nonzero(~np.isnan(vals))[0]), :]\n",
    "\n",
    "    return vals, locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Linear Regression for Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = {'Struct_Degree':     {'xlabel': 'Struc. Node Strength',\n",
    "                                  'ylabel': 'Mem. Enc. State',\n",
    "                                  'xlim': [0.0, 0.01],\n",
    "                                  'ylim': [-0.02, 0.02],\n",
    "                                  'color': [0.2, 0.2, 0.2]},\n",
    "            'Struct_Avg_Cntl':   {'xlabel': 'Average Controll.',\n",
    "                                  'ylabel': 'Mem. Enc. State',\n",
    "                                  'xlim': [1.00, 1.06],\n",
    "                                  'ylim': [-0.02, 0.02],\n",
    "                                  'color': [0.2, 0.2, 0.2]},\n",
    "            'Struct_Mod_Cntl':   {'xlabel': 'Modal Controllability\\n(z-score)',\n",
    "                                  'ylabel': 'Mem. Enc. State',\n",
    "                                  'xlim': [-1.5, 1.5],\n",
    "                                  'ylim': [-0.02, 0.02],                             \n",
    "                                  'color': [0.2, 0.2, 0.2]}}\n",
    "\n",
    "for meas in ['Struct_Mod_Cntl']: #analysis.keys():\n",
    "    vals, locs = compute_structural_memclass(meas)\n",
    "    \n",
    "    plt.figure(figsize=(1.5,4), dpi=300.0)\n",
    "    ax = plt.subplot(4,1,1)\n",
    "    ax.set_xlim(analysis[meas]['xlim'])\n",
    "    ax.set_ylim(analysis[meas]['ylim'])\n",
    "    ax.set_xlabel(analysis[meas]['xlabel'])\n",
    "    ax.set_ylabel(analysis[meas]['ylabel'])\n",
    "    ax.locator_params(nbins=3, axis='both')\n",
    "    #if meas == 'Struct_Avg_Cntl':\n",
    "    #    ax.locator_params(nbins=4, axis='x')\n",
    "    ax.set_xticks([-1.5, 0, 1.5])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = sns.regplot(x=vals[:, 1], y=vals[:, 0],\n",
    "                     color=analysis[meas]['color'],\n",
    "                     scatter_kws={'s':1.0}, ci=68, ax=ax)\n",
    "\n",
    "    slp, yint, rv, pv, stdr = stats.linregress(vals[:, 1], vals[:, 0])\n",
    "    #rv, pv = stats.spearmanr(vals[:, 1], vals[:, 0])\n",
    "    write('{}: rv={:2.2f}, pv={:2.2e}\\n'.format(meas, rv, pv))\n",
    "    write('\\n')\n",
    "    \n",
    "    plt.savefig('{}/{}-Mem_Enc_State.LinReg.svg'.format(path_Data['Figure'][reref], meas))\n",
    "    plt.close()\n",
    "write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modal Controllability Distribution (MNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_modal_ctl = np.array([structural_control.modal_control(meta_dict['struct_adj']['CommonAverage'][subj_key]['scale125']['QA']['adj'])\n",
    "                          for subj_key in meta_dict['struct_adj']['CommonAverage'].keys()])\n",
    "\n",
    "pop_modal_ctl = pop_modal_ctl.mean(axis=0)\n",
    "pop_modal_ctl_zscored = pop_modal_ctl\n",
    "#pop_modal_ctl_zscored = (pop_modal_ctl - pop_modal_ctl.mean()) / pop_modal_ctl.std()\n",
    "\n",
    "\n",
    "itksnap_list = [[0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "norm = plt.Normalize(vmin=0.96, vmax=1.0)\n",
    "cmap = plt.get_cmap('Spectral_r')\n",
    "for ii, mm in enumerate(pop_modal_ctl_zscored):\n",
    "    rgba = cmap(norm(mm))\n",
    "    \n",
    "    itksnap_list.append([ii+1, int(255*rgba[0]), int(255*rgba[1]), int(255*rgba[2]), 1, 1, 1, ii+1])\n",
    "np.savetxt('/Users/akhambhati/Remotes/CORE.MRI_Atlases/Lausanne/modal.txt', itksnap_list, fmt='    %2d    %3d    %3d    %3d        %d  %d  %d    \\\"%s\\\"')\n",
    "    \n",
    "# IDX   -R-  -G-  -B-  -A--  VIS MSH  LABEL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Energy Landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x, y = np.mgrid[-1:1:.005, -1:1:.005]\n",
    "pos = np.empty(x.shape + (2,))\n",
    "pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "rv_1 = stats.multivariate_normal(mean=[-0.50, +0.50], cov=[0.04, 0.04])\n",
    "rv_2 = stats.multivariate_normal(mean=[+0.00, -0.50], cov=[0.25, 0.25])\n",
    "rv_3 = stats.multivariate_normal(mean=[+0.25, +0.75], cov=[0.10, 0.10])\n",
    "rv = 0.75*rv_1.pdf(pos) + 2.00*rv_2.pdf(pos) + rv_3.pdf(pos)\n",
    "rv = (rv - rv.min()) / (rv.max()-rv.min())\n",
    "\n",
    "fig = plt.figure(figsize=(3,3), dpi=300.0)\n",
    "ax = fig.gca(projection='3d')\n",
    "ss = ax.plot_surface(x, y, rv, cmap=plt.cm.YlGnBu_r, lw=0.0)\n",
    "ax.view_init(25, -40)\n",
    "ax.set_axis_off()\n",
    "plt.colorbar(ss, ax=ax)\n",
    "plt.savefig('{}/Artifical_Energy_Landscape.svg'.format(path_Data['Figure'][reref]))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "336px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "880px",
    "left": "0px",
    "right": "1707px",
    "top": "107px",
    "width": "432px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "655px",
   "left": "1562.08px",
   "right": "20px",
   "top": "129px",
   "width": "340px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
