{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev1 toc-item\"><a href=\"#Gather-all-data-sets\" data-toc-modified-id=\"Gather-all-data-sets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Gather all data sets</a></div><div class=\"lev2 toc-item\"><a href=\"#Structural-data\" data-toc-modified-id=\"Structural-data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Structural data</a></div><div class=\"lev2 toc-item\"><a href=\"#Channel-data\" data-toc-modified-id=\"Channel-data-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Channel data</a></div><div class=\"lev2 toc-item\"><a href=\"#Baseline-data\" data-toc-modified-id=\"Baseline-data-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Baseline data</a></div><div class=\"lev2 toc-item\"><a href=\"#Stim-data\" data-toc-modified-id=\"Stim-data-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Stim data</a></div><div class=\"lev2 toc-item\"><a href=\"#Memory-State-data\" data-toc-modified-id=\"Memory-State-data-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Memory State data</a></div><div class=\"lev1 toc-item\"><a href=\"#Figures-for-pipeline\" data-toc-modified-id=\"Figures-for-pipeline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Figures for pipeline</a></div><div class=\"lev2 toc-item\"><a href=\"#Project-Population-Level-Electrodes-to-Surface\" data-toc-modified-id=\"Project-Population-Level-Electrodes-to-Surface-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Project Population-Level Electrodes to Surface</a></div><div class=\"lev2 toc-item\"><a href=\"#Plot-time-series-from-baseline---&gt;-stim\" data-toc-modified-id=\"Plot-time-series-from-baseline--->-stim-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Plot time-series from baseline --&gt; stim</a></div><div class=\"lev2 toc-item\"><a href=\"#Plot-the-Adjacency-Matrices-for-the-above-trial\" data-toc-modified-id=\"Plot-the-Adjacency-Matrices-for-the-above-trial-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Plot the Adjacency Matrices for the above trial</a></div><div class=\"lev2 toc-item\"><a href=\"#Plot-the-Adjacency-Matrices-for-the-baseline\" data-toc-modified-id=\"Plot-the-Adjacency-Matrices-for-the-baseline-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Plot the Adjacency Matrices for the baseline</a></div><div class=\"lev1 toc-item\"><a href=\"#Measure-Evoked-Topology\" data-toc-modified-id=\"Measure-Evoked-Topology-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Measure Evoked Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Baseline-Topology\" data-toc-modified-id=\"Baseline-Topology-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Baseline Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Stim-Topology\" data-toc-modified-id=\"Stim-Topology-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Stim Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Pre-Compute-Measures\" data-toc-modified-id=\"Pre-Compute-Measures-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Pre-Compute Measures</a></div><div class=\"lev1 toc-item\"><a href=\"#Functional-Network-Reorganization\" data-toc-modified-id=\"Functional-Network-Reorganization-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Functional Network Reorganization</a></div><div class=\"lev2 toc-item\"><a href=\"#Mean-Connection-Strength\" data-toc-modified-id=\"Mean-Connection-Strength-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Mean Connection Strength</a></div><div class=\"lev2 toc-item\"><a href=\"#Topological-Similarity\" data-toc-modified-id=\"Topological-Similarity-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Topological Similarity</a></div><div class=\"lev2 toc-item\"><a href=\"#Evoked-Node-Strength\" data-toc-modified-id=\"Evoked-Node-Strength-53\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Evoked Node Strength</a></div><div class=\"lev1 toc-item\"><a href=\"#Distinct-Modes-of-Functional-Control\" data-toc-modified-id=\"Distinct-Modes-of-Functional-Control-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Distinct Modes of Functional Control</a></div><div class=\"lev2 toc-item\"><a href=\"#Topological-Similarity-vs.-Evoked-Node-Strength\" data-toc-modified-id=\"Topological-Similarity-vs.-Evoked-Node-Strength-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Topological Similarity vs. Evoked Node Strength</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Baseline-Variance-of-Coherence\" data-toc-modified-id=\"Effect-of-Baseline-Variance-of-Coherence-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Effect of Baseline Variance of Coherence</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity\" data-toc-modified-id=\"On-Topological-Similarity-621\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>On Topological Similarity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Evoked-Node-Strengths\" data-toc-modified-id=\"On-Evoked-Node-Strengths-622\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>On Evoked Node Strengths</a></div><div class=\"lev2 toc-item\"><a href=\"#Geometric-Predictors-of-Localized-Changes\" data-toc-modified-id=\"Geometric-Predictors-of-Localized-Changes-63\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Geometric Predictors of Localized Changes</a></div><div class=\"lev3 toc-item\"><a href=\"#Functional-Topological-Effect-of-Baseline-Connectivity\" data-toc-modified-id=\"Functional-Topological-Effect-of-Baseline-Connectivity-631\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Functional Topological Effect of Baseline Connectivity</a></div><div class=\"lev3 toc-item\"><a href=\"#Structural-Topological-Effect\" data-toc-modified-id=\"Structural-Topological-Effect-632\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Structural Topological Effect</a></div><div class=\"lev3 toc-item\"><a href=\"#Spatial-Effect-of-Distance-to-Stim\" data-toc-modified-id=\"Spatial-Effect-of-Distance-to-Stim-633\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>Spatial Effect of Distance to Stim</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Input-Energy\" data-toc-modified-id=\"Effect-of-Input-Energy-64\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Effect of Input Energy</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity\" data-toc-modified-id=\"On-Topological-Similarity-641\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>On Topological Similarity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Evoked-Node\" data-toc-modified-id=\"On-Evoked-Node-642\"><span class=\"toc-item-num\">6.4.2&nbsp;&nbsp;</span>On Evoked Node</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Stimulation-Location-(Functional-Hubness)\" data-toc-modified-id=\"Effect-of-Stimulation-Location-(Functional-Hubness)-65\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Effect of Stimulation Location (Functional Hubness)</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity\" data-toc-modified-id=\"On-Topological-Similarity-651\"><span class=\"toc-item-num\">6.5.1&nbsp;&nbsp;</span>On Topological Similarity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Evoked-Node-Strengths\" data-toc-modified-id=\"On-Evoked-Node-Strengths-652\"><span class=\"toc-item-num\">6.5.2&nbsp;&nbsp;</span>On Evoked Node Strengths</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Stimulation-Location-(Structural-Hubness)\" data-toc-modified-id=\"Effect-of-Stimulation-Location-(Structural-Hubness)-66\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>Effect of Stimulation Location (Structural Hubness)</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity\" data-toc-modified-id=\"On-Topological-Similarity-661\"><span class=\"toc-item-num\">6.6.1&nbsp;&nbsp;</span>On Topological Similarity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Evoked-Node-Strengths\" data-toc-modified-id=\"On-Evoked-Node-Strengths-662\"><span class=\"toc-item-num\">6.6.2&nbsp;&nbsp;</span>On Evoked Node Strengths</a></div><div class=\"lev1 toc-item\"><a href=\"#Modulation-Map\" data-toc-modified-id=\"Modulation-Map-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Modulation Map</a></div><div class=\"lev2 toc-item\"><a href=\"#Compute-the-map\" data-toc-modified-id=\"Compute-the-map-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Compute the map</a></div><div class=\"lev2 toc-item\"><a href=\"#Effects-of-Structural-Connectivity-on-Regional-Modulation\" data-toc-modified-id=\"Effects-of-Structural-Connectivity-on-Regional-Modulation-72\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Effects of Structural Connectivity on Regional Modulation</a></div><div class=\"lev1 toc-item\"><a href=\"#Miscellaneous\" data-toc-modified-id=\"Miscellaneous-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Miscellaneous</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Stimulation-Location-(Functional-Region)\" data-toc-modified-id=\"Effect-of-Stimulation-Location-(Functional-Region)-81\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Effect of Stimulation Location (Functional Region)</a></div><div class=\"lev3 toc-item\"><a href=\"#Baseline-Node-Strength\" data-toc-modified-id=\"Baseline-Node-Strength-811\"><span class=\"toc-item-num\">8.1.1&nbsp;&nbsp;</span>Baseline Node Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Mean-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Mean-Change-in-Connection-Strength-812\"><span class=\"toc-item-num\">8.1.2&nbsp;&nbsp;</span>On Mean Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Variance-of-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Variance-of-Change-in-Connection-Strength-813\"><span class=\"toc-item-num\">8.1.3&nbsp;&nbsp;</span>On Variance of Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity-of-Evoked-Connectivity\" data-toc-modified-id=\"On-Topological-Similarity-of-Evoked-Connectivity-814\"><span class=\"toc-item-num\">8.1.4&nbsp;&nbsp;</span>On Topological Similarity of Evoked Connectivity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Modulated-Hubness-of-Brain-Regions\" data-toc-modified-id=\"On-Modulated-Hubness-of-Brain-Regions-815\"><span class=\"toc-item-num\">8.1.5&nbsp;&nbsp;</span>On Modulated Hubness of Brain Regions</a></div><div class=\"lev1 toc-item\"><a href=\"#Generate-Electrode-Level-Adjacency-Matrices\" data-toc-modified-id=\"Generate-Electrode-Level-Adjacency-Matrices-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Generate Electrode-Level Adjacency Matrices</a></div><div class=\"lev1 toc-item\"><a href=\"#Memory-States\" data-toc-modified-id=\"Memory-States-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Memory States</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Input-Energy\" data-toc-modified-id=\"Effect-of-Input-Energy-101\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Effect of Input Energy</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Stimulation-Location-(Structural-Control)\" data-toc-modified-id=\"Effect-of-Stimulation-Location-(Structural-Control)-102\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Effect of Stimulation Location (Structural Control)</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Network-Reorganization-on-Memory-State\" data-toc-modified-id=\"Effect-of-Network-Reorganization-on-Memory-State-103\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>Effect of Network Reorganization on Memory State</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Network-State-on-Memory-State\" data-toc-modified-id=\"Effect-of-Network-State-on-Memory-State-104\"><span class=\"toc-item-num\">10.4&nbsp;&nbsp;</span>Effect of Network State on Memory State</a></div><div class=\"lev3 toc-item\"><a href=\"#Optimal-stim-state-identification\" data-toc-modified-id=\"Optimal-stim-state-identification-1041\"><span class=\"toc-item-num\">10.4.1&nbsp;&nbsp;</span>Optimal stim state identification</a></div><div class=\"lev2 toc-item\"><a href=\"#Prepare-data-for-trajectory-analysis-(for-Jeni)\" data-toc-modified-id=\"Prepare-data-for-trajectory-analysis-(for-Jeni)-105\"><span class=\"toc-item-num\">10.5&nbsp;&nbsp;</span>Prepare data for trajectory analysis (for Jeni)</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "rcParams.update(rcParams)\n",
    "\n",
    "path_AtlasData = '/Users/akhambhati/Remotes/CORE.MRI_Atlases'\n",
    "path_CoreData = '/Users/akhambhati/Remotes/CORE.RAM_Stim'\n",
    "path_PeriphData = '/Users/akhambhati/Remotes/RSRCH.RAM_Stim'\n",
    "path_InpData = path_PeriphData + '/e01-FuncNetw'\n",
    "path_InpData_Baseline = path_PeriphData + '/e01b-FuncNetw'\n",
    "path_ExpData = path_PeriphData + '/e02-GlobalTopo'\n",
    "path_Figures = './e02-Figures'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData, path_Figures]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather all data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('{}/structural_dict.pkl'.format(path_ExpData)):\n",
    "    struct_dict = pkl.load(open('{}/structural_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    stradj_subj = glob.glob('{}/Adjacency_Matrices/Epilepsy_Subjects/lausanne/*'.format(path_CoreData))\n",
    "    struct_subj = glob.glob('{}/Controllability/Parcel_ROI/Epilepsy_Subjects/lausanne/*'.format(path_CoreData))\n",
    "    struct_dict = {'Subject': {},\n",
    "                   'Atlas': {'scale33': {},\n",
    "                             'scale60': {},\n",
    "                             'scale125': {},\n",
    "                             'scale250': {}}}\n",
    "\n",
    "    for scale in struct_dict['Atlas'].keys():\n",
    "\n",
    "        # Populate controllabiliy\n",
    "        for sadj_path, full_path in zip(stradj_subj, struct_subj):\n",
    "            subj_id = full_path.split('/')[-1]\n",
    "            try:\n",
    "                struct_dict['Subject'][subj_id]\n",
    "            except:\n",
    "                struct_dict['Subject'][subj_id] = {}\n",
    "            struct_dict['Subject'][subj_id][scale] = {}        \n",
    "\n",
    "            adj_gfa_path = glob.glob('{}/*ROIv_{}*{}*.mat'.format(sadj_path, scale, 'gfa'))[0]\n",
    "            adj_gfa = io.loadmat(adj_gfa_path)['connectivity']\n",
    "            ctl_gfa_path = glob.glob('{}/*{}*{}*.mat'.format(full_path, scale, 'gfa'))[0]\n",
    "            avg_ctl_gfa = io.loadmat(ctl_gfa_path)['avg_vector'][:, 0]\n",
    "            mod_ctl_gfa = io.loadmat(ctl_gfa_path)['modal_vector'][:, 0]            \n",
    "\n",
    "            adj_qa_path = glob.glob('{}/*ROIv_{}*{}*.mat'.format(sadj_path, scale, 'qa'))[0]            \n",
    "            adj_qa = io.loadmat(adj_qa_path)['connectivity']            \n",
    "            ctl_qa_path = glob.glob('{}/*{}*{}*.mat'.format(full_path, scale, 'qa'))[0]\n",
    "            avg_ctl_qa = io.loadmat(ctl_qa_path)['avg_vector'][:, 0]\n",
    "            mod_ctl_qa = io.loadmat(ctl_qa_path)['modal_vector'][:, 0]  \n",
    "\n",
    "            # Populate the subject dict\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA'] = {}\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA']['adj'] = adj_gfa\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA']['avg_ctl'] = avg_ctl_gfa\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA']['mod_ctl'] = mod_ctl_gfa        \n",
    "            struct_dict['Subject'][subj_id][scale]['QA'] = {}        \n",
    "            struct_dict['Subject'][subj_id][scale]['QA']['adj'] = adj_qa            \n",
    "            struct_dict['Subject'][subj_id][scale]['QA']['avg_ctl'] = avg_ctl_qa\n",
    "            struct_dict['Subject'][subj_id][scale]['QA']['mod_ctl'] = mod_ctl_qa        \n",
    "\n",
    "\n",
    "        # Populate MNI Coordinates for each ROI of each Lausanne Atlas\n",
    "        # Find voxel coordinates for each ROI\n",
    "        atlas_label = pd.read_csv('{}/Lausanne/{}.csv'.format(path_AtlasData, scale))    \n",
    "        atlas = nib.load('{}/Lausanne/lausanne/ROIv_{}_dilated.nii.gz'.format(path_AtlasData, scale))\n",
    "        atlas_data = atlas.get_data()\n",
    "        for roi_id in np.unique(atlas_data)[1:]:        \n",
    "            i,j,k = np.nonzero(atlas_data == roi_id)\n",
    "\n",
    "            roi_coords = []\n",
    "            for ii, jj, kk in zip(i, j, k):\n",
    "                xx, yy, zz = atlas.affine[:3, :3].dot([ii, jj, kk]) + atlas.affine[:3, 3]\n",
    "                roi_coords.append((xx, yy, zz))\n",
    "            roi_coords = np.array(roi_coords)\n",
    "\n",
    "            # Add to coords for ROI label to dict\n",
    "            sel_lbl = (atlas_label['Label_ID'] == roi_id)\n",
    "            roi_lbl = (atlas_label[sel_lbl]['Hemisphere'] + '_' + atlas_label[sel_lbl]['ROI']).as_matrix()[0]\n",
    "            struct_dict['Atlas'][scale][roi_lbl] = roi_coords\n",
    "\n",
    "    pkl.dump(struct_dict, open('{}/structural_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "print('There are {} processed structural datasets to analyze.'.format(len(struct_dict['Subject'].keys())))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/channel_dict.pkl'.format(path_ExpData)):\n",
    "    channel_dict = pkl.load(open('{}/channel_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    channel_subj = glob.glob('{}/Exp_Info/Channel_Info/*.mat'.format(path_CoreData))\n",
    "    channel_dict = {'Subject': {}}\n",
    "    \"\"\"\n",
    "    contains:  \n",
    "    - Jacksheet #: int\n",
    "    - Label: (good_channels x 1)\n",
    "    - Atlas_Label: {'scale': (good_channels x 1)}    \n",
    "    - MNI_Coord: (good_channels x 3)\n",
    "    - Dist_Matrix: spatial distances between electrodes\n",
    "    - Struct_Adj: scale and track_type, electrode adjacency matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    for full_path in channel_subj:\n",
    "        subj_id = full_path.split('/')[-1].split('.')[0]\n",
    "        try:\n",
    "            channel_dict['Subject'][subj_id]\n",
    "        except:\n",
    "            channel_dict['Subject'][subj_id] = {}        \n",
    "        \n",
    "        ### Get channel map for subject\n",
    "        chan_file = glob.glob('{}/Exp_Info/Channel_Info/{}.mat'.format(path_CoreData, subj_id))\n",
    "        if len(chan_file) != 1:\n",
    "            continue\n",
    "        df_chan = io.loadmat(chan_file[0])\n",
    "        if df_chan['good_channels_jack'].shape[1] != df_chan['good_channels_ind'].shape[1]:\n",
    "            continue\n",
    "        if df_chan['good_channels_jack'].shape[1] != df_chan['good_channels_lbl'].shape[1]:\n",
    "            continue\n",
    "            \n",
    "        ### Reformat channel labels\n",
    "        chan_lbl = np.array([lbl[0] for lbl in df_chan['good_channels_lbl'][0, :]])\n",
    "            \n",
    "        ### MNI Coords for good channels\n",
    "        mni_coords = []\n",
    "        for gc in df_chan['good_channels_jack'][0, :]:\n",
    "            gc_ix = np.flatnonzero(df_chan['xyzcoords'][:, 0] == gc)\n",
    "            if len(gc_ix) > 0:\n",
    "                mni_coords.append(tuple(df_chan['xyzcoords'][gc_ix[0], 1:]))\n",
    "            else:\n",
    "                mni_coords.append(tuple([np.nan, np.nan, np.nan]))\n",
    "        mni_coords = np.array(mni_coords)\n",
    "        if len(np.flatnonzero(np.isnan(mni_coords))) > 0:\n",
    "            print(subj_id + ' -- contains unlocalized channels')\n",
    "        else:\n",
    "            print(subj_id)\n",
    "        \n",
    "        ### Compute Inter-Electrode Distances\n",
    "        n_node = df_chan['good_channels_jack'].shape[1]\n",
    "        dist_matr = np.zeros((n_node, n_node))\n",
    "        triu_ix, triu_iy = np.triu_indices(n_node, k=1)\n",
    "        for ix, iy in zip(triu_ix, triu_iy):\n",
    "            ix_chan_loc = mni_coords[ix, :]\n",
    "            iy_chan_loc = mni_coords[iy, :]            \n",
    "            dist_matr[ix, iy] = np.sqrt(np.sum((ix_chan_loc-iy_chan_loc)**2))            \n",
    "        dist_matr += dist_matr.T\n",
    "        \n",
    "        ### Assign channel to an ROI using greedy approach\n",
    "        atlas_label = {}\n",
    "        for scale in struct_dict['Atlas'].keys():\n",
    "            roi_names = struct_dict['Atlas'][scale].keys()\n",
    "            chan_assign = []\n",
    "            for ch_crd in mni_coords:\n",
    "                roi_voxel_dist = []\n",
    "                for roi in roi_names:\n",
    "                    roi_crd = struct_dict['Atlas'][scale][roi]\n",
    "                    nearest_voxel = np.min(np.sqrt(np.sum((ch_crd - roi_crd)**2, axis=1)))\n",
    "                    roi_voxel_dist.append(nearest_voxel)\n",
    "                roi_ix = np.argmin(roi_voxel_dist)\n",
    "                chan_assign.append(roi_names[roi_ix])\n",
    "            atlas_label[scale] = np.array(chan_assign)\n",
    "\n",
    "        ### Compute channel-level structural connectivity matrix\n",
    "        struct_adj = {}\n",
    "        subj_id_abrv = subj_id.split('_')[0]\n",
    "        for scale in struct_dict['Atlas'].keys():\n",
    "            struct_adj[scale] = {}\n",
    "            \n",
    "            roi_names = np.array(struct_dict['Atlas'][scale].keys())\n",
    "            n_chan = len(atlas_label[scale])\n",
    "            assert n_chan == len(chan_lbl)\n",
    "            \n",
    "            for trk_type in ['QA', 'GFA']:\n",
    "                if subj_id_abrv not in struct_dict['Subject'].keys():\n",
    "                    struct_adj[scale][trk_type] = np.nan\n",
    "                    continue\n",
    "\n",
    "                roi_adj = struct_dict['Subject'][subj_id_abrv][scale][trk_type]['adj']\n",
    "                chan_adj = np.zeros((n_chan, n_chan))\n",
    "                for ch_ix, lbl_x in enumerate(atlas_label[scale]):\n",
    "                    for ch_iy, lbl_y in enumerate(atlas_label[scale]):\n",
    "                        ix = np.flatnonzero(roi_names == lbl_x)[0]\n",
    "                        iy = np.flatnonzero(roi_names == lbl_y)[0]\n",
    "\n",
    "                        chan_adj[ch_ix, ch_iy] = roi_adj[ix, iy]\n",
    "                chan_adj[np.diag_indices_from(chan_adj)] = 0\n",
    "                \n",
    "                struct_adj[scale][trk_type] = chan_adj\n",
    "        \n",
    "        ### Populate dict\n",
    "        channel_dict['Subject'][subj_id]['Jacksheet'] = df_chan['good_channels_jack'][0, :]\n",
    "        channel_dict['Subject'][subj_id]['Channel_Label'] = chan_lbl     \n",
    "        channel_dict['Subject'][subj_id]['Atlas_Label'] = atlas_label\n",
    "        channel_dict['Subject'][subj_id]['MNI_Coord'] = mni_coords\n",
    "        channel_dict['Subject'][subj_id]['Dist_Matr'] = dist_matr\n",
    "        channel_dict['Subject'][subj_id]['Struct_Adj'] = struct_adj\n",
    "        \n",
    "    pkl.dump(channel_dict, open('{}/channel_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "print('There are {} processed channel datasets to analyze.'.format(len(channel_dict['Subject'].keys())))                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/base_dict.pkl'.format(path_ExpData)):\n",
    "    base_dict = pkl.load(open('{}/base_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    base_list = glob.glob('{}/Adjacency.*.npz'.format(path_InpData_Baseline))\n",
    "    all_subj_id = np.unique([pth.split('/')[-1].split('.')[1] for pth in base_list])\n",
    "\n",
    "    base_dict = {'Subject_ID': [],\n",
    "                 'Base_ID': [],\n",
    "                 'Adj_Path': []}\n",
    "\n",
    "\n",
    "    for subj_id in all_subj_id:\n",
    "        print(subj_id)\n",
    "\n",
    "        ### Iterate over all baseline events for the subject\n",
    "        for pth in glob.glob('{}/Adjacency.{}.*.npz'.format(path_InpData_Baseline, subj_id)):    \n",
    "            full_file = pth.split('/')[-1]    \n",
    "            subj_id = full_file.split('.')[1]\n",
    "            base_id = int(full_file.split('.')[2].split('_')[-1])\n",
    "\n",
    "            ### Populate the dictionary\n",
    "            base_dict['Subject_ID'].append(subj_id)\n",
    "            base_dict['Base_ID'].append(base_id)    \n",
    "            base_dict['Adj_Path'].append(pth)\n",
    "\n",
    "    pkl.dump(base_dict, open('{}/base_dict.pkl'.format(path_ExpData), 'w')) \n",
    "\n",
    "df_base = pd.DataFrame(base_dict, columns=base_dict.keys())    \n",
    "print('There are {} processed baseline events to analyze.'.format(len(base_dict['Subject_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/stim_trial_dict.pkl'.format(path_ExpData)):\n",
    "    trial_dict = pkl.load(open('{}/stim_trial_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    trial_list = glob.glob('{}/Adjacency.*.npz'.format(path_InpData))\n",
    "    all_subj_id = np.unique([pth.split('/')[-1].split('.')[1] for pth in trial_list])\n",
    "\n",
    "    trial_dict = {'Subject_ID': [],\n",
    "                  'Experiment_ID': [],\n",
    "                  'Trial_ID': [],\n",
    "                  'Event_ID': [],\n",
    "                  'Stim_Freq': [],\n",
    "                  'Stim_Amp': [],\n",
    "                  'Stim_Dur': [],\n",
    "                  'Stim_Anode': [],\n",
    "                  'Stim_Cathode': [],           \n",
    "                  'Adj_Path': []}\n",
    "\n",
    "    for subj_id in all_subj_id:\n",
    "        print(subj_id)\n",
    "\n",
    "        ### Get Trial LUT for Subject\n",
    "        trial_lut_file = glob.glob('{}/Exp_Info/LUT_Trial_Events/{}_trial_lut.mat'.format(path_CoreData, subj_id))\n",
    "        if len(trial_lut_file) != 1:\n",
    "            continue\n",
    "        df_lut = h5py.File(trial_lut_file[0], 'r')\n",
    "\n",
    "        ### Get event table for subject\n",
    "        event_file = glob.glob('{}/Exp_Info/PS_Events/{}_events.mat'.format(path_CoreData, subj_id))\n",
    "        if len(event_file) != 1:\n",
    "            continue\n",
    "        df_event = io.loadmat(event_file[0])\n",
    "\n",
    "        ### Iterate over all trials for the subject\n",
    "        for pth in glob.glob('{}/Adjacency.{}.*.npz'.format(path_InpData, subj_id)):    \n",
    "            full_file = pth.split('/')[-1]    \n",
    "            subj_id = full_file.split('.')[1]\n",
    "            trial_id = int(full_file.split('.')[2].split('_')[-1])\n",
    "\n",
    "            ### Convert the Trial ID to Event ID\n",
    "            event_id = df_lut['trial_lut'][1, :][df_lut['trial_lut'][0, :] == trial_id]\n",
    "            if len(event_id) != 1:\n",
    "                continue\n",
    "            event_id = int(event_id[0] - 1)\n",
    "\n",
    "            ### Get Trial Parameters\n",
    "            sel_event = df_event['events'][0, event_id]\n",
    "            stim_type = sel_event['type'][0].lower()\n",
    "            if not (stim_type =='stimulating'):\n",
    "                continue        \n",
    "\n",
    "            stim_exp = sel_event['experiment'][0]        \n",
    "            stim_amp = sel_event['amplitude'][0, 0]\n",
    "            stim_freq = sel_event['pulse_frequency'][0, 0]\n",
    "            stim_dur = sel_event['pulse_duration'][0, 0]            \n",
    "\n",
    "            stim_anode_jack = df_event['events'][0, event_id]['stimAnode'][0, 0]\n",
    "            stim_cathode_jack = df_event['events'][0, event_id]['stimCathode'][0, 0]\n",
    "\n",
    "            ### Populate the dictionary\n",
    "            trial_dict['Subject_ID'].append(subj_id)\n",
    "            trial_dict['Experiment_ID'].append(stim_exp)        \n",
    "            trial_dict['Trial_ID'].append(trial_id)    \n",
    "            trial_dict['Event_ID'].append(event_id)\n",
    "            trial_dict['Stim_Freq'].append(stim_freq)\n",
    "            trial_dict['Stim_Amp'].append(stim_amp)\n",
    "            trial_dict['Stim_Dur'].append(stim_dur)            \n",
    "            trial_dict['Stim_Anode'].append(stim_anode_jack)\n",
    "            trial_dict['Stim_Cathode'].append(stim_cathode_jack)\n",
    "            trial_dict['Adj_Path'].append(pth)\n",
    "        df_lut.close()\n",
    "    \n",
    "    pkl.dump(trial_dict, open('{}/stim_trial_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "df_trial = pd.DataFrame(trial_dict, columns=trial_dict.keys())    \n",
    "print('There are {} processed trials to analyze.'.format(len(trial_dict['Subject_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/memory_trial_dict.pkl'.format(path_ExpData)):\n",
    "    memory_dict = pkl.load(open('{}/memory_trial_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    memory_list = glob.glob('{}/Memory_States/Memory_States/*.*.memory_states.mat'.format(path_CoreData))\n",
    "\n",
    "    memory_dict = {'Subject_ID': [],\n",
    "                   'Event_ID': [],\n",
    "                   'Experiment_ID': [],\n",
    "                   'Pre_Stim_Prob': [],\n",
    "                   'Post_Stim_Prob': [],                   \n",
    "                   'Stim_Freq': [],\n",
    "                   'Stim_Amp': [],\n",
    "                   'Stim_Duration': [],\n",
    "                   'Stim_Anode': [],\n",
    "                   'Stim_Cathode': []}\n",
    "\n",
    "    for pth in memory_list:\n",
    "        subj_id = pth.split('/')[-1].split('.')[0]\n",
    "        expr_id = pth.split('/')[-1].split('.')[1]\n",
    "\n",
    "        ### Get event table for subject\n",
    "        stim_event_file = glob.glob('{}/Exp_Info/PS_Events/{}_events.mat'.format(path_CoreData, subj_id))\n",
    "        try:\n",
    "            df_stim_event = io.loadmat(stim_event_file[0])\n",
    "            event_ids = []\n",
    "            for ii in xrange(len(df_stim_event['events'][0, :])):\n",
    "                if (df_stim_event['events'][0, ii]['experiment'] == 'PS2') & \\\n",
    "                   (df_stim_event['events'][0, ii]['type'] == 'STIMULATING'):\n",
    "                    event_ids.append(ii)\n",
    "        except:\n",
    "            event_ids = []\n",
    "        n_stim_event = len(event_ids)\n",
    "        \n",
    "        ### Get memory state table for subject\n",
    "        df_mem_event = io.loadmat(pth)\n",
    "        n_mem_event = df_mem_event['stim_freq'].shape[1]\n",
    "        \n",
    "        ### Sanity check\n",
    "        print(subj_id, expr_id, n_stim_event, n_mem_event, n_mem_event == n_stim_event)\n",
    "\n",
    "        ### Iterate over all trials for the subject\n",
    "        for ix in xrange(n_mem_event):\n",
    "            \n",
    "            ### Populate the dictionary\n",
    "            memory_dict['Subject_ID'].append(subj_id)\n",
    "            try:\n",
    "                memory_dict['Event_ID'].append(event_ids[ix])\n",
    "            except:\n",
    "                memory_dict['Event_ID'].append(np.nan)\n",
    "            memory_dict['Experiment_ID'].append(expr_id) \n",
    "            memory_dict['Pre_Stim_Prob'].append(df_mem_event['pre_stim_mem_prob'][0, ix])\n",
    "            memory_dict['Post_Stim_Prob'].append(df_mem_event['post_stim_mem_prob'][0, ix])            \n",
    "            memory_dict['Stim_Freq'].append(df_mem_event['stim_freq'][0, ix])\n",
    "            memory_dict['Stim_Amp'].append(df_mem_event['stim_amp'][0, ix]) \n",
    "            memory_dict['Stim_Duration'].append(df_mem_event['stim_duration'][0, ix])  \n",
    "            memory_dict['Stim_Anode'].append(df_mem_event['stim_anode_jack'][0, ix])\n",
    "            memory_dict['Stim_Cathode'].append(df_mem_event['stim_cathode_jack'][0, ix])\n",
    "\n",
    "    pkl.dump(memory_dict, open('{}/memory_trial_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "df_memory = pd.DataFrame(memory_dict, columns=memory_dict.keys())    \n",
    "print('There are {} processed trials to analyze.'.format(len(memory_dict['Subject_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Population-Level Electrodes to Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('{}/subject_electrode_pixmap.pkl'.format(path_ExpData)):\n",
    "    electrode_pixmap = pkl.load(open('{}/subject_electrode_pixmap.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "\n",
    "    from Echobase.Plotting import render_brain_connectivity\n",
    "\n",
    "    ### Collect surface data\n",
    "    # Vertices and triangles\n",
    "    verts_rh, trias_rh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/rh.pial'.format(path_AtlasData))\n",
    "    verts_lh, trias_lh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/lh.pial'.format(path_AtlasData))\n",
    "\n",
    "    n_rh_verts = verts_rh.shape[0]\n",
    "    n_lh_verts = verts_lh.shape[0]\n",
    "\n",
    "    verts = np.vstack((verts_rh, verts_lh))\n",
    "    trias = np.vstack((trias_rh, trias_lh+n_rh_verts))\n",
    "\n",
    "    label_scalars = 20*np.zeros(n_rh_verts+n_lh_verts)\n",
    "\n",
    "    view_angle = {'Axial_LR': [0.0, 0.0],\n",
    "                  'Axial_RL': [0.0, 180.0],\n",
    "                  'Sag_PA': [0.0, 90.0],\n",
    "                  'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "    # Get all the electrodes\n",
    "    electrode_pixmap = {}\n",
    "    for subj_id in np.unique(df_trial['Subject_ID']):\n",
    "        print(subj_id)\n",
    "\n",
    "        node_coord = []\n",
    "        node_rgba = []\n",
    "        node_size = []\n",
    "\n",
    "        if len(channel_dict['Subject'][subj_id].keys()) == 0:\n",
    "            continue\n",
    "\n",
    "        subj_stim_anode = np.unique(df_trial[df_trial['Subject_ID'] == subj_id]['Stim_Anode'])\n",
    "        subj_stim_cathode = np.unique(df_trial[df_trial['Subject_ID'] == subj_id]['Stim_Cathode'])\n",
    "\n",
    "        if (len(subj_stim_anode) == 0) or (len(subj_stim_cathode) == 0):\n",
    "            continue\n",
    "\n",
    "        for jack_ii, jack in enumerate(channel_dict['Subject'][subj_id]['Jacksheet']):\n",
    "            node_coord.append(channel_dict['Subject'][subj_id]['MNI_Coord'][jack_ii, :])\n",
    "            if (jack in subj_stim_anode) or (jack in subj_stim_cathode):\n",
    "                node_rgba.append([1.0, 0.0, 0.0, 1.0])\n",
    "            else:\n",
    "                node_rgba.append([0.0, 0.0, 1.0, 1.0])\n",
    "            node_size.append(3.5)\n",
    "\n",
    "        node_coord = np.array(node_coord)\n",
    "        node_rgba = np.array(node_rgba)\n",
    "        node_size = np.array(node_size)\n",
    "\n",
    "        render_brain_connectivity.mlab.close(all=True)    \n",
    "        engine = render_brain_connectivity.draw(verts, trias, label_scalars, 'Greys', 196.0,\n",
    "                                                node_coords=node_coord, node_sizes=node_size, node_colors=node_rgba,\n",
    "                                                conn_list=None, conn_pct=None, conn_cmap=None)\n",
    "        pixmap = {}\n",
    "        for ang in view_angle.keys():\n",
    "            render_brain_connectivity.mlab.view(azimuth=view_angle[ang][0],\n",
    "                                                elevation=view_angle[ang][1])\n",
    "            pixmap['{}'.format(ang)] = render_brain_connectivity.mlab.screenshot(mode='rgba')\n",
    "        electrode_pixmap[subj_id] = pixmap\n",
    "\n",
    "        render_brain_connectivity.mlab.close(all=True)\n",
    "    pkl.dump(electrode_pixmap, open('{}/subject_electrode_pixmap.pkl'.format(path_ExpData), 'w'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "for subj_id in electrode_pixmap.keys():\n",
    "    plt.figure(figsize=(3,3), dpi=300)\n",
    "    for view_ii, view in enumerate(['Sag_AP', 'Sag_PA']):\n",
    "        ax = plt.subplot(1,2,view_ii+1)\n",
    "        ax.imshow(electrode_pixmap[subj_id][view])\n",
    "        ax.set_axis_off()\n",
    "    plt.suptitle(subj_id)\n",
    "    plt.savefig('{}/{}.electrode_pixmap.svg'.format(path_Figures, subj_id), dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot time-series from baseline --> stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subj_id = 'R1050M'\n",
    "sel_trial = df_trial[df_trial['Subject_ID'] == subj_id]\n",
    "\n",
    "\"\"\"\n",
    "### Retrieve baseline clips\n",
    "for ii in xrange(10):\n",
    "    baseline_path = '{}/Baseline_Trials/{}.Baseline_{}.mat'.format(path_CoreData, subj_id, ii+1)\n",
    "    df = h5py.File(baseline_path, 'r')\n",
    "    if ii == 0:\n",
    "        evData = df['evData'][...]\n",
    "    else:\n",
    "        evData = np.vstack((evData, df['evData'][...]))\n",
    "df.close()\n",
    "\"\"\"\n",
    "\n",
    "### Retrieve First stim trial\n",
    "sel_trial_rnd = sel_trial.iloc[np.random.permutation(sel_trial.shape[0])[0]]\n",
    "trial_id = 652 #sel_trial_rnd['Trial_ID']\n",
    "trial_path = glob.glob('{}/Stim_Trials/{}.*.Trial_{}.mat'.format(path_CoreData, subj_id, trial_id))[0]\n",
    "df = h5py.File(trial_path, 'r')\n",
    "#evData = np.vstack((evData, df['evData'][...]))\n",
    "evData = df['evData'][0:-1, :]\n",
    "fs = int(np.ceil(df['samp_freq'][0, 0]))\n",
    "#df.close()\n",
    "\n",
    "### Filter params\n",
    "wpass = [58.0, 62.0]\n",
    "wstop = [59.0, 61.0]\n",
    "gpass = 0.1\n",
    "gstop = 60.0\n",
    "evData = Echobase.Sigproc.filters.elliptic(evData, fs,\n",
    "                                           wpass, wstop, gpass, gstop)\n",
    "### Generate the plot\n",
    "evData_norm = (evData - evData.mean(axis=0)) / (6*evData.std(axis=0))\n",
    "n_samp, n_chan = evData_norm.shape\n",
    "sel_chan = np.random.randint(0, n_chan, size=(9))\n",
    "\n",
    "\n",
    "# Window the stimulation clip\n",
    "stim_dur = sel_trial[sel_trial['Trial_ID'] == trial_id]['Stim_Dur']\n",
    "n_win_dur = int(1*fs/2)\n",
    "\n",
    "n_stim_start = int(1*fs)\n",
    "n_stim_dur = int(stim_dur/1000.0*fs)\n",
    "n_stim_end = n_stim_start + n_stim_dur\n",
    "n_stim_pad = int(25/1000.0*fs)\n",
    "\n",
    "win_pre_stim = np.arange(n_stim_start-n_win_dur, n_stim_start)\n",
    "win_post_stim = np.arange(n_stim_end+n_stim_pad, n_stim_end+n_stim_pad+n_win_dur)\n",
    "\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(np.arange(len(sel_chan))+evData_norm[:, sel_chan], lw=0.2, color='k')\n",
    "ax.fill_between([win_pre_stim.min(), win_pre_stim.max()],\n",
    "                y1=-1, y2=len(sel_chan),\n",
    "                color=[0.1, 0.1, 1.0], alpha=0.1, lw=0)\n",
    "ax.fill_between([win_pre_stim.max()+1, win_pre_stim.max()+1+n_stim_dur],\n",
    "                y1=-1, y2=len(sel_chan),\n",
    "                color=[1.0, 0.1, 0.1], alpha=0.1, lw=0)\n",
    "ax.fill_between([win_post_stim.min(), win_post_stim.max()],\n",
    "                y1=-1, y2=len(sel_chan),\n",
    "                color=[0.1, 0.1, 1.0], alpha=0.1, lw=0)\n",
    "\n",
    "ax.set_ylim([-1, len(sel_chan)])\n",
    "ax.set_xlim([0, n_samp+1])\n",
    "ax.set_xticks([0, win_pre_stim.min(),\n",
    "               win_pre_stim.max()+1,\n",
    "               win_post_stim.min(),\n",
    "               win_post_stim.max(),\n",
    "               n_samp])\n",
    "ax.set_xticklabels(np.array([0, win_pre_stim.min(),\n",
    "                             win_pre_stim.max()+1,\n",
    "                             win_post_stim.min()+0.5,\n",
    "                             win_post_stim.max()+1.5,\n",
    "                             n_samp]) / fs)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('{}/ECoG_Stim.{}.Trial_{}.svg'.format(path_Figures, subj_id, trial_id))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Adjacency Matrices for the above trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Echobase.Plotting import render_brain_connectivity\n",
    "\n",
    "subj_id = 'R1050M'\n",
    "\n",
    "### Retrieve First stim trial\n",
    "sel_trial = df_trial[df_trial['Subject_ID'] == subj_id]\n",
    "sel_trial_rnd = sel_trial.iloc[np.random.permutation(sel_trial.shape[0])[0]]\n",
    "trial_id = 652 # sel_trial_rnd['Trial_ID'] #652\n",
    "trial_adj_path = '{}/Adjacency.{}.Trial_{}.npz'.format(path_InpData, subj_id, trial_id)\n",
    "df = np.load(trial_adj_path)\n",
    "df_adj = df['adj'][()]\n",
    "\n",
    "print(trial_id)\n",
    "\n",
    "\n",
    "### Plot the Adjacency Matrix\n",
    "for epoch in ['Pre_Stim', 'Post_Stim']:\n",
    "    for fband in ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']:\n",
    "        adj_matr = df_adj[epoch][fband]\n",
    "        cfg_vec = convert_adj_matr_to_cfg_matr(adj_matr.reshape(1, adj_matr.shape[0], adj_matr.shape[0])).T   \n",
    "        \n",
    "        plt.figure(figsize=(3,3), dpi=300)\n",
    "        ax = plt.subplot(111)\n",
    "        mat = ax.matshow(adj_matr, cmap='plasma', vmin=0, vmax=1)\n",
    "        ax.set_axis_off()\n",
    "        plt.colorbar(mat, ax=ax)        \n",
    "        plt.savefig('{}/ECoG_Stim.Adjacency.{}.Trial_{}.{}.{}.svg'.format(path_Figures, subj_id, trial_id, epoch, fband))\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(3,3), dpi=300)\n",
    "        ax = plt.subplot(111)\n",
    "        mat = ax.matshow(cfg_vec, cmap='plasma', vmin=0, vmax=1, aspect=0.01)\n",
    "        ax.set_axis_off()\n",
    "        plt.savefig('{}/ECoG_Stim.Cfg_Vec.{}.Trial_{}.{}.{}.svg'.format(path_Figures, subj_id, trial_id, epoch, fband))\n",
    "        plt.close()        \n",
    "        \n",
    "        \n",
    "### Plot the Delta Matrix        \n",
    "stim_anode_jack = sel_trial[sel_trial['Trial_ID'] == trial_id]['Stim_Anode'].iloc[0]\n",
    "stim_cathode_jack = sel_trial[sel_trial['Trial_ID'] == trial_id]['Stim_Cathode'].iloc[0]\n",
    "anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "        \n",
    "if len(channel_dict['Subject'][subj_id].keys()) == 0:\n",
    "    raise Exception\n",
    "\n",
    "freq_pixmap = {}\n",
    "for fband in ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']:\n",
    "    adj_matr = (df_adj['Post_Stim'][fband] - df_adj['Pre_Stim'][fband]).copy()\n",
    "    #adj_matr = df_adj['Post_Stim'][fband].copy()\n",
    "    adj_matr = np.insert(adj_matr, [anode_ix], np.nan, axis=0)\n",
    "    adj_matr = np.insert(adj_matr, [cathode_ix], np.nan, axis=0)\n",
    "    adj_matr = np.insert(adj_matr, [anode_ix], np.nan, axis=1)\n",
    "    adj_matr = np.insert(adj_matr, [cathode_ix], np.nan, axis=1)  \n",
    "    \n",
    "    deg_vec = np.abs(np.nanmean(adj_matr, axis=0)) \n",
    "    deg_vec *= 60\n",
    "    #deg_vec = (7.0-2.0)/(np.nanmax(deg_vec)-np.nanmin(deg_vec))*(deg_vec-np.nanmax(deg_vec))+7.0\n",
    "    #deg_vec[np.isnan(deg_vec)] = 2.0\n",
    "\n",
    "    ### Collect surface data\n",
    "    # Vertices and triangles\n",
    "    verts_rh, trias_rh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/rh.pial'.format(path_AtlasData))\n",
    "    verts_lh, trias_lh = nib.freesurfer.io.read_geometry('{}/fsaverage/surf/lh.pial'.format(path_AtlasData))\n",
    "\n",
    "    n_rh_verts = verts_rh.shape[0]\n",
    "    n_lh_verts = verts_lh.shape[0]\n",
    "\n",
    "    verts = np.vstack((verts_rh, verts_lh))\n",
    "    trias = np.vstack((trias_rh, trias_lh+n_rh_verts))\n",
    "\n",
    "    label_scalars = 20*np.zeros(n_rh_verts+n_lh_verts)\n",
    "\n",
    "    view_angle = {'Axial_LR': [0.0, 0.0],\n",
    "                  'Axial_RL': [0.0, 180.0],\n",
    "                  'Sag_PA': [0.0, 90.0],\n",
    "                  'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "    node_coord = []\n",
    "    node_rgba = []\n",
    "    node_size = []\n",
    "    conn_list = convert_adj_matr_to_cfg_matr(\n",
    "        adj_matr.reshape(1, adj_matr.shape[0], adj_matr.shape[0]))[0, :]\n",
    "\n",
    "    for jack_ii, jack in enumerate(channel_dict['Subject'][subj_id]['Jacksheet']):\n",
    "        node_coord.append(channel_dict['Subject'][subj_id]['MNI_Coord'][jack_ii, :])\n",
    "        if (jack == stim_anode_jack) or (jack == stim_cathode_jack):\n",
    "            node_rgba.append([1.0, 0.0, 0.0, 1.0])\n",
    "        else:\n",
    "            node_rgba.append([0.2, 0.2, 0.2, 1.0])\n",
    "        node_size.append(deg_vec[jack_ii])\n",
    "\n",
    "    node_coord = np.array(node_coord)\n",
    "    node_rgba = np.array(node_rgba)\n",
    "    node_size = np.array(node_size)\n",
    "    \n",
    "    conn_list_thresh = conn_list.copy()\n",
    "    inval_ix = np.flatnonzero((conn_list > -0.4) & #np.percentile(conn_list[~np.isnan(conn_list)], 1.0)) &\n",
    "                              (conn_list < 0.4))   #np.percentile(conn_list[~np.isnan(conn_list)], 99.0)))\n",
    "    conn_list_thresh[inval_ix] = np.nan\n",
    "\n",
    "    render_brain_connectivity.mlab.close(all=True)    \n",
    "    engine = render_brain_connectivity.draw(verts, trias, label_scalars, 'Greys', 132.0,\n",
    "                                            node_coords=node_coord, node_sizes=node_size, node_colors=node_rgba,\n",
    "                                            conn_list=conn_list_thresh, conn_cmap='coolwarm')\n",
    "    pixmap = {}\n",
    "    for ang in view_angle.keys():\n",
    "        render_brain_connectivity.mlab.view(azimuth=view_angle[ang][0],\n",
    "                                            elevation=view_angle[ang][1])\n",
    "        pixmap['{}'.format(ang)] = render_brain_connectivity.mlab.screenshot(mode='rgba', antialiased=False)\n",
    "    freq_pixmap[fband] = pixmap\n",
    "\n",
    "    render_brain_connectivity.mlab.close(all=True)\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(6,6), dpi=300)\n",
    "view = 'Sag_AP'\n",
    "for ii, fband in enumerate(['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    ax.imshow(freq_pixmap[fband][view], cmap='rainbow');\n",
    "    ax.set_axis_off()\n",
    "plt.savefig('{}/Evoked_Conn.{}.Trial_{}.{}.svg'.format(path_Figures, subj_id, trial_id, view), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Adjacency Matrices for the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subj_id = 'R1050M'\n",
    "\n",
    "### Plot the Adjacency Matrix\n",
    "for fband in ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']:\n",
    "    for base_i in xrange(1):\n",
    "        trial_adj_path = '{}/Adjacency.{}.Baseline_{}.npz'.format(path_InpData_Baseline, subj_id, base_i+1)\n",
    "        df = np.load(trial_adj_path)\n",
    "        df_adj = df['adj'][()]\n",
    "        \n",
    "        if i == 0:\n",
    "            adj_matr = df_adj['No_Stim'][fband].copy()\n",
    "        else:\n",
    "            adj_matr += df_adj['No_Stim'][fband].copy()\n",
    "\n",
    "    plt.figure(figsize=(3,3), dpi=300)\n",
    "    ax = plt.subplot(111)\n",
    "    mat = ax.matshow(adj_matr, cmap='plasma', vmin=0, vmax=1)\n",
    "    ax.set_axis_off()\n",
    "    plt.colorbar(mat, ax=ax)\n",
    "\n",
    "    plt.savefig('{}/ECoG_Baseline.Adjacency.{}.{}.svg'.format(path_Figures, subj_id, fband))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Evoked Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/baseline_topology.pkl'.format(path_ExpData)):\n",
    "    df_base_topo = pd.read_pickle('{}/baseline_topology.pkl'.format(path_ExpData))\n",
    "else:\n",
    "    data_table = {'Subject_ID': [],\n",
    "                  'Coherence_ID': [],\n",
    "                  'Base_Delta_Cor': [],\n",
    "                  'Base_AdjMatr': [],\n",
    "                  'Base_NodeStr': [],\n",
    "                  'Base_ZNodeStr': [],\n",
    "                  'Base_Delta_Node_Cnt': []}\n",
    "    coherence_id = ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']\n",
    "\n",
    "    n_perm = 1000\n",
    "    alpha = 2.0 / n_perm                \n",
    "    \n",
    "    for subj_id in np.unique(df_base['Subject_ID']):\n",
    "        print(subj_id)\n",
    "        sel_subj = df_base[df_base['Subject_ID'] == subj_id]\n",
    "\n",
    "        for coh_id in coherence_id:\n",
    "            cfg_vec = []       \n",
    "            ns = []\n",
    "\n",
    "            for base_ix, base_data in sel_subj.iterrows():\n",
    "                # Load Adjacency\n",
    "                df_adj = np.load(base_data['Adj_Path'])\n",
    "                adj = df_adj['adj'].item()   \n",
    "                df_adj.close()\n",
    "\n",
    "                # Grab adjacency matrices\n",
    "                adj_coh = adj['No_Stim'][coh_id]\n",
    "\n",
    "                # Compute node strength\n",
    "                ns.append(np.mean(adj_coh, axis=0))\n",
    "\n",
    "                # Get configuration vector\n",
    "                cfg_coh = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_coh, axis=0)).reshape(-1)\n",
    "\n",
    "                cfg_vec.append(cfg_coh)\n",
    "\n",
    "            # Average the node strengths across baseline events\n",
    "            ns = np.mean(np.array(ns), axis=0)\n",
    "\n",
    "            # Compute Z-Scored node strengths\n",
    "            zns = (ns - np.nanmean(ns)) / np.nanstd(ns)   \n",
    "\n",
    "            # Compute correlations between configurations of different baseline time points\n",
    "            cfg_vec = np.array(cfg_vec)\n",
    "            adj_matr = convert_conn_vec_to_adj_matr(cfg_vec.mean(axis=0))\n",
    "\n",
    "            t_ix, t_iy = np.triu_indices(cfg_vec.shape[0], k=1)\n",
    "            delta_cor = np.mean([stats.pearsonr(cfg_vec[t_ixx, :], cfg_vec[t_iyy, :])[0]\n",
    "                                 for t_ixx, t_iyy in zip(t_ix, t_iy)])\n",
    "            \n",
    "            \n",
    "            # Compute different delta_ns \n",
    "            delta_ns_cnt = []\n",
    "            for t_ixx, t_iyy in zip(t_ix, t_iy):\n",
    "                cfg_delta_coh = cfg_vec[t_ixx, :] - cfg_vec[t_iyy, :]\n",
    "                delta_ns_coh = convert_conn_vec_to_adj_matr(cfg_delta_coh).mean(axis=0)\n",
    "                \n",
    "                # Generate a thresholded delta_ns_coh matrix\n",
    "                delta_ns_coh_null = np.zeros((n_perm, delta_ns_coh.shape[0]))\n",
    "                for p_ii in xrange(n_perm):\n",
    "                    adj_delta_coh_null = convert_conn_vec_to_adj_matr(np.random.permutation(cfg_delta_coh))\n",
    "                    delta_ns_coh_null[p_ii, :] = np.mean(adj_delta_coh_null, axis=0)\n",
    "    \n",
    "                thresh_hi = np.percentile(delta_ns_coh_null, (1-alpha)*100)\n",
    "                thresh_lo = np.percentile(delta_ns_coh_null, alpha*100)\n",
    "                delta_ns_coh[np.flatnonzero((delta_ns_coh < thresh_hi) &\n",
    "                                            (delta_ns_coh > thresh_lo))] = np.nan\n",
    "                \n",
    "                delta_ns_cnt.append(np.mean(~np.isnan(delta_ns_coh)))\n",
    "            delta_ns_cnt = np.mean(delta_ns_cnt)\n",
    "            \n",
    "\n",
    "            # Add to Data Table\n",
    "            data_table['Subject_ID'].append(subj_id)\n",
    "            data_table['Coherence_ID'].append(coh_id)            \n",
    "\n",
    "            data_table['Base_Delta_Cor'].append(delta_cor)\n",
    "            data_table['Base_AdjMatr'].append(adj_matr) \n",
    "            data_table['Base_NodeStr'].append(ns)\n",
    "            data_table['Base_Delta_Node_Cnt'].append(delta_ns_cnt)            \n",
    "            data_table['Base_ZNodeStr'].append(zns)\n",
    "\n",
    "    # Save Data Tables for R-stats\n",
    "    df_base_topo = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    df_base_topo.to_pickle('{}/baseline_topology.pkl'.format(path_ExpData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/stim_topology.pkl'.format(path_ExpData)) :\n",
    "    df_stim_topo = pd.read_pickle('{}/stim_topology.pkl'.format(path_ExpData))\n",
    "else:    \n",
    "    data_table = {'Subject_ID': [],\n",
    "                  'Experiment_ID': [],\n",
    "                  'Event_ID': [],\n",
    "                  'Trial_ID': [],\n",
    "                  'Coherence_ID': [],\n",
    "                  'Stim_Freq': [],\n",
    "                  'Stim_Amp': [],\n",
    "                  'Stim_Anode': [],\n",
    "                  'Stim_Cathode': [],\n",
    "                  \n",
    "                  'Pre_MeanConnStr': [],\n",
    "                  'Post_MeanConnStr': [],\n",
    "                  'Delta_MeanConnStr': [],\n",
    "                  \n",
    "                  'Pre_VarConnStr': [],\n",
    "                  'Post_VarConnStr': [],\n",
    "                  'Delta_VarConnStr': [],\n",
    "\n",
    "                  'Delta_Cor': [],\n",
    "\n",
    "                  'Pre_NodeStr': [],\n",
    "                  'Post_NodeStr': [],\n",
    "                  'Delta_NodeStr': [],\n",
    "                  'Delta_NodeStr_Thresh': []}\n",
    "    coherence_id = ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']                  \n",
    "\n",
    "    n_perm = 1000\n",
    "    alpha = 2.0 / n_perm                \n",
    "    \n",
    "    for subj_id in np.unique(df_trial['Subject_ID']):\n",
    "        sel_subj = df_trial[df_trial['Subject_ID'] == subj_id]\n",
    "\n",
    "        for trial_ix, trial_data in sel_subj.iterrows():\n",
    "            if (trial_ix % 1000) == 0:\n",
    "                print(trial_ix)\n",
    "            \n",
    "            # Load Adjacency\n",
    "            df_adj = np.load(trial_data['Adj_Path'])\n",
    "            adj = df_adj['adj'].item()   \n",
    "            df_adj.close()\n",
    "\n",
    "            for coh_id in coherence_id:\n",
    "                # Grab adjacency matrices\n",
    "                adj_pre_coh = adj['Pre_Stim'][coh_id]\n",
    "                adj_post_coh = adj['Post_Stim'][coh_id]\n",
    "                adj_delta_coh = (adj_post_coh - adj_pre_coh)\n",
    "                adj_delta_coh[np.isnan(adj_delta_coh)] = 0\n",
    "\n",
    "                # Compute Pre/Post/Delta Configuration vectors\n",
    "                cfg_pre_coh = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre_coh, axis=0)).reshape(-1)\n",
    "                cfg_post_coh = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post_coh, axis=0)).reshape(-1)\n",
    "                cfg_delta_coh = (cfg_post_coh - cfg_pre_coh)\n",
    "                cfg_delta_coh[np.isnan(cfg_delta_coh)] = 0\n",
    "                \n",
    "                # Compute pre/post/delta connection stats (mean / variance / Pearson)\n",
    "                pre_mcs_coh = np.mean(cfg_pre_coh)\n",
    "                post_mcs_coh = np.mean(cfg_post_coh)\n",
    "                delta_mcs_coh = np.mean(cfg_delta_coh)\n",
    "                \n",
    "                pre_vcs_coh = np.var(cfg_pre_coh)\n",
    "                post_vcs_coh = np.var(cfg_post_coh)\n",
    "                delta_vcs_coh = np.var(cfg_delta_coh)\n",
    "\n",
    "                delta_cor_coh = stats.pearsonr(cfg_pre_coh, cfg_post_coh)[0]\n",
    "\n",
    "                # Change in node strength (Post - Pre)\n",
    "                pre_ns_coh = np.mean(adj_pre_coh, axis=0)\n",
    "                post_ns_coh = np.mean(adj_post_coh, axis=0)\n",
    "                delta_ns_coh = np.mean(adj_delta_coh, axis=0)\n",
    "                \n",
    "                # Generate a thresholded delta_ns_coh matrix\n",
    "                delta_ns_coh_null = np.zeros((n_perm, delta_ns_coh.shape[0]))\n",
    "                for p_ii in xrange(n_perm):\n",
    "                    adj_delta_coh_null = convert_conn_vec_to_adj_matr(np.random.permutation(cfg_delta_coh))\n",
    "                    delta_ns_coh_null[p_ii, :] = np.mean(adj_delta_coh_null, axis=0)\n",
    "    \n",
    "                delta_ns_coh_thr = delta_ns_coh.copy()\n",
    "                thresh_hi = np.percentile(delta_ns_coh_null, (1-alpha)*100)\n",
    "                thresh_lo = np.percentile(delta_ns_coh_null, alpha*100)\n",
    "                delta_ns_coh_thr[np.flatnonzero((delta_ns_coh_thr < thresh_hi) &\n",
    "                                                (delta_ns_coh_thr > thresh_lo))] = np.nan\n",
    "                \n",
    "                                \n",
    "                # Add to Data Table 1\n",
    "                data_table['Subject_ID'].append(trial_data['Subject_ID'])\n",
    "                data_table['Experiment_ID'].append(trial_data['Experiment_ID'])                 \n",
    "                data_table['Event_ID'].append(trial_data['Event_ID'])                \n",
    "                data_table['Trial_ID'].append(trial_data['Trial_ID'])\n",
    "                data_table['Coherence_ID'].append(coh_id)                \n",
    "                data_table['Stim_Freq'].append(trial_data['Stim_Freq'])\n",
    "                data_table['Stim_Amp'].append(trial_data['Stim_Amp'])\n",
    "                data_table['Stim_Anode'].append(trial_data['Stim_Anode'])\n",
    "                data_table['Stim_Cathode'].append(trial_data['Stim_Cathode'])\n",
    "                \n",
    "                data_table['Pre_MeanConnStr'].append(pre_mcs_coh)\n",
    "                data_table['Post_MeanConnStr'].append(post_mcs_coh)\n",
    "                data_table['Delta_MeanConnStr'].append(delta_mcs_coh)\n",
    "                \n",
    "                data_table['Pre_VarConnStr'].append(pre_vcs_coh)\n",
    "                data_table['Post_VarConnStr'].append(post_vcs_coh)\n",
    "                data_table['Delta_VarConnStr'].append(delta_vcs_coh)\n",
    "\n",
    "                data_table['Delta_Cor'].append(delta_cor_coh)\n",
    "\n",
    "                data_table['Pre_NodeStr'].append(pre_ns_coh)\n",
    "                data_table['Post_NodeStr'].append(post_ns_coh)\n",
    "                data_table['Delta_NodeStr'].append(delta_ns_coh)\n",
    "                data_table['Delta_NodeStr_Thresh'].append(delta_ns_coh_thr)                \n",
    "        \n",
    "    # Save Data Tables for R-stats\n",
    "    df_stim_topo = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    df_stim_topo.to_pickle('{}/stim_topology.pkl'.format(path_ExpData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Compute Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all invalid trials\n",
    "#df_stim_topo = df_stim_topo[df_stim_topo['Experiment_ID'] != 'PS1']\n",
    "df_stim_topo = df_stim_topo.dropna(axis=0)\n",
    "\n",
    "# Get all the subjects and coherence names\n",
    "base_subject_id = np.unique(df_base_topo['Subject_ID'])\n",
    "stim_subject_id = np.unique(df_stim_topo['Subject_ID'])\n",
    "common_base_stim_subject_id = np.intersect1d(base_subject_id, stim_subject_id)\n",
    "coherence_id = ['AlphaTheta', 'Beta', 'LowGamma', 'HighGamma']\n",
    "\n",
    "# Pre compute the Average Baseline stim node strength and fraction evoked nodes\n",
    "df_stim_topo['Stim_Base_ZNodeStr'] = np.nan\n",
    "df_stim_topo['Stim_Delta_Node_Cnt'] = np.nan\n",
    "df_stim_topo['Stim_Mag_Delta_NodeStr'] = np.nan\n",
    "\n",
    "for subj_id in stim_subject_id:\n",
    "    sel_base_subj = df_base_topo[df_base_topo['Subject_ID'] == subj_id]\n",
    "    sel_stim_subj = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "    for coh_id in coherence_id:\n",
    "        sel_base_subj_coh = sel_base_subj[sel_base_subj['Coherence_ID'] == coh_id]\n",
    "        sel_stim_subj_coh = sel_stim_subj[sel_stim_subj['Coherence_ID'] == coh_id]\n",
    "\n",
    "        for rr in sel_stim_subj_coh.iterrows():\n",
    "            ### Compute evoked node strength counts\n",
    "            stim_delta_node_cnt = np.mean(~np.isnan(rr[1]['Delta_NodeStr_Thresh']))                \n",
    "            df_stim_topo.set_value(rr[0], 'Stim_Delta_Node_Cnt', stim_delta_node_cnt)\n",
    "            \n",
    "            stim_mag_delta_ns = np.nanmean(np.abs(rr[1]['Delta_NodeStr_Thresh']))                \n",
    "            df_stim_topo.set_value(rr[0], 'Stim_Mag_Delta_NodeStr', stim_mag_delta_ns)\n",
    "\n",
    "            ### Append baseline node strength of stimulation nodes\n",
    "            if subj_id not in base_subject_id:\n",
    "                continue\n",
    "            stim_anode_jack = rr[1]['Stim_Anode']\n",
    "            stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "            stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "            stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "\n",
    "            base_zns = sel_base_subj_coh['Base_ZNodeStr'].iloc[0]                            \n",
    "            base_stim_zns = 0.5*(base_zns[stim_anode_ix] + \n",
    "                                 base_zns[stim_cathode_ix])\n",
    "\n",
    "            df_stim_topo.set_value(rr[0], 'Stim_Base_ZNodeStr', base_stim_zns)\n",
    "\n",
    "sel_base_topo = df_base_topo.groupby(['Subject_ID', 'Coherence_ID']).mean().reset_index()\n",
    "sel_stim_topo = df_stim_topo.groupby(['Subject_ID', 'Coherence_ID']).mean().reset_index()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Network Reorganization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Connection Strength\n",
    "The average node strength before stimulation predicts the average node strength after. There is a \"conservation of connectivity\" for Alpha/Theta, Beta, Low Gamma and High Gamma coherence networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Individual Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_coh = sel_stim_topo[sel_stim_topo['Coherence_ID'] == coh_id]\n",
    "    \n",
    "    # Plot Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(sel_coh['Pre_MeanConnStr'],\n",
    "                                                    sel_coh['Post_MeanConnStr'])\n",
    "    \n",
    "    ax = plt.subplot(2, 2, ii+1)   \n",
    "    n_pts = len(sel_coh['Pre_MeanConnStr'])\n",
    "    ax.plot([0.0, 1.0], slope*np.array([0.0, 1.0])+yint,\n",
    "            color='k', alpha=1.0, linewidth=1.0)    \n",
    "    ax.scatter(sel_coh['Pre_MeanConnStr'],\n",
    "               sel_coh['Post_MeanConnStr'],\n",
    "               s=20.0, lw=0, color=[0.5, 0.5, 0.5], alpha=0.2)\n",
    "    ax.text(0.2, 0.75, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([0, 1.0])\n",
    "    ax.set_ylim([0, 1.0])\n",
    "    ax.set_xticks(np.linspace(0.0, 1.0, 3))     \n",
    "    ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Post-Stim\\nMean Conn Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Pre-Stim\\nMean Conn Strength')      \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "plt.savefig('./e02-Figures/Pre_MeanConnStrength-Post_MeanConnStrength.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#### Frequency-Averaged\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "sel_subj = df_stim_topo.groupby(['Subject_ID']).mean().reset_index()    \n",
    "\n",
    "# Plot Regression\n",
    "slope, yint, rho, pv, stderr = stats.linregress(sel_subj['Pre_MeanConnStr'],\n",
    "                                                sel_subj['Post_MeanConnStr'])\n",
    " \n",
    "n_pts = len(sel_coh['Pre_MeanConnStr'])\n",
    "ax.plot([0.0, 1.0], slope*np.array([0.0, 1.0])+yint,\n",
    "        color='k', alpha=1.0, linewidth=1.0)    \n",
    "ax.scatter(sel_coh['Pre_MeanConnStr'],\n",
    "           sel_coh['Post_MeanConnStr'],\n",
    "           s=20.0, lw=0, color='k', alpha=0.2)\n",
    "ax.text(0.2, 0.75, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "\n",
    "ax.set_xlim([0, 1.0])\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.set_xticks(np.linspace(0.0, 1.0, 3))     \n",
    "ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "ax.set_ylabel('Post-Stim\\nMean Conn Strength')\n",
    "ax.set_xlabel('Pre-Stim\\nMean Conn Strength')      \n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Pre_MeanConnStrength-Post_MeanConnStrength.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Independent Frequency\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_base_coh = sel_base_topo[sel_base_topo['Coherence_ID'] == coh_id]\n",
    "    sel_stim_coh = sel_stim_topo[sel_stim_topo['Coherence_ID'] == coh_id]    \n",
    "\n",
    "    sel_base_subj_coh = sel_base_coh.loc[sel_base_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "    sel_stim_subj_coh = sel_stim_coh.loc[sel_stim_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "    \n",
    "    subj_base_cor = sel_base_subj_coh['Base_Delta_Cor']\n",
    "    subj_stim_cor = sel_stim_subj_coh['Delta_Cor'] \n",
    "\n",
    "    bp1 = ax.boxplot([subj_stim_cor], positions=[ii], patch_artist=True)\n",
    "    Echobase.Plotting.fig_format.set_box_color(bp1, 'k', [[0.00, 0.37, 1.00]])\n",
    "    \n",
    "    bp2 = ax.boxplot([subj_base_cor], positions=[ii+0.2], patch_artist=True)\n",
    "    Echobase.Plotting.fig_format.set_box_color(bp2, 'k', [[0.25, 0.25, 0.25]])\n",
    "    \n",
    "    print(stats.ttest_rel(subj_base_cor, subj_stim_cor))\n",
    "\n",
    "ax.set_xlim([-0.5, 4])\n",
    "ax.set_xticks(np.arange(len(coherence_id))+0.1)\n",
    "ax.set_xticklabels(coherence_id)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_yticks(np.linspace(0.0, 1.0, 3)) \n",
    "ax.set_ylabel('Topological Similarity')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('./e02-Figures/Topological_Similarity-Stim_Base_Comparison.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Frequency-Average\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "sel_base_coh = df_base_topo.groupby(['Subject_ID']).mean().reset_index()    \n",
    "sel_stim_coh = df_stim_topo.groupby(['Subject_ID']).mean().reset_index()    \n",
    "\n",
    "sel_base_subj_coh = sel_base_coh.loc[sel_base_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "sel_stim_subj_coh = sel_stim_coh.loc[sel_stim_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "\n",
    "subj_base_cor = sel_base_subj_coh['Base_Delta_Cor']\n",
    "subj_stim_cor = sel_stim_subj_coh['Delta_Cor'] \n",
    "\n",
    "bp1 = ax.boxplot([subj_stim_cor], positions=[2.0], patch_artist=True)\n",
    "Echobase.Plotting.fig_format.set_box_color(bp1, 'k', [[0.00, 0.37, 1.00]])\n",
    "\n",
    "bp2 = ax.boxplot([subj_base_cor], positions=[1.0], patch_artist=True)\n",
    "Echobase.Plotting.fig_format.set_box_color(bp2, 'k', [[0.50, 0.50, 0.50]])\n",
    "\n",
    "print(stats.ttest_rel(subj_base_cor, subj_stim_cor))\n",
    "\n",
    "ax.set_xlim([0.0, 3.0])\n",
    "ax.set_xticks([1.0, 2.0])\n",
    "ax.set_xticklabels(['Baseline', 'Stimulation'])\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_yticks(np.linspace(0.0, 1.0, 3)) \n",
    "ax.set_ylabel('Topological Similarity')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Topological_Similarity-Stim_Base_Comparison.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evoked Node Strength "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Independent Frequency\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_base_coh = sel_base_topo[sel_base_topo['Coherence_ID'] == coh_id]\n",
    "    sel_stim_coh = sel_stim_topo[sel_stim_topo['Coherence_ID'] == coh_id]    \n",
    "        \n",
    "    sel_base_subj_coh = sel_base_coh.loc[sel_base_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "    sel_stim_subj_coh = sel_stim_coh.loc[sel_stim_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "        \n",
    "    subj_base_cor = sel_base_subj_coh['Base_Delta_Node_Cnt']\n",
    "    subj_stim_cor = sel_stim_subj_coh['Stim_Delta_Node_Cnt'] \n",
    "\n",
    "    bp1 = ax.boxplot([subj_stim_cor], positions=[ii], patch_artist=True)\n",
    "    Echobase.Plotting.fig_format.set_box_color(bp1, 'k', [[0.00, 0.37, 1.00]])\n",
    "    \n",
    "    bp2 = ax.boxplot([subj_base_cor], positions=[ii+0.2], patch_artist=True)\n",
    "    Echobase.Plotting.fig_format.set_box_color(bp2, 'k', [[0.25, 0.25, 0.25]])\n",
    "    \n",
    "    print(stats.ttest_rel(subj_base_cor, subj_stim_cor))\n",
    "\n",
    "ax.set_xlim([-0.5, 4])\n",
    "ax.set_xticks(np.arange(len(coherence_id))+0.1)\n",
    "ax.set_xticklabels(coherence_id)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_ylim([0.0, 0.6])\n",
    "ax.set_yticks(np.linspace(0.0, 0.6, 3)) \n",
    "ax.set_ylabel('Fraction of Nodes Evoked')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('./e02-Figures/Evoked_Node-Stim_Base_Comparison.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#### Frequency-Average\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "sel_base_coh = df_base_topo.groupby(['Subject_ID']).mean().reset_index()    \n",
    "sel_stim_coh = df_stim_topo.groupby(['Subject_ID']).mean().reset_index()    \n",
    "\n",
    "sel_base_subj_coh = sel_base_coh.loc[sel_base_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "sel_stim_subj_coh = sel_stim_coh.loc[sel_stim_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "\n",
    "subj_base_cor = sel_base_subj_coh['Base_Delta_Node_Cnt']\n",
    "subj_stim_cor = sel_stim_subj_coh['Stim_Delta_Node_Cnt'] \n",
    "\n",
    "bp1 = ax.boxplot([subj_stim_cor], positions=[2.0], patch_artist=True)\n",
    "Echobase.Plotting.fig_format.set_box_color(bp1, 'k', [[0.00, 0.37, 1.00]])\n",
    "\n",
    "bp2 = ax.boxplot([subj_base_cor], positions=[1.0], patch_artist=True)\n",
    "Echobase.Plotting.fig_format.set_box_color(bp2, 'k', [[0.50, 0.50, 0.50]])\n",
    "\n",
    "print(stats.ttest_rel(subj_base_cor, subj_stim_cor))\n",
    "\n",
    "ax.set_xlim([0.0, 3.0])\n",
    "ax.set_xticks([1.0, 2.0])\n",
    "ax.set_xticklabels(['Baseline', 'Stimulation'])\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_ylim([0.0, 0.6])\n",
    "ax.set_yticks(np.linspace(0.0, 0.6, 3)) \n",
    "ax.set_ylabel('Fraction of Nodes Evoked')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Evoked_Node-Stim_Base_Comparison.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinct Modes of Functional Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological Similarity vs. Evoked Node Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Independent Frequency\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = sel_stim_topo[sel_stim_topo['Coherence_ID'] == coh_id]\n",
    "    \n",
    "    subj_stim_cor = sel_stim_coh['Delta_Cor']    \n",
    "    subj_stim_delta_cnt = sel_stim_coh['Stim_Delta_Node_Cnt']\n",
    "            \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_stim_delta_cnt, subj_stim_cor)\n",
    "    ax.plot([0.0, 1.0], slope*np.array([0.0, 1.0])+yint,\n",
    "            color='k', alpha=1.0, linewidth=1.0)    \n",
    "    ax.scatter(subj_stim_delta_cnt,\n",
    "               subj_stim_cor,\n",
    "               s=20.0, lw=0, color=[0.5, 0.5, 0.5], alpha=0.2)\n",
    "    ax.text(0.01, 0.8, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_xticks(np.linspace(0.0, 1.0, 3))\n",
    "    ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "    ax.set_ylabel('Topological Similarity')\n",
    "    ax.set_xlabel('Fraction of Evoked Nodes')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Evoked_Node-Topological_Similarity.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#### Frequency-Averaged\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "sel_stim_coh = df_stim_topo.groupby(['Subject_ID']).mean().reset_index()\n",
    "\n",
    "subj_stim_cor = sel_stim_coh['Delta_Cor']    \n",
    "subj_stim_delta_cnt = sel_stim_coh['Stim_Delta_Node_Cnt']\n",
    "\n",
    "# Plot Regression\n",
    "slope, yint, rho, pv, stderr = stats.linregress(subj_stim_delta_cnt, subj_stim_cor)\n",
    "ax.plot([0.0, 0.6], slope*np.array([0.0, 0.6])+yint,\n",
    "        color='k', alpha=1.0, linewidth=1.0)    \n",
    "ax.scatter(subj_stim_delta_cnt,\n",
    "           subj_stim_cor,\n",
    "           s=20.0, lw=0, color='k', alpha=0.2)\n",
    "ax.text(0.01, 0.8, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "\n",
    "ax.set_xlim([0.0, 0.6])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xticks(np.linspace(0.0, 0.6, 3))\n",
    "ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "ax.set_ylabel('Topological Similarity')\n",
    "ax.set_xlabel('Fraction of Evoked Nodes')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Evoked_Node-Topological_Similarity.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Baseline Variance of Coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_base_coh = df_base_topo[df_base_topo['Coherence_ID'] == coh_id]\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "    \n",
    "    base_vcs_subj = []   \n",
    "    stim_cor_subj = []\n",
    "    for subj_id in common_base_stim_subject_id:\n",
    "        sel_base_subj_coh = sel_base_coh[sel_base_coh['Subject_ID'] == subj_id]\n",
    "        sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]        \n",
    "        \n",
    "        base_adj_matr = sel_base_subj_coh['Base_AdjMatr'].iloc[0]\n",
    "        base_cfg_vec = convert_adj_matr_to_cfg_matr(\n",
    "            base_adj_matr.reshape(1, base_adj_matr.shape[0],\n",
    "                                  base_adj_matr.shape[0]))\n",
    "        base_vcs_subj.append(np.var(base_cfg_vec))\n",
    "        \n",
    "        stim_cor_subj.append(sel_stim_subj_coh['Delta_Cor'].mean())\n",
    "    base_vcs_subj = np.array(base_vcs_subj)\n",
    "    stim_cor_subj = np.array(stim_cor_subj)    \n",
    "            \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(base_vcs_subj, stim_cor_subj)\n",
    "    ax.plot([-4, 0], slope*np.array([-4, 0])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(base_vcs_subj, stim_cor_subj, s=1.0,\n",
    "               color='r', alpha=0.5, lw=0)\n",
    "    ax.text(-3.5, 0.7, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([-4, 0])\n",
    "    ax.set_ylim([-0.1, 1.1])\n",
    "    ax.set_xticks(np.linspace(-4, 0, 3))    \n",
    "    ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Topological Similarity')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Baseline log(var)\\nConn Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Base_VarConnStrength-Topological_Similarity.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Evoked Node Strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_base_coh = df_base_topo[df_base_topo['Coherence_ID'] == coh_id]\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "    \n",
    "    base_vcs_subj = []   \n",
    "    stim_cor_subj = []\n",
    "    for subj_id in common_base_stim_subject_id:\n",
    "        sel_base_subj_coh = sel_base_coh[sel_base_coh['Subject_ID'] == subj_id]\n",
    "        sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]        \n",
    "        \n",
    "        base_adj_matr = sel_base_subj_coh['Base_AdjMatr'].iloc[0]\n",
    "        base_cfg_vec = convert_adj_matr_to_cfg_matr(\n",
    "            base_adj_matr.reshape(1, base_adj_matr.shape[0],\n",
    "                                  base_adj_matr.shape[0]))\n",
    "        base_vcs_subj.append(np.var(base_cfg_vec))\n",
    "        \n",
    "        stim_cor_subj.append(sel_stim_subj_coh['Stim_Mag_Delta_NodeStr'].mean())\n",
    "    base_vcs_subj = np.array(base_vcs_subj)\n",
    "    stim_cor_subj = np.array(stim_cor_subj)    \n",
    "            \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(base_vcs_subj, stim_cor_subj)\n",
    "    ax.plot([-4, 0], slope*np.array([-4, 0])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(base_vcs_subj, stim_cor_subj, s=1.0,\n",
    "               color='r', alpha=0.5, lw=0)\n",
    "    ax.text(-3.5, 0.7, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([-4, 0])\n",
    "    ax.set_ylim([-0.1, 1.1])\n",
    "    ax.set_xticks(np.linspace(-4, 0, 3))\n",
    "    ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Fraction of Evoked Nodes')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Baseline log(var)\\nConn Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Base_VarConnStrength-Evoked_Node.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Predictors of Localized Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Topological Effect of Baseline Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Independent Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_base_coh = df_base_topo[df_base_topo['Coherence_ID'] == coh_id]    \n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "    \n",
    "    base_conn_subj = []\n",
    "    delta_ns_subj = []\n",
    "    for subj_id in common_base_stim_subject_id:\n",
    "        sel_base_subj_coh = sel_base_coh[sel_base_coh['Subject_ID'] == subj_id]            \n",
    "        sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "    \n",
    "        base_adj_matr = sel_base_subj_coh['Base_AdjMatr'].iloc[0]    \n",
    "        base_cfg_vec = convert_adj_matr_to_cfg_matr(\n",
    "            base_adj_matr.reshape(1, base_adj_matr.shape[0],\n",
    "                                  base_adj_matr.shape[0]))[0, :]\n",
    "        base_cfg_vec = (base_cfg_vec - base_cfg_vec.mean()) / base_cfg_vec.std()\n",
    "        base_adj_matr = convert_conn_vec_to_adj_matr(base_cfg_vec)\n",
    "        \n",
    "        base_conn = []\n",
    "        delta_ns = []            \n",
    "        for rr in sel_stim_subj_coh.iterrows():\n",
    "            delta_ns_thresh = np.abs(rr[1]['Delta_NodeStr_Thresh'])\n",
    "            \n",
    "            sig_ix = np.flatnonzero(delta_ns_thresh > 0)\n",
    "            delta_ns.append(np.nanmean(delta_ns_thresh[sig_ix]))\n",
    "            \n",
    "            stim_anode_jack = rr[1]['Stim_Anode']\n",
    "            stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "            stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "            stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "            stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "            \n",
    "            base_adj_matr_del = np.delete(base_adj_matr, stim_ix, axis=1)\n",
    "            \n",
    "            base_conn.append(np.mean(base_adj_matr_del[stim_ix, :][:, sig_ix]))\n",
    "\n",
    "        base_conn_subj.append(np.nanmean(base_conn))\n",
    "        delta_ns_subj.append(np.nanmean(delta_ns))\n",
    "            \n",
    "    base_conn_subj = np.array(base_conn_subj)\n",
    "    delta_ns_subj = np.array(delta_ns_subj)\n",
    "                \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(base_conn_subj, delta_ns_subj)\n",
    "    ax.plot([-1, 1], slope*np.array([-1, 1])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(base_conn_subj, delta_ns_subj, s=1.0,\n",
    "               color='k', alpha=0.5, lw=0)\n",
    "    rho, pv = stats.spearmanr(base_conn_subj, delta_ns_subj)\n",
    "    ax.text(0.5, 0.15, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-1.5, 1.5])\n",
    "    ax.set_ylim([0.0, 0.3])\n",
    "    ax.set_xticks(np.linspace(-1.5, 1.5, 4))\n",
    "    ax.set_yticks(np.linspace(0.0, 0.3, 3))    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('|Evoked Node Strengths|')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Baseline Conn. Strength\\nto Evoked Nodes')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "plt.savefig('./e02-Figures/Baseline_ConnTopo-Evoked_Node.svg')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "### Average Frequencies\n",
    "sel_base_coh = df_base_topo.copy()\n",
    "sel_stim_coh = df_stim_topo.copy()\n",
    "\n",
    "base_conn_subj = []\n",
    "delta_ns_subj = []\n",
    "for subj_id in common_base_stim_subject_id:\n",
    "    sel_base_subj = df_base_topo[df_base_topo['Subject_ID'] == subj_id]\n",
    "    sel_stim_subj = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "    \n",
    "    base_conn = []\n",
    "    delta_ns = []                \n",
    "    for coh_id in coherence_id:\n",
    "        sel_base_subj_coh = sel_base_subj[sel_base_subj['Coherence_ID'] == coh_id]\n",
    "        sel_stim_subj_coh = sel_stim_subj[sel_stim_subj['Coherence_ID'] == coh_id]\n",
    "    \n",
    "        base_adj_matr = sel_base_subj_coh['Base_AdjMatr'].iloc[0]    \n",
    "        base_cfg_vec = convert_adj_matr_to_cfg_matr(\n",
    "            base_adj_matr.reshape(1, base_adj_matr.shape[0],\n",
    "                                  base_adj_matr.shape[0]))[0, :]\n",
    "        base_cfg_vec = (base_cfg_vec - base_cfg_vec.mean()) / base_cfg_vec.std()\n",
    "        base_adj_matr = convert_conn_vec_to_adj_matr(base_cfg_vec)\n",
    "\n",
    "        for rr in sel_stim_subj_coh.iterrows():\n",
    "            delta_ns_thresh = np.abs(rr[1]['Delta_NodeStr_Thresh'])\n",
    "\n",
    "            sig_ix = np.flatnonzero(delta_ns_thresh > 0)\n",
    "            delta_ns.append(np.nanmean(delta_ns_thresh[sig_ix]))\n",
    "\n",
    "            stim_anode_jack = rr[1]['Stim_Anode']\n",
    "            stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "            stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "            stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "            stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "\n",
    "            base_adj_matr_del = np.delete(base_adj_matr, stim_ix, axis=1)\n",
    "\n",
    "            base_conn.append(np.mean(base_adj_matr_del[stim_ix, :][:, sig_ix]))\n",
    "\n",
    "    base_conn_subj.append(np.nanmean(base_conn))\n",
    "    delta_ns_subj.append(np.nanmean(delta_ns))\n",
    "\n",
    "base_conn_subj = np.array(base_conn_subj)\n",
    "delta_ns_subj = np.array(delta_ns_subj)\n",
    "\n",
    "# Plot Regression\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "slope, yint, rho, pv, stderr = stats.linregress(base_conn_subj, delta_ns_subj)\n",
    "ax.plot([-0.8, 0.8], slope*np.array([-0.8, 0.8])+yint, color='k', alpha=1.0, linewidth=1.0)    \n",
    "ax.scatter(base_conn_subj, delta_ns_subj,\n",
    "           s=20.0, color='k', alpha=0.2, lw=0)\n",
    "ax.text(0.5, 0.15, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "\n",
    "ax.set_xlim([-0.8, 0.8])\n",
    "ax.set_ylim([0.0, 0.2])\n",
    "ax.set_xticks(np.linspace(-0.8, 0.8, 3))\n",
    "ax.set_yticks(np.linspace(0.0, 0.2, 3))    \n",
    "ax.set_ylabel('|Evoked Node Strengths|')\n",
    "ax.set_xlabel('Baseline Coherence\\nto Evoked Nodes')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Baseline_ConnTopo-Evoked_Node.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural Topological Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Independent Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "    \n",
    "    base_conn_subj = []\n",
    "    delta_ns_subj = []\n",
    "    for subj_id in stim_subject_id:\n",
    "        sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_adj_matr_orig = channel_dict['Subject'][subj_id]['Struct_Adj']['scale250']['QA']\n",
    "        if np.isnan(base_adj_matr_orig).any():\n",
    "            continue\n",
    "        base_adj_matr = base_adj_matr_orig.copy()\n",
    "        #base_adj_matr[base_adj_matr == 0] = np.nan      \n",
    "        \n",
    "        base_conn = []\n",
    "        delta_ns = []    \n",
    "        for rr in sel_stim_subj_coh.iterrows():\n",
    "            delta_ns_thresh = np.abs(rr[1]['Delta_NodeStr_Thresh'])\n",
    "            \n",
    "            sig_ix = np.flatnonzero(delta_ns_thresh > 0)\n",
    "            delta_ns.append(np.nanmean(delta_ns_thresh[sig_ix]))\n",
    "            \n",
    "            stim_anode_jack = rr[1]['Stim_Anode']\n",
    "            stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "            stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "            stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "            stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "            \n",
    "            base_adj_matr_del = np.delete(base_adj_matr, stim_ix, axis=1)\n",
    "            \n",
    "            base_conn.append(np.nanmean(base_adj_matr_del[stim_ix, :][:, sig_ix]))\n",
    "\n",
    "        base_conn_subj.append(np.nanmean(base_conn))\n",
    "        delta_ns_subj.append(np.nanmean(delta_ns))\n",
    "            \n",
    "    base_conn_subj = np.array(base_conn_subj)\n",
    "    delta_ns_subj = np.array(delta_ns_subj)\n",
    "                \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(base_conn_subj, delta_ns_subj)\n",
    "    ax.plot([0.0, 0.15], slope*np.array([0.0, 0.15])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(base_conn_subj, delta_ns_subj, s=1.0,\n",
    "               color='k', alpha=0.5, lw=0)\n",
    "    rho, pv = stats.spearmanr(base_conn_subj, delta_ns_subj)\n",
    "    ax.text(0.08, 0.15, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "        \n",
    "    ax.set_xlim([0.0, 0.15])\n",
    "    ax.set_ylim([0.0, 0.2])\n",
    "    ax.set_xticks(np.linspace(0.0, 0.15, 4))\n",
    "    ax.set_yticks(np.linspace(0.0, 0.20, 3))      \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('|Evoked Node Strengths|')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Structural Conn. Strength\\nto Evoked Nodes')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "plt.savefig('./e02-Figures/Structural_ConnTopo-Evoked_Node.svg')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### Average Frequencies\n",
    "rho_null = []\n",
    "base_conn_subj = []\n",
    "delta_ns_subj = []\n",
    "for null_i in xrange(1001):\n",
    "    print(null_i)\n",
    "    \n",
    "    base_conn_null = []\n",
    "    delta_ns_null = []\n",
    "    for subj_id in stim_subject_id:\n",
    "        sel_stim_subj = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_adj_matr_orig = channel_dict['Subject'][subj_id]['Struct_Adj']['scale250']['QA']\n",
    "        if np.isnan(base_adj_matr_orig).any():\n",
    "            continue\n",
    "        if null_i > 0:\n",
    "            base_cfg_vec = convert_adj_matr_to_cfg_matr(base_adj_matr_orig.reshape(1, base_adj_matr_orig.shape[0], base_adj_matr_orig.shape[0]))[0, :]\n",
    "            base_cfg_vec_rnd = np.random.permutation(base_cfg_vec)\n",
    "            base_adj_matr = convert_conn_vec_to_adj_matr(base_cfg_vec_rnd)\n",
    "        else:\n",
    "            base_adj_matr = base_adj_matr_orig.copy()\n",
    "\n",
    "        base_conn = []\n",
    "        delta_ns = []        \n",
    "        for coh_id in coherence_id:\n",
    "            sel_stim_subj_coh = sel_stim_subj[sel_stim_subj['Coherence_ID'] == coh_id]\n",
    "\n",
    "            for rr in sel_stim_subj_coh.iterrows():\n",
    "                delta_ns_thresh = np.abs(rr[1]['Delta_NodeStr_Thresh'])\n",
    "\n",
    "                sig_ix = np.flatnonzero(delta_ns_thresh > 0)\n",
    "                delta_ns.append(np.nanmean(delta_ns_thresh[sig_ix]))\n",
    "\n",
    "                stim_anode_jack = rr[1]['Stim_Anode']\n",
    "                stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "                stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "                stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "                stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "\n",
    "                base_adj_matr_del = np.delete(base_adj_matr, stim_ix, axis=1)\n",
    "\n",
    "                base_conn.append(np.nanmean(base_adj_matr_del[stim_ix, :][:, sig_ix]))\n",
    "        \n",
    "        if null_i > 0:\n",
    "            base_conn_null.append(np.nanmean(base_conn))\n",
    "            delta_ns_null.append(np.nanmean(delta_ns))\n",
    "        else:\n",
    "            base_conn_subj.append(np.nanmean(base_conn))\n",
    "            delta_ns_subj.append(np.nanmean(delta_ns))\n",
    "\n",
    "    if null_i > 0:\n",
    "        rho_null.append(stats.pearsonr(base_conn_null, delta_ns_null)[0])\n",
    "    else:\n",
    "        rho = stats.pearsonr(base_conn_subj, delta_ns_subj)[0]\n",
    "\n",
    "        \n",
    "# Plot the null distribution\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "bin_height = ax.hist(rho_null, 50, normed=True, color='k', lw=0)[0]\n",
    "ax.vlines(rho_true, 0, np.max(bin_height), linewidth=1.0, color='r')\n",
    "\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('CorrCoef: QA vs Evoked Node Strength')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Structural_ConnTopo-Evoked_Node-NullHist.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot Regression   \n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "slope, yint, _, _, stderr = stats.linregress(base_conn_subj, delta_ns_subj)\n",
    "pv = np.mean(rho_null > rho)\n",
    "\n",
    "ax.plot([0.0, 0.015], slope*np.array([0.0, 0.015])+yint, 'k', alpha=1.0, linewidth=1.0)    \n",
    "ax.scatter(base_conn_subj, delta_ns_subj,\n",
    "           s=20.0, color='k', alpha=0.2, lw=0)\n",
    "ax.text(0.001, 0.025, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "\n",
    "ax.set_xlim([0.0, 0.015])\n",
    "ax.set_ylim([0.0, 0.1])\n",
    "ax.set_xticks(np.linspace(0.0, 0.015, 3))\n",
    "ax.set_yticks(np.linspace(0.0, 0.1, 3))      \n",
    "\n",
    "ax.set_ylabel('|Evoked Node Strengths|')\n",
    "ax.set_xlabel('Structural Conn. Strength\\nto Evoked Nodes')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Structural_ConnTopo-Evoked_Node.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Effect of Distance to Stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "stim_dist_coh = []\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_base_coh = df_base_topo[df_base_topo['Coherence_ID'] == coh_id]    \n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "    \n",
    "    stim_dist_subj = []\n",
    "    for subj_id in common_base_stim_subject_id:\n",
    "        sel_base_subj_coh = sel_base_coh[sel_base_coh['Subject_ID'] == subj_id]            \n",
    "        sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "    \n",
    "        dist_matr = channel_dict['Subject'][subj_id]['Dist_Matr']\n",
    "        base_zns = sel_base_subj_coh['Base_ZNodeStr'].iloc[0]\n",
    "        \n",
    "        stim_dist = []\n",
    "        for rr in sel_stim_subj_coh.iterrows():\n",
    "            delta_ns_thresh = np.abs(rr[1]['Delta_NodeStr_Thresh'])\n",
    "            sig_ix = np.flatnonzero(delta_ns_thresh > 0)\n",
    "            \n",
    "            stim_anode_jack = rr[1]['Stim_Anode']\n",
    "            stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "            stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "            stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "            stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "            \n",
    "            dist_matr_del = np.delete(dist_matr, stim_ix, axis=1)\n",
    "            \n",
    "            stim_dist.append(np.mean(dist_matr_del[stim_ix, :][:, sig_ix]))\n",
    "\n",
    "        stim_dist_subj.append(np.nanmean(stim_dist))\n",
    "    stim_dist_coh.append(stim_dist_subj)\n",
    "stim_dist_coh = np.array(stim_dist_coh)\n",
    "\n",
    "# Plot Regression\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.errorbar(np.arange(len(coherence_id)), stim_dist_coh.mean(axis=1),\n",
    "            yerr=stim_dist_coh.std(axis=1) / np.sqrt(len(common_base_stim_subject_id)),\n",
    "            color='k', alpha=0.5)    \n",
    "print(stats.spearmanr(np.arange(len(coherence_id)), stim_dist_coh.mean(axis=1)))\n",
    "\n",
    "ax.set_xlim([-0.1, len(coherence_id)-0.9])\n",
    "ax.set_ylim([57, 63])\n",
    "ax.set_yticks(np.linspace(57, 63, 3))  \n",
    "ax.set_xticks(np.arange(len(coherence_id)))\n",
    "ax.set_ylabel('Stim Distance to Evoked Node (mm)')\n",
    "ax.set_xticklabels(coherence_id)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "plt.savefig('./e02-Figures/Distance_Stim-Evoked_Node.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Input Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stim_freqs = np.unique(df_stim_topo['Stim_Freq'])\n",
    "stim_amps = np.unique(df_stim_topo['Stim_Amp'])\n",
    "\n",
    "stim_freqs = np.array([sfreq if len(np.unique(df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq]['Subject_ID'])) > 2 else np.nan\n",
    "              for sfreq in stim_freqs])\n",
    "stim_freqs = stim_freqs[~np.isnan(stim_freqs)]\n",
    "\n",
    "stim_amps = np.array([samp if len(np.unique(df_stim_topo[df_stim_topo['Stim_Amp'] == samp]['Subject_ID'])) > 2 else np.nan\n",
    "              for samp in stim_amps])\n",
    "stim_amps = stim_amps[~np.isnan(stim_amps)]\n",
    "\n",
    "n_freq = len(stim_freqs)\n",
    "n_amp = len(stim_amps)\n",
    "\n",
    "sel_metric = 'Delta_Cor'\n",
    "\"\"\"\n",
    "### Independent Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, coh_id in enumerate(coherence_id):  \n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    ### For the heatmap\n",
    "    mean_evoke_map = np.nan*np.zeros((n_freq, n_amp))\n",
    "    err_evoke_map = np.nan*np.zeros((n_freq, n_amp))    \n",
    "    energy = []\n",
    "    evoke_mean = []\n",
    "    evoke_err = []\n",
    "    for sfreq_i, sfreq in enumerate(stim_freqs):\n",
    "        for samp_i, samp in enumerate(stim_amps):\n",
    "            \n",
    "            sel_stim_freq_amp = sel_stim_coh[(sel_stim_coh['Stim_Freq'] == sfreq) &\n",
    "                                             (sel_stim_coh['Stim_Amp'] == samp)]\n",
    "            sel_stim_subj_freq_amp = sel_stim_freq_amp.groupby(['Subject_ID']).mean().unstack()\n",
    "                                             \n",
    "            mean_evoke_map[sfreq_i, samp_i] = np.nanmean(sel_stim_subj_freq_amp[sel_metric])\n",
    "            err_evoke_map[sfreq_i, samp_i] = np.nanstd(sel_stim_subj_freq_amp[sel_metric]) / np.sqrt(len(sel_stim_subj_freq_amp[sel_metric]))\n",
    "            \n",
    "            energy.append(np.log10(sfreq)*samp)\n",
    "            evoke_mean.append(mean_evoke_map[sfreq_i, samp_i])\n",
    "            evoke_err.append(err_evoke_map[sfreq_i, samp_i])\n",
    "            \n",
    "    # Plot Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(energy, evoke_mean)\n",
    "    \n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    ax.plot([0.0, 4.0], slope*np.array([0.0, 4.0])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(energy, evoke_mean,\n",
    "               s=2.0, color=[0.5, 0.5, 0.5], lw=0)\n",
    "    ax.text(2.5, 0.45, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([0, 4])\n",
    "    ax.set_ylim([0.1, 0.5])\n",
    "    ax.set_xticks(np.linspace(0, 4, 3))\n",
    "    ax.set_yticks(np.linspace(0.1, 0.50, 3))        \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Topological Similarity')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Input Energy\\n(log$_{10}$Hz-mA)')      \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Input_Energy-Topological_Similarity.svg')\n",
    "plt.show()    \n",
    "\"\"\"\n",
    "\n",
    "### Average Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "sel_stim_coh = df_stim_topo.copy()\n",
    "\n",
    "### For the heatmap\n",
    "mean_evoke_map = np.nan*np.zeros((n_freq, n_amp))\n",
    "err_evoke_map = np.nan*np.zeros((n_freq, n_amp))    \n",
    "energy = []\n",
    "evoke_mean = []\n",
    "evoke_err = []\n",
    "for sfreq_i, sfreq in enumerate(stim_freqs):\n",
    "    for samp_i, samp in enumerate(stim_amps):\n",
    "\n",
    "        sel_stim_freq_amp = sel_stim_coh[(sel_stim_coh['Stim_Freq'] == sfreq) &\n",
    "                                         (sel_stim_coh['Stim_Amp'] == samp)]\n",
    "        sel_stim_subj_freq_amp = sel_stim_freq_amp.groupby(['Subject_ID']).mean().unstack()\n",
    "\n",
    "        mean_evoke_map[sfreq_i, samp_i] = np.nanmean(sel_stim_subj_freq_amp[sel_metric])\n",
    "        err_evoke_map[sfreq_i, samp_i] = np.nanstd(sel_stim_subj_freq_amp[sel_metric]) / np.sqrt(len(sel_stim_subj_freq_amp[sel_metric]))\n",
    "\n",
    "        energy.append(np.log10(sfreq)*samp)\n",
    "        evoke_mean.append(mean_evoke_map[sfreq_i, samp_i])\n",
    "        evoke_err.append(err_evoke_map[sfreq_i, samp_i])\n",
    "\n",
    "# Plot Regression\n",
    "slope, yint, rho, pv, stderr = stats.linregress(energy, evoke_mean)\n",
    "\n",
    "ax.plot([0.0, 4.0], slope*np.array([0.0, 4.0])+yint, 'k', alpha=1.0, linewidth=1.0) \n",
    "ax.scatter(energy, evoke_mean,\n",
    "           s=20.0, color='k', alpha=0.2, lw=0)\n",
    "ax.text(2.5, 0.38, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "\n",
    "ax.set_xlim([0, 4])\n",
    "ax.set_ylim([0.25, 0.45])\n",
    "ax.set_xticks(np.linspace(0, 4, 3))\n",
    "ax.set_yticks(np.linspace(0.25, 0.45, 3))        \n",
    "ax.set_ylabel('Topological Similarity')\n",
    "ax.set_xlabel('Input Energy\\n(log$_{10}$Hz-mA)')      \n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_title(coh_id)\n",
    "\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Input_Energy-Topological_Similarity.svg')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Evoked Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stim_freqs = np.unique(df_stim_topo['Stim_Freq'])\n",
    "stim_amps = np.unique(df_stim_topo['Stim_Amp'])\n",
    "\n",
    "stim_freqs = np.array([sfreq if len(np.unique(df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq]['Subject_ID'])) > 2 else np.nan\n",
    "              for sfreq in stim_freqs])\n",
    "stim_freqs = stim_freqs[~np.isnan(stim_freqs)]\n",
    "\n",
    "stim_amps = np.array([samp if len(np.unique(df_stim_topo[df_stim_topo['Stim_Amp'] == samp]['Subject_ID'])) > 2 else np.nan\n",
    "              for samp in stim_amps])\n",
    "stim_amps = stim_amps[~np.isnan(stim_amps)]\n",
    "\n",
    "n_freq = len(stim_freqs)\n",
    "n_amp = len(stim_amps)\n",
    "\n",
    "sel_metric = 'Stim_Delta_Node_Cnt'\n",
    "\"\"\"\n",
    "### Independent Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, coh_id in enumerate(coherence_id):  \n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    ### For the heatmap\n",
    "    mean_evoke_map = np.nan*np.zeros((n_freq, n_amp))\n",
    "    err_evoke_map = np.nan*np.zeros((n_freq, n_amp))    \n",
    "    energy = []\n",
    "    evoke_mean = []\n",
    "    evoke_err = []\n",
    "    for sfreq_i, sfreq in enumerate(stim_freqs):\n",
    "        for samp_i, samp in enumerate(stim_amps):\n",
    "            \n",
    "            sel_stim_freq_amp = sel_stim_coh[(sel_stim_coh['Stim_Freq'] == sfreq) &\n",
    "                                             (sel_stim_coh['Stim_Amp'] == samp)]\n",
    "            sel_stim_subj_freq_amp = sel_stim_freq_amp.groupby(['Subject_ID']).mean().unstack()\n",
    "                                             \n",
    "            mean_evoke_map[sfreq_i, samp_i] = np.nanmean(sel_stim_subj_freq_amp[sel_metric])\n",
    "            err_evoke_map[sfreq_i, samp_i] = np.nanstd(sel_stim_subj_freq_amp[sel_metric]) / np.sqrt(len(sel_stim_subj_freq_amp[sel_metric]))\n",
    "            \n",
    "            energy.append(np.log10(sfreq)*samp)\n",
    "            evoke_mean.append(mean_evoke_map[sfreq_i, samp_i])\n",
    "            evoke_err.append(err_evoke_map[sfreq_i, samp_i])\n",
    "            \n",
    "    # Plot Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(energy, evoke_mean)\n",
    "    \n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    ax.plot([0.0, 4.0], slope*np.array([0.0, 4.0])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(energy, evoke_mean,\n",
    "               s=2.0, color=[0.5, 0.5, 0.5], lw=0)\n",
    "    ax.text(2.5, 0.45, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([0, 4])\n",
    "    ax.set_ylim([0.25, 0.5])\n",
    "    ax.set_xticks(np.linspace(0, 4, 3))      \n",
    "    ax.set_yticks(np.linspace(0.25, 0.50, 3))    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Fraction of Evoked Node')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Input Energy\\n(log$_{10}$Hz-mA)')      \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "\n",
    "plt.savefig('./e02-Figures/Input_Energy-Evoked_Node.svg')\n",
    "plt.show()   \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### Average Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "sel_stim_coh = df_stim_topo.copy() \n",
    "\n",
    "### For the heatmap\n",
    "mean_evoke_map = np.nan*np.zeros((n_freq, n_amp))\n",
    "err_evoke_map = np.nan*np.zeros((n_freq, n_amp))    \n",
    "energy = []\n",
    "evoke_mean = []\n",
    "evoke_err = []\n",
    "for sfreq_i, sfreq in enumerate(stim_freqs):\n",
    "    for samp_i, samp in enumerate(stim_amps):\n",
    "\n",
    "        sel_stim_freq_amp = sel_stim_coh[(sel_stim_coh['Stim_Freq'] == sfreq) &\n",
    "                                         (sel_stim_coh['Stim_Amp'] == samp)]\n",
    "        sel_stim_subj_freq_amp = sel_stim_freq_amp.groupby(['Subject_ID']).mean().unstack()\n",
    "\n",
    "        mean_evoke_map[sfreq_i, samp_i] = np.nanmean(sel_stim_subj_freq_amp[sel_metric])\n",
    "        err_evoke_map[sfreq_i, samp_i] = np.nanstd(sel_stim_subj_freq_amp[sel_metric]) / np.sqrt(len(sel_stim_subj_freq_amp[sel_metric]))\n",
    "\n",
    "        energy.append(np.log10(sfreq)*samp)\n",
    "        evoke_mean.append(mean_evoke_map[sfreq_i, samp_i])\n",
    "        evoke_err.append(err_evoke_map[sfreq_i, samp_i])\n",
    "\n",
    "# Plot Regression\n",
    "slope, yint, rho, pv, stderr = stats.linregress(energy, evoke_mean)\n",
    "\n",
    "ax.plot([0.0, 4.0], slope*np.array([0.0, 4.0])+yint, 'k', alpha=1.0, linewidth=1.0)    \n",
    "ax.scatter(energy, evoke_mean,\n",
    "           s=20.0, color='k', alpha=0.2, lw=0)\n",
    "ax.text(2.5, 0.41, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0)\n",
    "\n",
    "ax.set_xlim([0, 4])\n",
    "ax.set_ylim([0.34, 0.44])\n",
    "ax.set_xticks(np.linspace(0, 4, 3))      \n",
    "ax.set_yticks(np.linspace(0.34, 0.44, 3))    \n",
    "ax.set_ylabel('Fraction of Evoked Node')\n",
    "ax.set_xlabel('Input Energy\\n(log$_{10}$Hz-mA)')      \n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Input_Energy-Evoked_Node.svg')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Stimulation Location (Functional Hubness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Independent Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    base_conn_subj = []\n",
    "    delta_cor_subj = []    \n",
    "    for subj_id in common_base_stim_subject_id:\n",
    "        sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "        base_conn_subj.append(sel_stim_subj_coh['Stim_Base_ZNodeStr'].mean())\n",
    "        delta_cor_subj.append(sel_stim_subj_coh['Delta_Cor'].mean())\n",
    "    \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(base_conn_subj, delta_cor_subj)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(base_conn_subj, delta_cor_subj, s=1.0,\n",
    "               color='k', alpha=0.5, lw=0)\n",
    "    rho, pv = stats.spearmanr(base_conn_subj, delta_cor_subj)\n",
    "    ax.text(1.0, 0.8, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-3, 3])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_xticks(np.linspace(-3, 3, 4))\n",
    "    ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Topological Similarity')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Baseline Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "plt.savefig('./e02-Figures/Baseline_ZNodeStr-Topological_Similarity.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Average Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "sel_stim_coh = df_stim_topo.groupby(['Subject_ID']).mean().reset_index()    \n",
    "sel_stim_subj_coh = sel_stim_coh.loc[sel_stim_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "\n",
    "base_conn_subj = []\n",
    "delta_cor_subj = []    \n",
    "for subj_id in common_base_stim_subject_id:\n",
    "    sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "    base_conn_subj.append(sel_stim_subj_coh['Stim_Base_ZNodeStr'].mean())\n",
    "    delta_cor_subj.append(sel_stim_subj_coh['Delta_Cor'].mean())\n",
    "    \n",
    "# Plot Regression\n",
    "slope, yint, rho, pv, stderr = stats.linregress(base_conn_subj, delta_cor_subj)\n",
    "ax.plot([-3, 3], slope*np.array([-3, 3])+yint, 'k', alpha=1.0, linewidth=1.0)    \n",
    "ax.scatter(base_conn_subj, delta_cor_subj,\n",
    "           s=20.0, color='k', alpha=0.2, lw=0)\n",
    "ax.text(1.0, 0.8, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "\n",
    "ax.set_xlim([-3, 3])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xticks(np.linspace(-3, 3, 4))\n",
    "ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "ax.set_ylabel('Topological Similarity')\n",
    "ax.set_xlabel('Baseline Node Strength')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_title(coh_id)\n",
    "    \n",
    "plt.savefig('./e02-Figures/Average-Baseline_ZNodeStr-Topological_Similarity.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Evoked Node Strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Independent Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    base_conn_subj = []\n",
    "    delta_ns_subj = []    \n",
    "    for subj_id in common_base_stim_subject_id:\n",
    "        sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "        base_conn_subj.append(sel_stim_subj_coh['Stim_Base_ZNodeStr'].mean())\n",
    "        delta_ns_subj.append(sel_stim_subj_coh['Stim_Delta_Node_Cnt'].mean())\n",
    "    \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(base_conn_subj, delta_ns_subj)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(base_conn_subj, delta_ns_subj, s=1.0,\n",
    "               color='k', alpha=0.5, lw=0)\n",
    "    rho, pv = stats.spearmanr(base_conn_subj, delta_ns_subj)\n",
    "    ax.text(1.0, 0.22, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-3, 3])\n",
    "    ax.set_ylim([0.0, 0.6])\n",
    "    ax.set_xticks(np.linspace(-3, 3, 4))\n",
    "    ax.set_yticks(np.linspace(0.0, 0.6, 3))    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Fraction of Nodes Evoked')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Baseline Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "plt.savefig('./e02-Figures/Baseline_ZNodeStr-Evoked_Node.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Average Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1, 1, 1)    \n",
    "    \n",
    "sel_stim_coh = df_stim_topo.groupby(['Subject_ID']).mean().reset_index()    \n",
    "sel_stim_subj_coh = sel_stim_coh.loc[sel_stim_coh['Subject_ID'].isin(common_base_stim_subject_id)]\n",
    "\n",
    "base_conn_subj = []\n",
    "delta_ns_subj = []    \n",
    "for subj_id in common_base_stim_subject_id:\n",
    "    sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "    base_conn_subj.append(sel_stim_subj_coh['Stim_Base_ZNodeStr'].mean())\n",
    "    delta_ns_subj.append(sel_stim_subj_coh['Stim_Delta_Node_Cnt'].mean())\n",
    "\n",
    "# Plot Regression\n",
    "slope, yint, rho, pv, stderr = stats.linregress(base_conn_subj, delta_ns_subj)\n",
    "ax.plot([-3, 3], slope*np.array([-3, 3])+yint, 'k', alpha=1.0, linewidth=1.0)    \n",
    "ax.scatter(base_conn_subj, delta_ns_subj,\n",
    "           s=20.0, color='k', alpha=0.2, lw=0)\n",
    "ax.text(1.0, 0.15, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "\n",
    "ax.set_xlim([-3, 3])\n",
    "ax.set_ylim([0.0, 0.6])\n",
    "ax.set_xticks(np.linspace(-3, 3, 4))\n",
    "ax.set_yticks(np.linspace(0.0, 0.6, 3))    \n",
    "ax.set_ylabel('Fraction of Nodes Evoked')\n",
    "ax.set_xlabel('Baseline Node Strength')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Baseline_ZNodeStr-Evoked_Node.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Stimulation Location (Structural Hubness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Independent Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    base_conn_subj = []\n",
    "    delta_cor_subj = []    \n",
    "    for subj_id in stim_subject_id:\n",
    "        struct_adj = channel_dict['Subject'][subj_id]['Struct_Adj']['scale250']['QA']\n",
    "        if np.isnan(struct_adj).any():\n",
    "            continue\n",
    "        deg_vec = np.nanmean(struct_adj, axis=0)\n",
    "        deg_vec = (deg_vec - np.nanmean(deg_vec)) / np.nanstd(deg_vec)\n",
    "        \n",
    "        base_conn = []\n",
    "        sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "        for rr in sel_stim_subj_coh.iterrows():\n",
    "            stim_anode_jack = rr[1]['Stim_Anode']\n",
    "            stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "            stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "            stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "            stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "            \n",
    "            base_conn.append(np.nanmean(deg_vec[stim_ix]))\n",
    "        base_conn_subj.append(np.nanmean(base_conn))\n",
    "        delta_cor_subj.append(sel_stim_subj_coh['Delta_Cor'].mean())\n",
    "    \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(base_conn_subj, delta_cor_subj)\n",
    "    ax.plot([-1.5, 1.5], slope*np.array([-1.5, 1.5])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(base_conn_subj, delta_cor_subj, s=1.0,\n",
    "               color='k', alpha=0.5, lw=0)\n",
    "    ax.text(-1.0, 0.8, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-1.5, 1.5])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_xticks(np.linspace(-1.5, 1.5, 3))\n",
    "    ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Topological Similarity')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Structural Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "plt.savefig('./e02-Figures/Structural_ZNodeStr-Topological_Similarity.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### Average Frequencies\n",
    "rho_null = []\n",
    "base_conn_subj = []\n",
    "delta_cor_subj = []    \n",
    "for null_i in xrange(1001):\n",
    "    \n",
    "    base_conn_null = []\n",
    "    delta_cor_null = []\n",
    "    for subj_id in stim_subject_id:\n",
    "        base_adj_matr_orig = channel_dict['Subject'][subj_id]['Struct_Adj']['scale250']['QA']\n",
    "        if np.isnan(base_adj_matr_orig).any():\n",
    "            continue\n",
    "        if null_i > 0:\n",
    "            base_cfg_vec = convert_adj_matr_to_cfg_matr(base_adj_matr_orig.reshape(1, base_adj_matr_orig.shape[0], base_adj_matr_orig.shape[0]))[0, :]\n",
    "            base_cfg_vec_rnd = np.random.permutation(base_cfg_vec)\n",
    "            base_adj_matr = convert_conn_vec_to_adj_matr(base_cfg_vec_rnd)\n",
    "        else:\n",
    "            base_adj_matr = base_adj_matr_orig.copy()\n",
    "        deg_vec = np.nanmean(base_adj_matr, axis=0)\n",
    "        deg_vec = (deg_vec - deg_vec.mean()) / deg_vec.std()\n",
    "\n",
    "        base_conn = []\n",
    "        sel_stim_subj_coh = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "        for rr_ii, rr in enumerate(sel_stim_subj_coh.iterrows()):\n",
    "            stim_anode_jack = rr[1]['Stim_Anode']\n",
    "            stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "            stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "            stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "            stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "\n",
    "            base_conn.append(np.nanmean(deg_vec[stim_ix]))\n",
    "            \n",
    "        if null_i > 0:\n",
    "            base_conn_null.append(np.nanmean(base_conn))\n",
    "            delta_cor_null.append(sel_stim_subj_coh['Delta_Cor'].mean())\n",
    "        else:\n",
    "            base_conn_subj.append(np.nanmean(base_conn))\n",
    "            delta_cor_subj.append(sel_stim_subj_coh['Delta_Cor'].mean())\n",
    "            \n",
    "    if null_i > 0:\n",
    "        rho_null.append(stats.pearsonr(base_conn_null, delta_cor_null)[0])\n",
    "    else:\n",
    "        rho = stats.pearsonr(base_conn_subj, delta_cor_subj)[0]\n",
    "        \n",
    "# Plot the null distribution\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "bin_height = ax.hist(rho_null, 50, normed=True, color='k', lw=0)[0]\n",
    "ax.vlines(rho, 0, np.max(bin_height), linewidth=1.0, color='r')\n",
    "\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('CorrCoef: QA Degr vs Topo. Siml.')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Structural_ZNodeStr-Topological_Similarity-NullHist.svg')\n",
    "plt.show()            \n",
    "\n",
    "# Plot Regression\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "slope, yint, _, _, stderr = stats.linregress(base_conn_subj, delta_cor_subj)\n",
    "pv = np.mean(rho_null > rho)\n",
    "\n",
    "ax.plot([-1.5, 1.5], slope*np.array([-1.5, 1.5])+yint, 'k', alpha=1.0, linewidth=1.0)    \n",
    "ax.scatter(base_conn_subj, delta_cor_subj,\n",
    "           s=20.0, color='k', alpha=0.2, lw=0)\n",
    "ax.text(-1.2, 0.8, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "\n",
    "ax.set_xlim([-1.5, 1.5])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xticks(np.linspace(-1.5, 1.5, 3))\n",
    "ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "ax.set_ylabel('Topological Similarity')\n",
    "ax.set_xlabel('Structural Node Strength')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Structural_ZNodeStr-Topological_Similarity.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Evoked Node Strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Independent Frequencies\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    base_conn_subj = []\n",
    "    delta_cor_subj = []    \n",
    "    for subj_id in stim_subject_id:\n",
    "        struct_adj = channel_dict['Subject'][subj_id]['Struct_Adj']['scale250']['QA']\n",
    "        if np.isnan(struct_adj).any():\n",
    "            continue\n",
    "        deg_vec = np.nanmean(struct_adj, axis=0)\n",
    "        deg_vec = (deg_vec - np.nanmean(deg_vec)) / np.nanstd(deg_vec)\n",
    "        \n",
    "        base_conn = []\n",
    "        sel_stim_subj_coh = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "        for rr in sel_stim_subj_coh.iterrows():\n",
    "            stim_anode_jack = rr[1]['Stim_Anode']\n",
    "            stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "            stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "            stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "            stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "            \n",
    "            base_conn.append(np.nanmean(deg_vec[stim_ix]))\n",
    "        base_conn_subj.append(np.nanmean(base_conn))\n",
    "        delta_cor_subj.append(sel_stim_subj_coh['Stim_Delta_Node_Cnt'].mean())\n",
    "    \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(base_conn_subj, delta_cor_subj)\n",
    "    ax.plot([-1.5, 1.5], slope*np.array([-1.5, 1.5])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(base_conn_subj, delta_cor_subj, s=1.0,\n",
    "               color='k', alpha=0.5, lw=0)\n",
    "    ax.text(0.002, 0.8, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-1.5, 1.5])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_xticks(np.linspace(-1.5, 1.5, 3))\n",
    "    ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Fraction of Nodes Evoked')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Structural Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "plt.savefig('./e02-Figures/Structural_ZNodeStr-Evoked_Node.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Average Frequencies\n",
    "rho_null = []\n",
    "base_conn_subj = []\n",
    "delta_cor_subj = []    \n",
    "for null_i in xrange(1001):\n",
    "    \n",
    "    base_conn_null = []\n",
    "    delta_cor_null = []        \n",
    "    for subj_id in stim_subject_id:\n",
    "        base_adj_matr_orig = channel_dict['Subject'][subj_id]['Struct_Adj']['scale250']['QA']\n",
    "        if np.isnan(base_adj_matr_orig).any():\n",
    "            continue\n",
    "        if null_i > 0:\n",
    "            base_cfg_vec = convert_adj_matr_to_cfg_matr(base_adj_matr_orig.reshape(1, base_adj_matr_orig.shape[0], base_adj_matr_orig.shape[0]))[0, :]\n",
    "            base_cfg_vec_rnd = np.random.permutation(base_cfg_vec)\n",
    "            base_adj_matr = convert_conn_vec_to_adj_matr(base_cfg_vec_rnd)\n",
    "        else:\n",
    "            base_adj_matr = base_adj_matr_orig.copy()\n",
    "        deg_vec = np.nanmean(base_adj_matr, axis=0)\n",
    "        deg_vec = (deg_vec - deg_vec.mean()) / deg_vec.std()\n",
    "\n",
    "        base_conn = []\n",
    "        sel_stim_subj_coh = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "        for rr in sel_stim_subj_coh.iterrows():\n",
    "            stim_anode_jack = rr[1]['Stim_Anode']\n",
    "            stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "            stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "            stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "            stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "\n",
    "            base_conn.append(np.nanmean(deg_vec[stim_ix]))\n",
    "\n",
    "        if null_i > 0:\n",
    "            base_conn_null.append(np.nanmean(base_conn))\n",
    "            delta_cor_null.append(sel_stim_subj_coh['Stim_Delta_Node_Cnt'].mean())            \n",
    "        else:\n",
    "            base_conn_subj.append(np.nanmean(base_conn))\n",
    "            delta_cor_subj.append(sel_stim_subj_coh['Stim_Delta_Node_Cnt'].mean())\n",
    "            \n",
    "    if null_i > 0:\n",
    "        rho_null.append(stats.pearsonr(base_conn_null, delta_cor_null)[0])\n",
    "    else:\n",
    "        rho = stats.pearsonr(base_conn_subj, delta_cor_subj)[0]\n",
    "        \n",
    "        \n",
    "# Plot the null distribution\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "bin_height = ax.hist(rho_null, 50, normed=True, color='k', lw=0)[0]\n",
    "ax.vlines(rho, 0, np.max(bin_height), linewidth=1.0, color='r')\n",
    "\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('CorrCoef: QA Degr vs Topo. Siml.')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Structural_ZNodeStr-Evoked_Node-NullHist.svg')\n",
    "plt.show()            \n",
    "    \n",
    "\n",
    "# Plot Regression\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "slope, yint, _, _, stderr = stats.linregress(base_conn_subj, delta_cor_subj)\n",
    "pv = np.mean(rho_null > rho)\n",
    "\n",
    "ax.plot([-1.5, 1.5], slope*np.array([-1.5, 1.5])+yint, 'k', alpha=1.0, linewidth=1.0)    \n",
    "ax.scatter(base_conn_subj, delta_cor_subj,\n",
    "           s=20.0, color='k', alpha=0.2, lw=0)\n",
    "ax.text(-1.0, 0.8, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "\n",
    "ax.set_xlim([-1.5, 1.5])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xticks(np.linspace(-1.5, 1.5, 3))\n",
    "ax.set_yticks(np.linspace(0.0, 1.0, 3))    \n",
    "ax.set_ylabel('Fraction of Nodes Evoked')\n",
    "ax.set_xlabel('Structural Node Strength')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('./e02-Figures/Average-Structural_ZNodeStr-Evoked_Node.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulation Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/evoke_map.pkl'.format(path_ExpData)):\n",
    "    evoke_map = pkl.load(open('{}/evoke_map.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    evoke_map = {}\n",
    "    for scale in struct_dict['Atlas']:\n",
    "        print('Processing: {}'.format(scale))\n",
    "        \n",
    "        evoke_map[scale] = {}\n",
    "\n",
    "        roi_lbl = np.sort(np.array(struct_dict['Atlas'][scale].keys()))\n",
    "        n_roi = len(roi_lbl)\n",
    "\n",
    "        for ii, coh_id in enumerate(coherence_id):\n",
    "            evoke_map[scale][coh_id] = {}\n",
    "\n",
    "            sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "            for subj_id in stim_subject_id:\n",
    "                evoke_map_subj_ns = np.zeros((n_roi, n_roi))\n",
    "                evoke_map_subj_cnt = np.zeros((n_roi, n_roi))            \n",
    "\n",
    "                sel_subj_stim = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "\n",
    "                chan_atlas_lbl = np.array(channel_dict['Subject'][subj_id]['Atlas_Label'][scale])\n",
    "                n_chan = len(chan_atlas_lbl)\n",
    "\n",
    "                # Iterate over stimulation trials\n",
    "                for rr in sel_subj_stim.iterrows():\n",
    "                    delta_ns_thresh = np.abs(rr[1]['Delta_NodeStr_Thresh'])\n",
    "\n",
    "                    stim_anode_jack = rr[1]['Stim_Anode']\n",
    "                    stim_cathode_jack = rr[1]['Stim_Cathode']\n",
    "\n",
    "                    stim_anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_anode_jack)[0]\n",
    "                    stim_cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == stim_cathode_jack)[0]\n",
    "                    stim_ix = np.array([stim_anode_ix, stim_cathode_ix])\n",
    "\n",
    "                    chan_atlas_lbl_nostim = chan_atlas_lbl[np.setdiff1d(np.arange(n_chan), stim_ix)]\n",
    "\n",
    "                    # Get stim location\n",
    "                    anode_loc = chan_atlas_lbl[stim_anode_ix]\n",
    "                    anode_roi_ix = np.flatnonzero(roi_lbl == anode_loc)[0]\n",
    "\n",
    "                    cathode_loc = chan_atlas_lbl[stim_cathode_ix]\n",
    "                    cathode_roi_ix = np.flatnonzero(roi_lbl == cathode_loc)[0]   \n",
    "\n",
    "                    for ns_ii, ns in enumerate(delta_ns_thresh):\n",
    "                        if np.isnan(ns):\n",
    "                            continue\n",
    "\n",
    "                        roi_lbl_ix = np.flatnonzero(roi_lbl == chan_atlas_lbl_nostim[ns_ii])[0]\n",
    "                        evoke_map_subj_ns[anode_roi_ix, roi_lbl_ix] += ns\n",
    "                        evoke_map_subj_cnt[anode_roi_ix, roi_lbl_ix] += 1\n",
    "\n",
    "                        evoke_map_subj_ns[cathode_roi_ix, roi_lbl_ix] += ns\n",
    "                        evoke_map_subj_cnt[cathode_roi_ix, roi_lbl_ix] += 1\n",
    "\n",
    "                evoke_map[scale][coh_id][subj_id] = evoke_map_subj_ns / evoke_map_subj_cnt\n",
    "                \n",
    "    pkl.dump(evoke_map, open('{}/evoke_map.pkl'.format(path_ExpData), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects of Structural Connectivity on Regional Modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for scale in evoke_map.keys():\n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(3,3), dpi=300)\n",
    "    \n",
    "    for ii, coh_id in enumerate(coherence_id):\n",
    "\n",
    "        delta_ns_subj = []\n",
    "        struct_conn_subj = []\n",
    "        for subj_id in evoke_map[scale][coh_id].keys():\n",
    "            if subj_id not in struct_dict['Subject'].keys():\n",
    "                continue\n",
    "\n",
    "            struct_adj = struct_dict['Subject'][subj_id][scale]['QA']['adj'].copy()   \n",
    "            #struct_vec = convert_adj_matr_to_cfg_matr(struct_adj.reshape(1, struct_adj.shape[0], -1)).ravel()\n",
    "            #struct_adj = convert_conn_vec_to_adj_matr(np.random.permutation(struct_vec))\n",
    "\n",
    "            emap = evoke_map[scale][coh_id][subj_id].copy()\n",
    "            \n",
    "            for src_ix in xrange(emap.shape[0]):\n",
    "                for targ_ix in xrange(emap.shape[1]):\n",
    "                    if np.isnan(emap[src_ix, targ_ix]):\n",
    "                        continue\n",
    "                    if struct_adj[src_ix, targ_ix] == 0:\n",
    "                        continue\n",
    "\n",
    "                    delta_ns_subj.append(emap[src_ix, targ_ix])\n",
    "                    struct_conn_subj.append(struct_adj[src_ix, targ_ix])\n",
    "        \n",
    "        \n",
    "        ax = plt.subplot(2,2,ii+1)\n",
    "        \n",
    "        slope, yint, rho, pv, stderr = stats.linregress(struct_conn_subj, delta_ns_subj)\n",
    "        ax.plot([0, 0.3], slope*np.array([0, 0.3])+yint, 'k', alpha=0.5)    \n",
    "        ax.scatter(struct_conn_subj, delta_ns_subj, s=1.0,\n",
    "                   color='k', alpha=0.5, lw=0)\n",
    "        ax.text(0.2, 0.14, ' rho=%0.2f\\n pv=%0.1e' % (rho, pv), fontsize=3.0, color='k')\n",
    "        \n",
    "        ax.set_xlim([0, 0.3])\n",
    "        ax.set_ylim([0.0, 0.3])\n",
    "        ax.set_xticks(np.linspace(0, 0.3, 3))\n",
    "        ax.set_yticks(np.linspace(0.0, 0.3, 3))    \n",
    "        if ii in [0, 2]:\n",
    "            ax.set_ylabel('|Evoked Node Strengths|')\n",
    "        if ii in [2, 3]:\n",
    "            ax.set_xlabel('Structural Connectivity')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.set_title(coh_id)\n",
    "\n",
    "    plt.savefig('./e02-Figures/Evoked_Map-Structural_Conn-{}.svg'.format(scale))\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_evoke_map = np.nanmean(np.nanmean(\n",
    "        np.array([evoke_map['scale33']['HighGamma'].values()]), axis=0), axis=0)\n",
    "\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "mat = ax.matshow(pop_evoke_map, cmap='viridis'); \n",
    "plt.colorbar(mat, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Stimulation Location (Functional Region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Node Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['ZNodeStr_AlphaTheta',\n",
    "             'ZNodeStr_Beta',\n",
    "             'ZNodeStr_LowGamma',\n",
    "             'ZNodeStr_HighGamma']\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_zns = sel_subj_base[afreq].mean()\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(base_zns[a_ix])\n",
    "            \n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            c_loc = c_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(base_zns[c_ix])\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    #ax.set_xlim([-0.5, len(lbl)-0.5])\n",
    "    ax.set_ylim([-1.25, 1.25])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Baseline\\nFunctional Connectivity of\\nStimulated Electrode')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq.split('_')[-1], Fv, Pv))\n",
    "    \n",
    "    \n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Mean Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_MeanConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_MeanConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_MeanConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_MeanConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "            \n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            c_loc = c_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    ax.set_ylim([-0.004, 0.015])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Mean of Evoked\\nConnection Strength')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq[0].split('_')[-1], Fv, Pv))\n",
    "    \n",
    "    \n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Variance of Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_VarConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_VarConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_VarConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_VarConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "            \n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            c_loc = c_loc.split('_')[1]                \n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    ax.set_ylim([0.015, 0.05])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Variance of Evoked\\nConnection Strength')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq[0].split('_')[-1], Fv, Pv))\n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity of Evoked Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_Cor_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_Cor_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_Cor_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_Cor_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "\n",
    "            arr = []\n",
    "            for trial in sel_stim[afreq[0]]:\n",
    "                arr.append(1-np.abs(trial))            \n",
    "            \n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            #if len(a_loc.split('_')) == 3:\n",
    "            #    a_loc = '_'.join(a_loc.split('_')[0:2])\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(np.mean(arr))\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            #if len(c_loc.split('_')) == 3:\n",
    "            #    c_loc = '_'.join(c_loc.split('_')[0:2])     \n",
    "            c_loc = c_loc.split('_')[1]            \n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(np.mean(arr))\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    ax.set_ylim([0.4, 1.0])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Evoked Reorg. of\\nNetwork Topology')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq[0].split('_')[-1], Fv, Pv))\n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Modulated Hubness of Brain Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 'scale250'\n",
    "\n",
    "roi_lbl = np.sort(np.array(struct_dict['Atlas'][scale].keys()))\n",
    "#roi_lbl = np.unique([roi.split('_')[1] for roi in roi_lbl])\n",
    "\n",
    "n_roi = len(roi_lbl)\n",
    "subj_lbl = []\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "\n",
    "evoke_map_coh = {}\n",
    "evoke_map_coh_cnt = {}\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "\n",
    "    evoke_map_ns = np.zeros((n_roi, n_roi))\n",
    "    evoke_map_cnt = np.zeros((n_roi, n_roi))    \n",
    "\n",
    "    evoke_map_subj_ns = np.zeros((n_roi, n_roi))\n",
    "    evoke_map_subj_cnt = np.zeros((n_roi, n_roi))        \n",
    "    \n",
    "    evoke_ns_targ_ds = []\n",
    "    struct_conn_targ_ds = []    \n",
    "    for subj_id in subject_id:\n",
    "        sel_subj_stim = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "        atlas_lbl = np.array(channel_dict['Subject'][subj_id]['Atlas_Label'][scale])\n",
    "        n_chan = len(atlas_lbl)\n",
    "        \n",
    "        evoke_subj_ns = np.zeros((n_roi, n_roi))\n",
    "        evoke_subj_cnt = np.zeros((n_roi, n_roi))    \n",
    "\n",
    "        # Iterate over stimulation trials\n",
    "        for rr in sel_subj_stim.iterrows():\n",
    "            delta_ns = rr[1]['Post_NodeStr'] - rr[1]['Pre_NodeStr']\n",
    "\n",
    "            anode_jack = rr[1]['Stim_Anode']\n",
    "            cathode_jack = rr[1]['Stim_Cathode']          \n",
    "            a_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            c_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]        \n",
    "            atlas_lbl_nostim = atlas_lbl[np.setdiff1d(np.arange(n_chan), [a_ix, c_ix])]\n",
    "            #atlas_lbl_nostim = np.array([roi.split('_')[1] for roi in atlas_lbl_nostim])\n",
    "            \n",
    "            # Get stim location\n",
    "            a_loc = atlas_lbl[a_ix]    \n",
    "            #a_loc = a_loc.split('_')[1]\n",
    "            a_roi_ix = np.flatnonzero(roi_lbl == a_loc)[0]\n",
    "\n",
    "            c_loc = atlas_lbl[c_ix]\n",
    "            #c_loc = c_loc.split('_')[1]            \n",
    "            c_roi_ix = np.flatnonzero(roi_lbl == c_loc)[0]   \n",
    "            \n",
    "            # Get max pos and max neg evoke\n",
    "            for chan_ix in xrange(len(atlas_lbl_nostim)):\n",
    "                roi_lbl_ix = np.flatnonzero(roi_lbl == atlas_lbl_nostim[chan_ix])[0]\n",
    "                evoke_map_ns[a_roi_ix, roi_lbl_ix] += delta_ns[chan_ix]\n",
    "                evoke_map_ns[c_roi_ix, roi_lbl_ix] += delta_ns[chan_ix]\n",
    "                evoke_map_cnt[a_roi_ix, roi_lbl_ix] += 1\n",
    "                evoke_map_cnt[c_roi_ix, roi_lbl_ix] += 1\n",
    "\n",
    "                evoke_subj_ns[a_roi_ix, roi_lbl_ix] += delta_ns[chan_ix]\n",
    "                evoke_subj_ns[c_roi_ix, roi_lbl_ix] += delta_ns[chan_ix]\n",
    "                evoke_subj_cnt[a_roi_ix, roi_lbl_ix] += 1\n",
    "                evoke_subj_cnt[c_roi_ix, roi_lbl_ix] += 1  \n",
    "        \n",
    "        evoke_subj_mns = evoke_subj_ns / evoke_subj_cnt\n",
    "        evoke_subj_mns[np.isnan(evoke_subj_mns)] = 0\n",
    "        \n",
    "        evoke_map_subj_ns += evoke_subj_mns\n",
    "        evoke_subj_cnt[evoke_subj_cnt > 0] = 1\n",
    "        evoke_map_subj_cnt += evoke_subj_cnt\n",
    "                    \n",
    "        # Correlate Subject's evoked map to Structural Connectivity\n",
    "        if subj_id in struct_dict['Subject'].keys():\n",
    "            subj_lbl.append(subj_id)\n",
    "            \n",
    "            for ixx, iyy in zip(np.nonzero(evoke_subj_mns)[0],\n",
    "                                np.nonzero(evoke_subj_mns)[1]):\n",
    "                if ixx == iyy:\n",
    "                    continue\n",
    "                s_conn = struct_dict['Subject'][subj_id][scale]['QA']['adj'][ixx, iyy]\n",
    "                if s_conn == 0:\n",
    "                    continue\n",
    "                    \n",
    "                evoke_ns_targ_ds.append(evoke_subj_mns[ixx, iyy])\n",
    "                struct_conn_targ_ds.append(s_conn)\n",
    "    evoke_ns_targ_ds = np.array(evoke_ns_targ_ds)\n",
    "    struct_conn_targ_ds = np.array(struct_conn_targ_ds)\n",
    "    \n",
    "    # Aggregate population evoked map\n",
    "    #evoke_map_mns = evoke_map_ns / evoke_map_cnt\n",
    "    #evoke_map_mns[np.isnan(evoke_map_mns)] = 0\n",
    "    evoke_map_coh[coh_id] = evoke_map_subj_ns / len(subject_id)\n",
    "    evoke_map_coh_cnt[coh_id] = evoke_map_subj_cnt\n",
    "    \n",
    "    # Plot relationship between structural connectivity between stim site and target vs. the functional effect of stim\n",
    "    ax = plt.subplot(2,2,ii+1)\n",
    "\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(struct_conn_targ_ds, evoke_ns_targ_ds)\n",
    "    #ax.plot([0.01, 0.20], slope*np.array([0.01, 0.20])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(struct_conn_targ_ds, evoke_ns_targ_ds, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    rho, pv = stats.spearmanr(struct_conn_targ_ds, evoke_ns_targ_ds)\n",
    "    print(coh_id, rho, pv)\n",
    "    #ax.text(0.15, 0.015, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    #ax.set_xlim([0, 0.21])\n",
    "    #ax.set_ylim([-0.02, 0.02])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Downstream Functional Effect')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Structural Connectivity\\n(Stim Target --> Downstream)')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "plt.savefig('./e02-Figures/StructuralConn-DSFunctionalEffect.{}.png'.format(coh_id))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoke = evoke_map_coh['AlphaTheta'].copy()\n",
    "evoke[evoke == 0] = np.nan\n",
    "\n",
    "evoke_cnt = evoke_map_coh_cnt['AlphaTheta']\n",
    "evoke[evoke_cnt < 2] = np.nan\n",
    "\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "mat = ax.matshow(evoke, cmap='coolwarm', vmin=-0.0005, vmax=0.0005)\n",
    "plt.colorbar(mat, ax=ax)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_xticks(xrange(len(roi_lbl)))\n",
    "ax.set_yticks(xrange(len(roi_lbl)))\n",
    "ax.set_xticklabels(roi_lbl, fontsize=3.0, rotation=90)\n",
    "ax.set_yticklabels(roi_lbl, fontsize=3.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Electrode-Level Adjacency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scale_id = 'scale250'\n",
    "atlas_lbl = np.array(struct_dict['Atlas'][scale_id].keys())\n",
    "\n",
    "electrode_struct_adj = {}\n",
    "\n",
    "for subj_id in np.intersect1d(struct_dict['Subject'].keys(),\n",
    "                              channel_dict['Subject'].keys()):\n",
    "    \n",
    "    roi_adj = struct_dict['Subject'][subj_id][scale_id]['QA']['adj']\n",
    "    \n",
    "    chan_atlas_lbl = channel_dict['Subject'][subj_id]['Atlas_Label'][scale_id]\n",
    "    chan_lbl = channel_dict['Subject'][subj_id]['Channel_Label']\n",
    "    n_chan = len(chan_atlas_lbl)\n",
    "    assert n_chan == len(chan_lbl)\n",
    "    adj = np.zeros((n_chan, n_chan))\n",
    "    \n",
    "    for ch_ix, lbl_x in enumerate(chan_atlas_lbl):\n",
    "        for ch_iy, lbl_y in enumerate(chan_atlas_lbl):\n",
    "            ix = np.flatnonzero(atlas_lbl == lbl_x)[0]\n",
    "            iy = np.flatnonzero(atlas_lbl == lbl_y)[0]\n",
    "            \n",
    "            adj[ch_ix, ch_iy] = roi_adj[ix, iy]\n",
    "    adj[np.diag_indices_from(adj)] = 0\n",
    "    \n",
    "    electrode_struct_adj[subj_id] = {'adj': adj,\n",
    "                                     'channel_label': chan_lbl,\n",
    "                                     'roi_label': chan_atlas_lbl}\n",
    "pkl.dump(electrode_struct_adj, open('{}/lausanne_scale250_electrode.pkl'.format(path_ExpData), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Input Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stim_freqs = np.unique(df_memory['Stim_Freq'])\n",
    "stim_amps = np.unique(df_memory['Stim_Amp'])\n",
    "\n",
    "stim_freqs = np.array([sfreq if len(np.unique(df_memory[df_memory['Stim_Freq'] == sfreq]['Subject_ID'])) > 2 else np.nan\n",
    "                       for sfreq in stim_freqs])\n",
    "stim_freqs = stim_freqs[~np.isnan(stim_freqs)]\n",
    "\n",
    "stim_amps = np.array([samp if len(np.unique(df_memory[df_memory['Stim_Amp'] == samp]['Subject_ID'])) > 2 else np.nan\n",
    "                      for samp in stim_amps])\n",
    "stim_amps = stim_amps[~np.isnan(stim_amps)]\n",
    "\n",
    "n_freq = len(stim_freqs)\n",
    "n_amp = len(stim_amps)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Stimulation Frequency\n",
    "mem_freq = []\n",
    "for sfreq in stim_freqs:\n",
    "    sel_freq = df_memory[df_memory['Stim_Freq'] == sfreq]\n",
    "    \n",
    "    subj_freq = []\n",
    "    for subj_id in np.unique(df_memory['Subject_ID']):\n",
    "        sel_memory = sel_freq[sel_freq['Subject_ID'] == subj_id]\n",
    "        subj_freq.append((sel_memory['Post_Stim_Prob'] - sel_memory['Pre_Stim_Prob']).mean())\n",
    "    mem_freq.append(subj_freq)\n",
    "    \n",
    "print('All Freq: {}'.format(stats.pearsonr(stim_freqs,  np.nanmean(np.array(mem_freq), axis=1))))\n",
    "print(' > 10 Hz: {}'.format(stats.pearsonr(stim_freqs[1:],  np.nanmean(np.array(mem_freq), axis=1)[1:])))\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.errorbar(stim_freqs, np.nanmean(np.array(mem_freq), axis=1), yerr=np.nanstd(np.array(mem_freq), axis=1) / np.sqrt(86))\n",
    "ax.set_xlim([0, 210])\n",
    "ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "ax.set_xlabel('Stimulation Frequency (Hz)')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')        \n",
    "plt.show()\n",
    "\n",
    "### Stimulation Amplitude\n",
    "mem_amp = []\n",
    "for samp in stim_amps:\n",
    "    sel_amp = df_memory[df_memory['Stim_Amp'] == samp]\n",
    "    \n",
    "    subj_amp = []\n",
    "    for subj_id in np.unique(df_memory['Subject_ID']):\n",
    "        sel_memory = sel_amp[sel_amp['Subject_ID'] == subj_id]\n",
    "        subj_amp.append((sel_memory['Post_Stim_Prob'] > sel_memory['Pre_Stim_Prob']).mean())\n",
    "    mem_amp.append(subj_amp)\n",
    "    \n",
    "print('All Amp: {}'.format(stats.pearsonr(stim_amps,  np.nanmean(np.array(mem_amp), axis=1))))\n",
    "plt.figure(figsize=(3,3), dpi=300)  \n",
    "ax = plt.subplot(111)\n",
    "ax.errorbar(stim_amps/1000, np.nanmean(np.array(mem_amp), axis=1), yerr=np.nanstd(np.array(mem_amp), axis=1) / np.sqrt(86))\n",
    "ax.set_xlim([0, 2.125])\n",
    "ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "ax.set_xlabel('Stimulation Amplitude (mA)')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Stimulation Location (Structural Control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scale = 'scale250'\n",
    "trk = 'QA'\n",
    "atlas_lbl = np.array(struct_dict['Atlas'][scale].keys())\n",
    "\n",
    "subj_lbl = []\n",
    "roi_lbl = []\n",
    "subj_strc_avg_ctl = []\n",
    "subj_strc_mod_ctl = []\n",
    "subj_delta_mem = []\n",
    "\n",
    "for subj_id in np.unique(df_memory['Subject_ID']):\n",
    "    try:\n",
    "        avg_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['avg_ctl'])\n",
    "        mod_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['mod_ctl'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    avg_ctl = (avg_ctl-avg_ctl.mean()) / avg_ctl.std()\n",
    "    mod_ctl = (mod_ctl-mod_ctl.mean()) / mod_ctl.std()            \n",
    "\n",
    "    sel_memory = df_memory[df_memory['Subject_ID'] == subj_id]\n",
    "\n",
    "    # Get stim anode/cathode pairs\n",
    "    stim_ix = []\n",
    "    for anode_jack, cathode_jack in zip(sel_memory['Stim_Anode'],\n",
    "                                        sel_memory['Stim_Cathode']):\n",
    "        try:\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        except:\n",
    "            continue\n",
    "    stim_ix = list(set(stim_ix))\n",
    "    \n",
    "    # Iterate over all stim pairs\n",
    "    for a_ix, c_ix in stim_ix:\n",
    "        a_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "        c_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "\n",
    "        a_roi_ix = np.flatnonzero(atlas_lbl == a_roi)[0]\n",
    "        c_roi_ix = np.flatnonzero(atlas_lbl == c_roi)[0]        \n",
    "\n",
    "        roi_lbl.append((a_roi, c_roi))\n",
    "        subj_strc_avg_ctl.append(0.5*(avg_ctl[c_roi_ix] + avg_ctl[a_roi_ix]))\n",
    "        subj_strc_mod_ctl.append(0.5*(mod_ctl[c_roi_ix] + mod_ctl[a_roi_ix]))            \n",
    "\n",
    "        a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "        c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "        sel_stim = sel_memory[sel_memory['Stim_Anode'] == a_jack]\n",
    "        sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "        \n",
    "        subj_lbl.append(subj_id)\n",
    "        subj_delta_mem.append((sel_stim['Post_Stim_Prob'] - sel_stim['Pre_Stim_Prob']).mean())\n",
    "\n",
    "subj_delta_mem = np.array(subj_delta_mem) \n",
    "subj_strc_avg_ctl = np.array(subj_strc_avg_ctl)  \n",
    "subj_strc_mod_ctl = np.array(subj_strc_mod_ctl)\n",
    "roi_lbl = np.array(roi_lbl)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Average Controllability\n",
    "slope, yint, rho, pv, stderr = stats.linregress(subj_strc_avg_ctl,\n",
    "                                                subj_delta_mem)\n",
    "\n",
    "plt.figure(figsize=(2,2), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.plot([-3, 3], slope*np.array([-3, 3])+yint, 'k', alpha=0.5)    \n",
    "ax.scatter(subj_strc_avg_ctl, subj_delta_mem,\n",
    "           s=3.0, color=[0.5, 0.5, 0.5], lw=0)\n",
    "ax.text(1.0, 0.01, ' rho=%0.2f\\n pv=%0.2e' % (rho, pv), fontsize=3.0)\n",
    "\n",
    "#ax.set_xlim([-1.5, 1.5])\n",
    "ax.set_ylim([-0.03, 0.03])\n",
    "ax.set_xlabel('Average Controllability\\n(Z-Score)')      \n",
    "ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.show()\n",
    "print(roi_lbl[np.argsort(subj_strc_avg_ctl)])\n",
    "\n",
    "### Modal Controllability\n",
    "slope, yint, rho, pv, stderr = stats.linregress(subj_strc_mod_ctl,\n",
    "                                                subj_delta_mem)\n",
    "\n",
    "plt.figure(figsize=(2,2), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "ax.plot([-4, 4], slope*np.array([-4, 4])+yint, 'k', alpha=0.5)    \n",
    "ax.scatter(subj_strc_mod_ctl, subj_delta_mem,\n",
    "           s=3.0, color=[0.5, 0.5, 0.5], lw=0)\n",
    "ax.text(-1.0, 0.02, ' rho=%0.2f\\n pv=%0.2e' % (rho, pv), fontsize=3.0)\n",
    "\n",
    "#ax.set_xlim([-1.5, 1.5])\n",
    "ax.set_ylim([-0.03, 0.03])\n",
    "ax.set_xlabel('Modal Controllability\\n(Z-Score)')      \n",
    "ax.set_ylabel('$\\Delta$ Memory Classifier')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.show()\n",
    "print(roi_lbl[np.argsort(subj_strc_mod_ctl)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Network Reorganization on Memory State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coh_id in coherence_id:\n",
    "    sel_stim_coh = df_stim_topo[df_stim_topo['Coherence_ID'] == coh_id]\n",
    "    sel_stim_coh = sel_stim_coh[sel_stim_coh['Experiment_ID'] == 'PS2']\n",
    "    \n",
    "    delta_stim_prob = []\n",
    "    z_nodestr = []\n",
    "    \n",
    "    for subj_id in np.unique(df_memory['Subject_ID']):\n",
    "        sel_mem_subj = df_memory[df_memory['Subject_ID'] == subj_id]\n",
    "        sel_stim_subj = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "        if len(sel_stim_subj) == 0:\n",
    "            continue\n",
    "        if subj_id not in np.unique(df_base_topo['Subject_ID']):\n",
    "            continue\n",
    "        \n",
    "        \"\"\"\n",
    "        anode_ix = np.intersect1d(sel_mem_subj['Stim_Anode'], sel_stim_subj['Stim_Anode'])\n",
    "        cathode_ix = np.intersect1d(sel_mem_subj['Stim_Cathode'], sel_stim_subj['Stim_Cathode'])\n",
    "\n",
    "        for an_ix in anode_ix:\n",
    "            for ct_ix in cathode_ix:         \n",
    "                sel_mem_subj_stim = sel_mem_subj[(sel_mem_subj['Stim_Anode'] == an_ix) &\n",
    "                                                 (sel_mem_subj['Stim_Cathode'] == ct_ix)]\n",
    "                sel_stim_subj_stim = sel_stim_subj[(sel_stim_subj['Stim_Anode'] == an_ix) &\n",
    "                                                   (sel_stim_subj['Stim_Cathode'] == ct_ix)]\n",
    "                if len(sel_mem_subj_stim) == 0:\n",
    "                    continue\n",
    "                if len(sel_stim_subj_stim) == 0:\n",
    "                    continue\n",
    "\n",
    "                delta_stim_prob.append((sel_mem_subj_stim['Post_Stim_Prob'] > \n",
    "                                        sel_mem_subj_stim['Pre_Stim_Prob']).mean())\n",
    "                z_nodestr.append(sel_stim_subj_stim['Delta_Cor'].mean())\n",
    "        \"\"\"\n",
    "        delta_stim_prob.append((sel_mem_subj['Post_Stim_Prob'] >\n",
    "                                sel_mem_subj['Pre_Stim_Prob']).mean())\n",
    "        z_nodestr.append(sel_stim_subj['Delta_Cor'].mean())\n",
    "    \n",
    "    print(stats.spearmanr(z_nodestr, delta_stim_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Effect of Network State on Memory State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig1 = plt.figure(figsize=(5,5), dpi=300)\n",
    "fig2 = plt.figure(figsize=(5,5), dpi=300)\n",
    "\n",
    "df_base_topo_nn = df_base_topo.dropna(axis=0)\n",
    "df_stim_topo_nn = df_stim_topo.dropna(axis=0)\n",
    "df_memory_nn = df_memory.dropna(axis=0)\n",
    "common_stim_mem_subject_id = np.intersect1d(df_stim_topo_nn['Subject_ID'],\n",
    "                                            df_memory_nn['Subject_ID'])\n",
    "\n",
    "opt_subj_id = []\n",
    "\n",
    "for ii, coh_id in enumerate(coherence_id):\n",
    "    sel_base_coh = df_base_topo_nn[df_base_topo_nn['Coherence_ID'] == coh_id]        \n",
    "    sel_stim_coh = df_stim_topo_nn[df_stim_topo_nn['Coherence_ID'] == coh_id]\n",
    "\n",
    "    pop_base_zns = []\n",
    "    pop_pre_mcs_corr = []\n",
    "    pop_delta_mcs_corr = []    \n",
    "    pop_pre_mcs_pv = []\n",
    "    pop_delta_mcs_pv = []    \n",
    "    for subj_id in common_stim_mem_subject_id:\n",
    "        sel_subj_base = sel_base_coh[sel_base_coh['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = sel_stim_coh[sel_stim_coh['Subject_ID'] == subj_id]\n",
    "        sel_subj_mem = df_memory_nn[df_memory_nn['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Iterate over stimulation trials\n",
    "        base_zns = []\n",
    "        pop_delta_mem_prob = []\n",
    "        pop_pre_mcs = []\n",
    "        pop_delta_mcs = []        \n",
    "        for rr in sel_subj_stim.iterrows():\n",
    "            ev_id = rr[1]['Event_ID']\n",
    "            a_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == rr[1]['Stim_Anode'])[0]\n",
    "            c_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == rr[1]['Stim_Cathode'])[0]\n",
    "\n",
    "            sel_subj_mem_ev = sel_subj_mem[sel_subj_mem['Event_ID'] == ev_id]\n",
    "            \n",
    "            pre_mem_prob = sel_subj_mem_ev['Pre_Stim_Prob']\n",
    "            post_mem_prob = sel_subj_mem_ev['Post_Stim_Prob']\n",
    "            delta_mem_prob = (post_mem_prob-pre_mem_prob).mean()\n",
    "            \n",
    "            if not np.isnan(delta_mem_prob):\n",
    "                pop_delta_mem_prob.append(delta_mem_prob)\n",
    "                pop_pre_mcs.append(rr[1]['Pre_MeanConnStr'])\n",
    "                pop_delta_mcs.append(np.percentile(rr[1]['Delta_NodeStr'], 5)) \n",
    "                 \n",
    "                base_zns_stim = 0.5*(sel_subj_base['Base_ZNodeStr'].mean()[a_ix] + \n",
    "                                     sel_subj_base['Base_ZNodeStr'].mean()[c_ix])\n",
    "                base_zns.append(base_zns_stim)            \n",
    "                #base_zns.append(rr[1]['Stim_Base_ZNodeStr'])\n",
    "        \n",
    "        pop_pre_mcs = np.array(pop_pre_mcs)\n",
    "        pop_delta_mcs = np.array(pop_delta_mcs)\n",
    "        pop_delta_mem_prob = np.array(pop_delta_mem_prob)\n",
    "        pre_mcs_corr = stats.pearsonr(pop_pre_mcs[1:] - pop_pre_mcs[:-1],\n",
    "                                      pop_delta_mem_prob[1:] - pop_delta_mem_prob[:-1])\n",
    "        delta_mcs_corr = stats.pearsonr(pop_delta_mcs[1:] - pop_delta_mcs[:-1],\n",
    "                                        pop_delta_mem_prob[1:] - pop_delta_mem_prob[:-1])\n",
    "        \n",
    "        #pre_mcs_corr = stats.pearsonr(pop_pre_mcs, pop_delta_mem_prob)\n",
    "        #delta_mcs_corr = stats.pearsonr(pop_delta_mcs, pop_delta_mem_prob)\n",
    "        \n",
    "        pop_pre_mcs_corr.append(pre_mcs_corr[0])\n",
    "        pop_delta_mcs_corr.append(delta_mcs_corr[0])\n",
    "        pop_pre_mcs_pv.append(pre_mcs_corr[1])\n",
    "        pop_delta_mcs_pv.append(delta_mcs_corr[1])\n",
    "        pop_base_zns.append(np.nanmean(base_zns))\n",
    "        \n",
    "    pop_pre_mcs_corr = np.array(pop_pre_mcs_corr)\n",
    "    pop_delta_mcs_corr = np.array(pop_delta_mcs_corr)\n",
    "    pop_pre_mcs_pv = np.array(pop_pre_mcs_pv)\n",
    "    pop_delta_mcs_pv = np.array(pop_delta_mcs_pv)\n",
    "    pop_base_zns = np.array(pop_base_zns)\n",
    "    \n",
    "    # Stats pre-proc\n",
    "    ord_subj_ix = np.argsort(pop_pre_mcs_corr)[::-1]\n",
    "    opt_subj_id.append(common_stim_mem_subject_id[ord_subj_ix[0]])\n",
    "    alpha = 0.05 / len(ord_subj_ix)\n",
    "    \n",
    "    \n",
    "    ### Correlation between pre stim network coherence and change in classifier likelihood\n",
    "    # on trial by trial basis\n",
    "    ax = fig1.add_subplot(4, 3, (3*ii)+1)\n",
    "    \n",
    "    colors = [[0.9, 0.3, 0.3] if pv < alpha else [0.3, 0.3, 0.9]\n",
    "              for pv in pop_pre_mcs_pv[ord_subj_ix]]    \n",
    "    ax.bar(xrange(len(ord_subj_ix)), pop_pre_mcs_corr[ord_subj_ix],\n",
    "           width=0.5, lw=0, color=colors)\n",
    "    ax.set_xlim([-0.5, len(ord_subj_ix)])\n",
    "    ax.set_ylabel('PearsonR(\\nPre-Stim Mean Conn.,\\n$\\Delta$Memory Classifier)')\n",
    "    ax.set_xlabel('RAM Subjects (PS2)')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)        \n",
    "    \n",
    "    \n",
    "    ### Correlation between change in network coherence and change in classifier likelihood\n",
    "    # on trial by trial basis\n",
    "    ax = fig1.add_subplot(4, 3, (3*ii)+2)\n",
    "    \n",
    "    colors = [[0.9, 0.3, 0.3] if pv < alpha else [0.3, 0.3, 0.9]\n",
    "              for pv in pop_delta_mcs_pv[ord_subj_ix]]\n",
    "    ax.bar(xrange(len(ord_subj_ix)), pop_delta_mcs_corr[ord_subj_ix],\n",
    "           width=0.5, lw=0, color=colors)\n",
    "    ax.set_xlim([-0.5, len(ord_subj_ix)])\n",
    "    ax.set_ylabel('PearsonR(\\n5% -$\\Delta$ Node Strength,\\n$\\Delta$Memory Classifier)')\n",
    "    ax.set_xlabel('RAM Subjects (PS2)')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "    \n",
    "\n",
    "    ### Correlation between delta network coherence and change in classifier likelihood\n",
    "    # on trial by trial basis\n",
    "    ax = fig1.add_subplot(4, 3, (3*ii)+3)\n",
    "   \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(pop_base_zns[ord_subj_ix], pop_delta_mcs_corr[ord_subj_ix])\n",
    "    ax.plot([-2, 2], slope*np.array([-1, 1])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(pop_base_zns[ord_subj_ix], pop_delta_mcs_corr[ord_subj_ix], s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.pearsonr(pop_base_zns[ord_subj_ix], pop_delta_mcs_corr[ord_subj_ix])\n",
    "    ax.text(-2, 0.2, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    #ax.set_xlim([-4, 4])\n",
    "    #ax.set_ylim([-4, 4])    \n",
    "    ax.set_ylabel('PearsonR(\\n5% -$\\Delta$ Node Strength,\\n$\\Delta$Memory Classifier)')\n",
    "    ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(coh_id)\n",
    "\n",
    "fig1.savefig('./e02-Figures/FunctionalConn-Memory_State_NEW.svg')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal stim state identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "lr = LogisticRegression(C=0.5, penalty='l2', solver='liblinear', multi_class='ovr')\n",
    "\n",
    "df_stim_topo_nn = df_stim_topo.dropna(axis=0)\n",
    "df_memory_nn = df_memory.dropna(axis=0)\n",
    "common_stim_mem_subject_id = np.intersect1d(df_stim_topo_nn['Subject_ID'],\n",
    "                                            df_memory_nn['Subject_ID'])\n",
    "\n",
    "# Iterate over subjects\n",
    "subjs = []\n",
    "base_zns = []\n",
    "pred = []\n",
    "pred_null = []\n",
    "for subj_id in common_stim_mem_subject_id:        \n",
    "    sel_subj_stim = df_stim_topo_nn[df_stim_topo_nn['Subject_ID'] == subj_id]\n",
    "    sel_subj_mem = df_memory_nn[df_memory_nn['Subject_ID'] == subj_id]\n",
    "\n",
    "    # Get stim anode/cathode pairs\n",
    "    stim_ix = []\n",
    "    for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                        sel_subj_stim['Stim_Cathode']):\n",
    "        anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "        cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "        stim_ix.append((anode_ix, cathode_ix))\n",
    "    stim_ix = list(set(stim_ix))\n",
    "\n",
    "    # Iterate over all stim pairs\n",
    "    for a_ix, c_ix in stim_ix:\n",
    "        a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "        c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]   \n",
    "        \n",
    "        sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "        sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "        \n",
    "        # Iterate over stimulation trials\n",
    "        pre_mcs = []\n",
    "        delta_mem_state = []\n",
    "        for ev_id in np.unique(sel_stim['Event_ID']):\n",
    "            sel_stim_ev = sel_stim[sel_stim['Event_ID'] == ev_id]\n",
    "            \n",
    "            # Pre-Stim Mean Coherence Feature\n",
    "            pre_mcs_coh = []\n",
    "            for coh_id in coherence_id:\n",
    "                sel_stim_coh = sel_stim_ev[sel_stim_ev['Coherence_ID'] == coh_id]\n",
    "                pre_mcs_coh.append(sel_stim_coh['Pre_MeanConnStr'].mean())\n",
    "                pre_mcs_coh.append(sel_stim_coh['Pre_VarConnStr'].mean())\n",
    "            pre_mcs.append(np.array(pre_mcs_coh).reshape(-1))\n",
    "\n",
    "            # Memory State Transition Output\n",
    "            sel_subj_mem_ev = sel_subj_mem[sel_subj_mem['Event_ID'] == ev_id]\n",
    "            pre_mem_prob = sel_subj_mem_ev['Pre_Stim_Prob']\n",
    "            post_mem_prob = sel_subj_mem_ev['Post_Stim_Prob']\n",
    "            delta_mem_state.append((post_mem_prob > pre_mem_prob).mean())\n",
    "                            \n",
    "        pre_mcs = np.array(pre_mcs)\n",
    "        delta_mem_state = np.array(delta_mem_state)\n",
    "        if np.nanmean(np.isnan(delta_mem_state)) == 1.0:\n",
    "            continue\n",
    "\n",
    "        pre_mcs_nn = pre_mcs[~np.isnan(delta_mem_state), :]\n",
    "        delta_mem_state_nn = delta_mem_state[~np.isnan(delta_mem_state)]\n",
    "        \n",
    "        # Split Train/Test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(pre_mcs_nn,\n",
    "                                                            delta_mem_state_nn,\n",
    "                                                            test_size=0.5)\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict_proba(X_test)\n",
    "        fpr, tpr, thr = roc_curve(y_test, y_pred[:, 1])\n",
    "        \n",
    "        subjs.append(subj_id)\n",
    "        base_zns.append(np.unique(sel_stim[sel_stim['Coherence_ID'] == 'AlphaTheta']['Stim_Base_ZNodeStr'])[0])\n",
    "        pred.append(auc(fpr, tpr))\n",
    "        \n",
    "        # Split Train/Test\n",
    "        for ii in xrange(100):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(pre_mcs_nn,\n",
    "                                                                np.random.permutation(delta_mem_state_nn),\n",
    "                                                                test_size=0.5)\n",
    "            lr.fit(X_train, y_train)\n",
    "            y_pred = lr.predict_proba(X_test)\n",
    "            fpr, tpr, thr = roc_curve(y_test, y_pred[:, 1])\n",
    "\n",
    "            pred_null.append(auc(fpr, tpr))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv, pv = stats.ttest_ind(pred, pred_null, equal_var=False)\n",
    "\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "bplot = ax.boxplot([pred, pred_null])\n",
    "ax.text(1.4, 0.5, ' $t$=%0.2f\\n$p$=%0.2e' % (tv, pv), fontsize=4.0)\n",
    "ax.set_title('Pre-Stim Prediction of\\nIncrease Likelihood of Good Memory State')\n",
    "ax.set_xticklabels(['Real', 'Null'])\n",
    "ax.set_ylabel('ROC Area Under Curve')\n",
    "\n",
    "ax.set_ylim([0.25, 0.75])\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('{}/LogisticRegression_OptimalTime.svg'.format(path_Figures))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "lr = LogisticRegression(C=0.5, penalty='l2', solver='liblinear', multi_class='ovr')\n",
    "\n",
    "df_stim_topo_nn = df_stim_topo.dropna(axis=0)\n",
    "df_memory_nn = df_memory.dropna(axis=0)\n",
    "common_stim_mem_subject_id = np.intersect1d(df_stim_topo_nn['Subject_ID'],\n",
    "                                            df_memory_nn['Subject_ID'])\n",
    "\n",
    "# Iterate over subjects\n",
    "subjs = []\n",
    "pred = []\n",
    "pred_null = []\n",
    "for subj_id in common_stim_mem_subject_id:        \n",
    "    sel_subj_stim = df_stim_topo_nn[df_stim_topo_nn['Subject_ID'] == subj_id]\n",
    "    sel_subj_mem = df_memory_nn[df_memory_nn['Subject_ID'] == subj_id]\n",
    "    sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]                    \n",
    "    \n",
    "    # Get stim anode/cathode pairs\n",
    "    stim_ix = []\n",
    "    for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                        sel_subj_stim['Stim_Cathode']):\n",
    "        anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "        cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "        stim_ix.append((anode_ix, cathode_ix))\n",
    "    stim_ix = list(set(stim_ix))\n",
    "    \n",
    "    if len(stim_ix) <= 1:\n",
    "        continue\n",
    "\n",
    "    # Iterate over all stim pairs\n",
    "    pre_mcs = []\n",
    "    delta_mem_state = []\n",
    "    for a_ix, c_ix in stim_ix:\n",
    "        a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "        c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]   \n",
    "        \n",
    "        sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "        sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "        \n",
    "        # Iterate over stimulation trials\n",
    "        for ev_id in np.unique(sel_stim['Event_ID']):\n",
    "            sel_stim_ev = sel_stim[sel_stim['Event_ID'] == ev_id]\n",
    "            \n",
    "            # Pre-Stim Mean Coherence Feature\n",
    "            pre_mcs_coh = []\n",
    "            for coh_id in coherence_id:\n",
    "                base_zns = sel_subj_base[sel_subj_base['Coherence_ID'] == coh_id]['Base_ZNodeStr'].mean()\n",
    "                base_zns_stim = 0.5*(base_zns[a_ix] + base_zns[c_ix])\n",
    "                pre_mcs_coh.append(base_zns_stim)\n",
    "            pre_mcs.append(np.array(pre_mcs_coh).reshape(-1))\n",
    "\n",
    "            # Memory State Transition Output\n",
    "            sel_subj_mem_ev = sel_subj_mem[sel_subj_mem['Event_ID'] == ev_id]\n",
    "            pre_mem_prob = sel_subj_mem_ev['Pre_Stim_Prob']\n",
    "            post_mem_prob = sel_subj_mem_ev['Post_Stim_Prob']\n",
    "            delta_mem_state.append((post_mem_prob > pre_mem_prob).mean())\n",
    "                            \n",
    "    pre_mcs = np.array(pre_mcs)\n",
    "    delta_mem_state = np.array(delta_mem_state)\n",
    "    if np.nanmean(np.isnan(delta_mem_state)) == 1.0:\n",
    "        continue\n",
    "\n",
    "    pre_mcs_nn = pre_mcs[~np.isnan(delta_mem_state), :]\n",
    "    delta_mem_state_nn = delta_mem_state[~np.isnan(delta_mem_state)]\n",
    "    if len(np.unique(pre_mcs_nn[:, 0])) <= 1:\n",
    "        continue\n",
    "        \n",
    "    # Split Train/Test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(pre_mcs_nn,\n",
    "                                                        delta_mem_state_nn,\n",
    "                                                        test_size=0.5)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict_proba(X_test)\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred[:, 1])\n",
    "\n",
    "    subjs.append(subj_id)\n",
    "    pred.append(auc(fpr, tpr))\n",
    "\n",
    "    # Split Train/Test\n",
    "    for ii in xrange(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(pre_mcs_nn,\n",
    "                                                            np.random.permutation(delta_mem_state_nn),\n",
    "                                                            test_size=0.5)\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict_proba(X_test)\n",
    "        fpr, tpr, thr = roc_curve(y_test, y_pred[:, 1])\n",
    "\n",
    "        pred_null.append(auc(fpr, tpr))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv, pv = stats.ttest_ind(pred, pred_null, equal_var=False)\n",
    "\n",
    "plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "bplot = ax.boxplot([pred, pred_null])\n",
    "ax.text(1.4, 0.5, ' $t$=%0.2f\\n$p$=%0.2e' % (tv, pv), fontsize=4.0)\n",
    "ax.set_title('Pre-Stim Prediction of\\nIncrease Likelihood of Good Memory State')\n",
    "ax.set_xticklabels(['Real', 'Null'])\n",
    "ax.set_ylabel('ROC Area Under Curve')\n",
    "\n",
    "ax.set_ylim([0.25, 0.75])\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('{}/LogisticRegression_OptimalLoc.svg'.format(path_Figures))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for trajectory analysis (for Jeni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stim_topo_nn = df_stim_topo.dropna(axis=0)\n",
    "df_memory_nn = df_memory.dropna(axis=0)\n",
    "\n",
    "common_stim_mem_subject_id = np.intersect1d(np.intersect1d(df_stim_topo_nn['Subject_ID'],\n",
    "                                                           df_memory_nn['Subject_ID']),\n",
    "                                            electrode_struct_adj.keys())\n",
    "\n",
    "for subj_id in common_stim_mem_subject_id:\n",
    "    sel_subj_stim = df_stim_topo_nn[df_stim_topo_nn['Subject_ID'] == subj_id]\n",
    "    sel_subj_mem = df_memory_nn[df_memory_nn['Subject_ID'] == subj_id]\n",
    "    \n",
    "    m_dict = {}\n",
    "    \n",
    "    m_dict['Struct_Adj'] = electrode_struct_adj[subj_id]['adj']\n",
    "    m_dict['Electrode_ROI'] = electrode_struct_adj[subj_id]['roi_label']\n",
    "    \n",
    "    m_dict['Stim_Anode_Idx'] = []\n",
    "    m_dict['Stim_Cathode_Idx'] = []    \n",
    "    m_dict['Stim_Freq'] = []\n",
    "    m_dict['Stim_Amp'] = []  \n",
    "    m_dict['Pre_Stim_Prob'] = []\n",
    "    m_dict['Post_Stim_Prob'] = []    \n",
    "    for ev_id in np.unique(sel_subj_stim['Event_ID']):\n",
    "        sel_subj_stim_ev = sel_subj_stim[sel_subj_stim['Event_ID'] == ev_id]\n",
    "        sel_subj_mem_ev = sel_subj_mem[sel_subj_mem['Event_ID'] == ev_id]\n",
    "        if len(sel_subj_mem_ev) == 1:\n",
    "            m_dict['Stim_Freq'].append(sel_subj_mem_ev['Stim_Freq'].ravel()[0])\n",
    "            m_dict['Stim_Amp'].append(sel_subj_mem_ev['Stim_Amp'].ravel()[0])\n",
    "            m_dict['Pre_Stim_Prob'].append(sel_subj_mem_ev['Pre_Stim_Prob'].ravel()[0])\n",
    "            m_dict['Post_Stim_Prob'].append(sel_subj_mem_ev['Post_Stim_Prob'].ravel()[0])\n",
    "            m_dict['Stim_Anode_Idx'].append(np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == sel_subj_mem_ev['Stim_Anode'].ravel()[0])[0]+1)\n",
    "            m_dict['Stim_Cathode_Idx'].append(np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == sel_subj_mem_ev['Stim_Cathode'].ravel()[0])[0]+1)\n",
    "            \n",
    "        \n",
    "            for coh_id in coherence_id:\n",
    "                sel_subj_stim_ev_coh = sel_subj_stim_ev[sel_subj_stim_ev['Coherence_ID'] == coh_id]\n",
    "\n",
    "                str_key = 'Pre_NodeStr_{}'.format(coh_id)\n",
    "                if  str_key not in m_dict.keys():\n",
    "                    m_dict[str_key] = []\n",
    "                m_dict[str_key].append(list(sel_subj_stim_ev_coh['Pre_NodeStr'].ravel()[0]))\n",
    "\n",
    "                str_key = 'Post_NodeStr_{}'.format(coh_id)\n",
    "                if  str_key not in m_dict.keys():\n",
    "                    m_dict[str_key] = []\n",
    "                m_dict[str_key].append(list(sel_subj_stim_ev_coh['Post_NodeStr'].ravel()[0]))\n",
    "            \n",
    "    io.savemat('{}/Trajectory_Data.{}.mat'.format(path_ExpData, subj_id), mdict=m_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dict['Struct_Adj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "336px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "853px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "432px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "655px",
   "left": "1562.08px",
   "right": "20px",
   "top": "129px",
   "width": "340px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
