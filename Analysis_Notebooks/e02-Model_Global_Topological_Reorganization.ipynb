{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev1 toc-item\"><a href=\"#Gather-all-data-sets\" data-toc-modified-id=\"Gather-all-data-sets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Gather all data sets</a></div><div class=\"lev2 toc-item\"><a href=\"#Structural-data\" data-toc-modified-id=\"Structural-data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Structural data</a></div><div class=\"lev2 toc-item\"><a href=\"#Channel-data\" data-toc-modified-id=\"Channel-data-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Channel data</a></div><div class=\"lev2 toc-item\"><a href=\"#Baseline-data\" data-toc-modified-id=\"Baseline-data-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Baseline data</a></div><div class=\"lev2 toc-item\"><a href=\"#Stim-data\" data-toc-modified-id=\"Stim-data-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Stim data</a></div><div class=\"lev2 toc-item\"><a href=\"#Find-Overlapping-Subjects\" data-toc-modified-id=\"Find-Overlapping-Subjects-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Find Overlapping Subjects</a></div><div class=\"lev1 toc-item\"><a href=\"#Measure-Global-Topology\" data-toc-modified-id=\"Measure-Global-Topology-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Measure Global Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Baseline-Topology\" data-toc-modified-id=\"Baseline-Topology-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Baseline Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Stim-Topology\" data-toc-modified-id=\"Stim-Topology-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Stim Topology</a></div><div class=\"lev2 toc-item\"><a href=\"#Global-Alterations-in-Topology\" data-toc-modified-id=\"Global-Alterations-in-Topology-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Global Alterations in Topology</a></div><div class=\"lev3 toc-item\"><a href=\"#Mean-Connection-Strength\" data-toc-modified-id=\"Mean-Connection-Strength-331\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Mean Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#Variance-Connection-Strength\" data-toc-modified-id=\"Variance-Connection-Strength-332\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Variance Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#Topological-Similarity\" data-toc-modified-id=\"Topological-Similarity-333\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Topological Similarity</a></div><div class=\"lev3 toc-item\"><a href=\"#Which-nodes-are-altered-most?\" data-toc-modified-id=\"Which-nodes-are-altered-most?-334\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Which nodes are altered most?</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Input-Energy\" data-toc-modified-id=\"Effect-of-Input-Energy-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Effect of Input Energy</a></div><div class=\"lev3 toc-item\"><a href=\"#On-the-Mean-of-Evoked-Connectivity\" data-toc-modified-id=\"On-the-Mean-of-Evoked-Connectivity-341\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>On the Mean of Evoked Connectivity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-the-Variance-of-Evoked-Connectivity\" data-toc-modified-id=\"On-the-Variance-of-Evoked-Connectivity-342\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>On the Variance of Evoked Connectivity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-the-Topological-Similarity-of-Evoked-Connectivity\" data-toc-modified-id=\"On-the-Topological-Similarity-of-Evoked-Connectivity-343\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>On the Topological Similarity of Evoked Connectivity</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Stimulation-Location-(Functional-Hubness)\" data-toc-modified-id=\"Effect-of-Stimulation-Location-(Functional-Hubness)-35\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Effect of Stimulation Location (Functional Hubness)</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Mean-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Mean-Change-in-Connection-Strength-351\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>On Mean Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Variance-of-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Variance-of-Change-in-Connection-Strength-352\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>On Variance of Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#Effect-on-Strongest-of-Changes-in-Connection-Strength\" data-toc-modified-id=\"Effect-on-Strongest-of-Changes-in-Connection-Strength-353\"><span class=\"toc-item-num\">3.5.3&nbsp;&nbsp;</span>Effect on Strongest of Changes in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity-of-Evoked-Connectivity\" data-toc-modified-id=\"On-Topological-Similarity-of-Evoked-Connectivity-354\"><span class=\"toc-item-num\">3.5.4&nbsp;&nbsp;</span>On Topological Similarity of Evoked Connectivity</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-Stimulation-Location-(Functional-Region)\" data-toc-modified-id=\"Effect-of-Stimulation-Location-(Functional-Region)-36\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Effect of Stimulation Location (Functional Region)</a></div><div class=\"lev3 toc-item\"><a href=\"#Baseline-Node-Strength\" data-toc-modified-id=\"Baseline-Node-Strength-361\"><span class=\"toc-item-num\">3.6.1&nbsp;&nbsp;</span>Baseline Node Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Mean-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Mean-Change-in-Connection-Strength-362\"><span class=\"toc-item-num\">3.6.2&nbsp;&nbsp;</span>On Mean Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Variance-of-Change-in-Connection-Strength\" data-toc-modified-id=\"On-Variance-of-Change-in-Connection-Strength-363\"><span class=\"toc-item-num\">3.6.3&nbsp;&nbsp;</span>On Variance of Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity-of-Evoked-Connectivity\" data-toc-modified-id=\"On-Topological-Similarity-of-Evoked-Connectivity-364\"><span class=\"toc-item-num\">3.6.4&nbsp;&nbsp;</span>On Topological Similarity of Evoked Connectivity</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Reorganization-at-Individual-Locations\" data-toc-modified-id=\"On-Reorganization-at-Individual-Locations-365\"><span class=\"toc-item-num\">3.6.5&nbsp;&nbsp;</span>On Reorganization at Individual Locations</a></div><div class=\"lev2 toc-item\"><a href=\"#Stimulation-Location-(Structural-Control)\" data-toc-modified-id=\"Stimulation-Location-(Structural-Control)-37\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Stimulation Location (Structural Control)</a></div><div class=\"lev3 toc-item\"><a href=\"#Effect-on-Mean-Change-in-Connection-Strength\" data-toc-modified-id=\"Effect-on-Mean-Change-in-Connection-Strength-371\"><span class=\"toc-item-num\">3.7.1&nbsp;&nbsp;</span>Effect on Mean Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#Effect-on-Variance-Change-in-Connection-Strength\" data-toc-modified-id=\"Effect-on-Variance-Change-in-Connection-Strength-372\"><span class=\"toc-item-num\">3.7.2&nbsp;&nbsp;</span>Effect on Variance Change in Connection Strength</a></div><div class=\"lev3 toc-item\"><a href=\"#On-Topological-Similarity-of-Evoked-Connectivity\" data-toc-modified-id=\"On-Topological-Similarity-of-Evoked-Connectivity-373\"><span class=\"toc-item-num\">3.7.3&nbsp;&nbsp;</span>On Topological Similarity of Evoked Connectivity</a></div><div class=\"lev3 toc-item\"><a href=\"#Functional-Baseline-and-Structural-Control\" data-toc-modified-id=\"Functional-Baseline-and-Structural-Control-374\"><span class=\"toc-item-num\">3.7.4&nbsp;&nbsp;</span>Functional Baseline and Structural Control</a></div><div class=\"lev1 toc-item\"><a href=\"#Visualize-stim-locations\" data-toc-modified-id=\"Visualize-stim-locations-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Visualize stim locations</a></div><div class=\"lev1 toc-item\"><a href=\"#Functional-and-Structural-Controllability-and-Behavior\" data-toc-modified-id=\"Functional-and-Structural-Controllability-and-Behavior-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Functional and Structural Controllability and Behavior</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "rcParams.update(rcParams)\n",
    "\n",
    "path_AtlasData = '/Users/akhambhati/Remotes/CORE.MRI_Atlases'\n",
    "path_CoreData = '/Users/akhambhati/Remotes/CORE.RAM_Stim'\n",
    "path_PeriphData = '/Users/akhambhati/Remotes/RSRCH.RAM_Stim'\n",
    "path_InpData = path_PeriphData + '/e01-FuncNetw'\n",
    "path_InpData_Baseline = path_PeriphData + '/e01b-FuncNetw'\n",
    "path_ExpData = path_PeriphData + '/e02-GlobalTopo'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather all data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/structural_dict.pkl'.format(path_ExpData)):\n",
    "    struct_dict = pkl.load(open('{}/structural_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    stradj_subj = glob.glob('{}/Adjacency_Matrices/Epilepsy_Subjects/lausanne/*'.format(path_CoreData))\n",
    "    struct_subj = glob.glob('{}/Controllability/Parcel_ROI/Epilepsy_Subjects/lausanne/*'.format(path_CoreData))\n",
    "    struct_dict = {'Subject': {},\n",
    "                   'Atlas': {'scale33': {},\n",
    "                             'scale60': {},\n",
    "                             'scale125': {},\n",
    "                             'scale250': {}}}\n",
    "\n",
    "    for scale in struct_dict['Atlas'].keys():\n",
    "\n",
    "        # Populate controllabiliy\n",
    "        for sadj_path, full_path in zip(stradj_subj, struct_subj):\n",
    "            subj_id = full_path.split('/')[-1]\n",
    "            try:\n",
    "                struct_dict['Subject'][subj_id]\n",
    "            except:\n",
    "                struct_dict['Subject'][subj_id] = {}\n",
    "            struct_dict['Subject'][subj_id][scale] = {}        \n",
    "\n",
    "            adj_gfa_path = glob.glob('{}/*ROIv_{}*{}*.mat'.format(sadj_path, scale, 'gfa'))[0]\n",
    "            adj_gfa = io.loadmat(adj_gfa_path)['connectivity']\n",
    "            ctl_gfa_path = glob.glob('{}/*{}*{}*.mat'.format(full_path, scale, 'gfa'))[0]\n",
    "            avg_ctl_gfa = io.loadmat(ctl_gfa_path)['avg_vector'][:, 0]\n",
    "            mod_ctl_gfa = io.loadmat(ctl_gfa_path)['modal_vector'][:, 0]            \n",
    "\n",
    "            adj_qa_path = glob.glob('{}/*ROIv_{}*{}*.mat'.format(sadj_path, scale, 'qa'))[0]            \n",
    "            adj_qa = io.loadmat(adj_qa_path)['connectivity']            \n",
    "            ctl_qa_path = glob.glob('{}/*{}*{}*.mat'.format(full_path, scale, 'qa'))[0]\n",
    "            avg_ctl_qa = io.loadmat(ctl_qa_path)['avg_vector'][:, 0]\n",
    "            mod_ctl_qa = io.loadmat(ctl_qa_path)['modal_vector'][:, 0]  \n",
    "\n",
    "            # Populate the subject dict\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA'] = {}\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA']['adj'] = adj_gfa\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA']['avg_ctl'] = avg_ctl_gfa\n",
    "            struct_dict['Subject'][subj_id][scale]['GFA']['mod_ctl'] = mod_ctl_gfa        \n",
    "            struct_dict['Subject'][subj_id][scale]['QA'] = {}        \n",
    "            struct_dict['Subject'][subj_id][scale]['QA']['adj'] = adj_qa            \n",
    "            struct_dict['Subject'][subj_id][scale]['QA']['avg_ctl'] = avg_ctl_qa\n",
    "            struct_dict['Subject'][subj_id][scale]['QA']['mod_ctl'] = mod_ctl_qa        \n",
    "\n",
    "\n",
    "        # Populate MNI Coordinates for each ROI of each Lausanne Atlas\n",
    "        # Find voxel coordinates for each ROI\n",
    "        atlas_label = pd.read_csv('{}/Lausanne/{}.csv'.format(path_AtlasData, scale))    \n",
    "        atlas = nib.load('{}/Lausanne/lausanne/ROIv_{}_dilated.nii.gz'.format(path_AtlasData, scale))\n",
    "        atlas_data = atlas.get_data()\n",
    "        for roi_id in np.unique(atlas_data)[1:]:        \n",
    "            i,j,k = np.nonzero(atlas_data == roi_id)\n",
    "\n",
    "            roi_coords = []\n",
    "            for ii, jj, kk in zip(i, j, k):\n",
    "                xx, yy, zz = atlas.affine[:3, :3].dot([ii, jj, kk]) + atlas.affine[:3, 3]\n",
    "                roi_coords.append((xx, yy, zz))\n",
    "            roi_coords = np.array(roi_coords)\n",
    "\n",
    "            # Add to coords for ROI label to dict\n",
    "            sel_lbl = (atlas_label['Label_ID'] == roi_id)\n",
    "            roi_lbl = (atlas_label[sel_lbl]['Hemisphere'] + '_' + atlas_label[sel_lbl]['ROI']).as_matrix()[0]\n",
    "            struct_dict['Atlas'][scale][roi_lbl] = roi_coords\n",
    "\n",
    "    pkl.dump(struct_dict, open('{}/structural_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "print('There are {} processed structural datasets to analyze.'.format(len(struct_dict['Subject'].keys())))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/channel_dict.pkl'.format(path_ExpData)):\n",
    "    channel_dict = pkl.load(open('{}/channel_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    channel_subj = glob.glob('{}/Exp_Info/Channel_Info/*.mat'.format(path_CoreData))\n",
    "    channel_dict = {'Subject': {}}\n",
    "    \"\"\"\n",
    "    contains:  \n",
    "    - Jacksheet #: int\n",
    "    - Label: (good_channels x 1)\n",
    "    - Atlas_Label: {'scale': (good_channels x 1)}    \n",
    "    - MNI_Coord: (good_channels x 3)\n",
    "    - Dist_Matrix: spatial distances between electrodes\n",
    "    \"\"\"\n",
    "    \n",
    "    for full_path in channel_subj:\n",
    "        subj_id = full_path.split('/')[-1].split('.')[0]\n",
    "        try:\n",
    "            channel_dict['Subject'][subj_id]\n",
    "        except:\n",
    "            channel_dict['Subject'][subj_id] = {}        \n",
    "        \n",
    "        ### Get channel map for subject\n",
    "        chan_file = glob.glob('{}/Exp_Info/Channel_Info/{}.mat'.format(path_CoreData, subj_id))\n",
    "        if len(chan_file) != 1:\n",
    "            continue\n",
    "        df_chan = io.loadmat(chan_file[0])\n",
    "        if df_chan['good_channels_jack'].shape[1] != df_chan['good_channels_ind'].shape[1]:\n",
    "            continue\n",
    "        if df_chan['good_channels_jack'].shape[1] != df_chan['good_channels_lbl'].shape[1]:\n",
    "            continue\n",
    "            \n",
    "        ### Reformat channel labels\n",
    "        chan_lbl = np.array([lbl[0] for lbl in df_chan['good_channels_lbl'][0, :]])\n",
    "            \n",
    "        ### MNI Coords for good channels\n",
    "        mni_coords = []\n",
    "        for gc in df_chan['good_channels_jack'][0, :]:\n",
    "            gc_ix = np.flatnonzero(df_chan['xyzcoords'][:, 0] == gc)\n",
    "            if len(gc_ix) > 0:\n",
    "                mni_coords.append(tuple(df_chan['xyzcoords'][gc_ix[0], 1:]))\n",
    "            else:\n",
    "                mni_coords.append(tuple([np.nan, np.nan, np.nan]))\n",
    "                if gc_ix < len(df_chan['xyzcoords'][:, 0])-10:\n",
    "                    print(subj_id + ' -- middle bad channel')\n",
    "        mni_coords = np.array(mni_coords)\n",
    "        \n",
    "        ### Compute Inter-Electrode Distances\n",
    "        n_node = df_chan['good_channels_jack'].shape[1]\n",
    "        dist_matr = np.zeros((n_node, n_node))\n",
    "        triu_ix, triu_iy = np.triu_indices(n_node, k=1)\n",
    "        for ix, iy in zip(triu_ix, triu_iy):\n",
    "            ix_chan_loc = mni_coords[ix, :]\n",
    "            iy_chan_loc = mni_coords[iy, :]            \n",
    "            dist_matr[ix, iy] = np.sqrt(np.sum((ix_chan_loc-iy_chan_loc)**2))            \n",
    "        dist_matr += dist_matr.T\n",
    "        \n",
    "        ### Assign channel to an ROI using greedy approach\n",
    "        atlas_label = {}\n",
    "        for scale in struct_dict['Atlas'].keys():\n",
    "            roi_names = struct_dict['Atlas'][scale].keys()\n",
    "            chan_assign = []\n",
    "            for ch_crd in mni_coords:\n",
    "                roi_voxel_dist = []\n",
    "                for roi in roi_names:\n",
    "                    roi_crd = struct_dict['Atlas'][scale][roi]\n",
    "                    nearest_voxel = np.min(np.sqrt(np.sum((ch_crd - roi_crd)**2, axis=1)))\n",
    "                    roi_voxel_dist.append(nearest_voxel)\n",
    "                roi_ix = np.argmin(roi_voxel_dist)\n",
    "                chan_assign.append(roi_names[roi_ix])\n",
    "            atlas_label[scale] = np.array(chan_assign)\n",
    "\n",
    "        \n",
    "        ### Populate dict\n",
    "        channel_dict['Subject'][subj_id]['Jacksheet'] = df_chan['good_channels_jack'][0, :]\n",
    "        channel_dict['Subject'][subj_id]['Channel_Label'] = chan_lbl     \n",
    "        channel_dict['Subject'][subj_id]['Atlas_Label'] = atlas_label\n",
    "        channel_dict['Subject'][subj_id]['MNI_Coord'] = mni_coords\n",
    "        channel_dict['Subject'][subj_id]['Dist_Matr'] = dist_matr\n",
    "        \n",
    "    pkl.dump(channel_dict, open('{}/channel_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "print('There are {} processed channel datasets to analyze.'.format(len(channel_dict['Subject'].keys())))                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/base_dict.pkl'.format(path_ExpData)):\n",
    "    base_dict = pkl.load(open('{}/base_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    base_list = glob.glob('{}/Adjacency.*.npz'.format(path_InpData_Baseline))\n",
    "    all_subj_id = np.unique([pth.split('/')[-1].split('.')[1] for pth in base_list])\n",
    "\n",
    "    base_dict = {'Subject_ID': [],\n",
    "                 'Base_ID': [],\n",
    "                 'Adj_Path': []}\n",
    "\n",
    "\n",
    "    for subj_id in all_subj_id:\n",
    "        print(subj_id)\n",
    "\n",
    "        ### Iterate over all baseline events for the subject\n",
    "        for pth in glob.glob('{}/Adjacency.{}.*.npz'.format(path_InpData_Baseline, subj_id)):    \n",
    "            full_file = pth.split('/')[-1]    \n",
    "            subj_id = full_file.split('.')[1]\n",
    "            base_id = int(full_file.split('.')[2].split('_')[-1])\n",
    "\n",
    "            ### Populate the dictionary\n",
    "            base_dict['Subject_ID'].append(subj_id)\n",
    "            base_dict['Base_ID'].append(base_id)    \n",
    "            base_dict['Adj_Path'].append(pth)\n",
    "\n",
    "    pkl.dump(base_dict, open('{}/base_dict.pkl'.format(path_ExpData), 'w')) \n",
    "\n",
    "df_base = pd.DataFrame(base_dict, columns=base_dict.keys())    \n",
    "print('There are {} processed baseline events to analyze.'.format(len(base_dict['Subject_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/stim_trial_dict.pkl'.format(path_ExpData)):\n",
    "    trial_dict = pkl.load(open('{}/stim_trial_dict.pkl'.format(path_ExpData), 'r'))\n",
    "else:\n",
    "    trial_list = glob.glob('{}/Adjacency.*.npz'.format(path_InpData))\n",
    "    all_subj_id = np.unique([pth.split('/')[-1].split('.')[1] for pth in trial_list])\n",
    "\n",
    "    trial_dict = {'Subject_ID': [],\n",
    "                  'Experiment_ID': [],\n",
    "                  'Trial_ID': [],\n",
    "                  'Event_ID': [],\n",
    "                  'Stim_Freq': [],\n",
    "                  'Stim_Amp': [],\n",
    "                  'Stim_Anode': [],\n",
    "                  'Stim_Cathode': [],           \n",
    "                  'Adj_Path': []}\n",
    "\n",
    "    for subj_id in all_subj_id:\n",
    "        print(subj_id)\n",
    "\n",
    "        ### Get Trial LUT for Subject\n",
    "        trial_lut_file = glob.glob('{}/Exp_Info/LUT_Trial_Events/{}_trial_lut.mat'.format(path_CoreData, subj_id))\n",
    "        if len(trial_lut_file) != 1:\n",
    "            continue\n",
    "        df_lut = h5py.File(trial_lut_file[0], 'r')\n",
    "\n",
    "        ### Get event table for subject\n",
    "        event_file = glob.glob('{}/Exp_Info/PS_Events/{}_events.mat'.format(path_CoreData, subj_id))\n",
    "        if len(event_file) != 1:\n",
    "            continue\n",
    "        df_event = io.loadmat(event_file[0])\n",
    "\n",
    "        ### Iterate over all trials for the subject\n",
    "        for pth in glob.glob('{}/Adjacency.{}.*.npz'.format(path_InpData, subj_id)):    \n",
    "            full_file = pth.split('/')[-1]    \n",
    "            subj_id = full_file.split('.')[1]\n",
    "            trial_id = int(full_file.split('.')[2].split('_')[-1])\n",
    "\n",
    "            ### Convert the Trial ID to Event ID\n",
    "            event_id = df_lut['trial_lut'][1, :][df_lut['trial_lut'][0, :] == trial_id]\n",
    "            if len(event_id) != 1:\n",
    "                continue\n",
    "            event_id = int(event_id[0] - 1)\n",
    "\n",
    "            ### Get Trial Parameters\n",
    "            sel_event = df_event['events'][0, event_id]\n",
    "            stim_type = sel_event['type'][0].lower()\n",
    "            if not (stim_type =='stimulating'):\n",
    "                continue        \n",
    "\n",
    "            stim_exp = sel_event['experiment'][0]        \n",
    "            stim_amp = sel_event['amplitude'][0, 0]\n",
    "            stim_freq = sel_event['pulse_frequency'][0, 0]\n",
    "\n",
    "            stim_anode_jack = df_event['events'][0, event_id]['stimAnode'][0, 0]\n",
    "            stim_cathode_jack = df_event['events'][0, event_id]['stimCathode'][0, 0]\n",
    "\n",
    "            ### Populate the dictionary\n",
    "            trial_dict['Subject_ID'].append(subj_id)\n",
    "            trial_dict['Experiment_ID'].append(stim_exp)        \n",
    "            trial_dict['Trial_ID'].append(trial_id)    \n",
    "            trial_dict['Event_ID'].append(event_id)\n",
    "            trial_dict['Stim_Freq'].append(stim_freq)\n",
    "            trial_dict['Stim_Amp'].append(stim_amp)    \n",
    "            trial_dict['Stim_Anode'].append(stim_anode_jack)\n",
    "            trial_dict['Stim_Cathode'].append(stim_cathode_jack)\n",
    "            trial_dict['Adj_Path'].append(pth)\n",
    "        df_lut.close()\n",
    "    \n",
    "    pkl.dump(trial_dict, open('{}/stim_trial_dict.pkl'.format(path_ExpData), 'w'))  \n",
    "    \n",
    "df_trial = pd.DataFrame(trial_dict, columns=trial_dict.keys())    \n",
    "print('There are {} processed trials to analyze.'.format(len(trial_dict['Subject_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Overlapping Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overlap_subj_ids = np.intersect1d(np.intersect1d(np.intersect1d(struct_dict['Subject'].keys(),\n",
    "                                                                channel_dict['Subject'].keys()),\n",
    "                                                 np.unique(df_trial['Subject_ID'])),\n",
    "                                  np.unique(df_base['Subject_ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Global Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/baseline_topology.pkl'.format(path_ExpData)):\n",
    "    df_base_topo = pd.read_pickle('{}/baseline_topology.pkl'.format(path_ExpData))\n",
    "else:\n",
    "    data_table = {'Subject_ID': [],\n",
    "\n",
    "                  'Delta_Cor_AlphaTheta': [],\n",
    "                  'Delta_Cor_Beta': [],\n",
    "                  'Delta_Cor_LowGamma': [],\n",
    "                  'Delta_Cor_HighGamma': [],\n",
    "\n",
    "                  'ZNodeStr_AlphaTheta': [],\n",
    "                  'ZNodeStr_Beta': [],\n",
    "                  'ZNodeStr_LowGamma': [],\n",
    "                  'ZNodeStr_HighGamma': []}\n",
    "\n",
    "    for subj_id in np.unique(df_base['Subject_ID']):\n",
    "        sel_subj = df_base[df_base['Subject_ID'] == subj_id]\n",
    "\n",
    "        cfg_vec_alphatheta = []\n",
    "        cfg_vec_beta = []\n",
    "        cfg_vec_lowgamma = []\n",
    "        cfg_vec_highgamma = []       \n",
    "\n",
    "        ns_alphatheta = []\n",
    "        ns_beta = []\n",
    "        ns_lowgamma = []\n",
    "        ns_highgamma = []\n",
    "\n",
    "        for base_ix, base_data in sel_subj.iterrows():\n",
    "            # Load Adjacency\n",
    "            df_adj = np.load(base_data['Adj_Path'])\n",
    "            adj = df_adj['adj'].item()   \n",
    "            df_adj.close()\n",
    "\n",
    "            # Grab adjacency matrices\n",
    "            adj_alphatheta = adj['No_Stim']['AlphaTheta']\n",
    "            adj_beta = adj['No_Stim']['Beta']\n",
    "            adj_lowgamma = adj['No_Stim']['LowGamma']\n",
    "            adj_highgamma = adj['No_Stim']['HighGamma']  \n",
    "\n",
    "            # Compute node strength\n",
    "            ns_alphatheta.append(np.mean(adj_alphatheta, axis=0))\n",
    "            ns_beta.append(np.mean(adj_beta, axis=0))\n",
    "            ns_lowgamma.append(np.mean(adj_lowgamma, axis=0))\n",
    "            ns_highgamma.append(np.mean(adj_highgamma, axis=0))        \n",
    "\n",
    "            # Get configuration vector\n",
    "            cfg_alphatheta = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_alphatheta, axis=0)).reshape(-1)\n",
    "            cfg_beta = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_beta, axis=0)).reshape(-1)\n",
    "            cfg_lowgamma = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_lowgamma, axis=0)).reshape(-1)\n",
    "            cfg_highgamma = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_highgamma, axis=0)).reshape(-1)    \n",
    "\n",
    "            cfg_vec_alphatheta.append(cfg_alphatheta)\n",
    "            cfg_vec_beta.append(cfg_beta)\n",
    "            cfg_vec_lowgamma.append(cfg_lowgamma)\n",
    "            cfg_vec_highgamma.append(cfg_highgamma)      \n",
    "\n",
    "        # Average the node strengths across baseline events\n",
    "        ns_alphatheta = np.mean(np.array(ns_alphatheta), axis=0)\n",
    "        ns_beta = np.mean(np.array(ns_beta), axis=0)\n",
    "        ns_lowgamma = np.mean(np.array(ns_lowgamma), axis=0)\n",
    "        ns_highgamma = np.mean(np.array(ns_highgamma), axis=0)\n",
    "\n",
    "        # Compute Z-Scored node strengths\n",
    "        zns_alphatheta = (ns_alphatheta - np.nanmean(ns_alphatheta)) / np.nanstd(ns_alphatheta)   \n",
    "        zns_beta = (ns_beta - np.nanmean(ns_beta)) / np.nanstd(ns_beta)   \n",
    "        zns_lowgamma = (ns_lowgamma - np.nanmean(ns_lowgamma)) / np.nanstd(ns_lowgamma)   \n",
    "        zns_highgamma = (ns_highgamma - np.nanmean(ns_highgamma)) / np.nanstd(ns_highgamma)\n",
    "\n",
    "        # Compute correlations between configurations of different baseline time points\n",
    "        cfg_vec_alphatheta = np.array(cfg_vec_alphatheta)\n",
    "        cfg_vec_beta = np.array(cfg_vec_beta)\n",
    "        cfg_vec_lowgamma = np.array(cfg_vec_lowgamma)\n",
    "        cfg_vec_highgamma = np.array(cfg_vec_highgamma)             \n",
    "\n",
    "        delta_cor_alphatheta = convert_adj_matr_to_cfg_matr(np.expand_dims(np.corrcoef(cfg_vec_alphatheta), axis=0)).mean()\n",
    "        delta_cor_beta = convert_adj_matr_to_cfg_matr(np.expand_dims(np.corrcoef(cfg_vec_beta), axis=0)).mean()\n",
    "        delta_cor_lowgamma = convert_adj_matr_to_cfg_matr(np.expand_dims(np.corrcoef(cfg_vec_lowgamma), axis=0)).mean()\n",
    "        delta_cor_highgamma = convert_adj_matr_to_cfg_matr(np.expand_dims(np.corrcoef(cfg_vec_highgamma), axis=0)).mean()    \n",
    "\n",
    "        # Add to Data Table\n",
    "        data_table['Subject_ID'].append(subj_id)\n",
    "\n",
    "        data_table['Delta_Cor_AlphaTheta'].append(delta_cor_alphatheta)\n",
    "        data_table['Delta_Cor_Beta'].append(delta_cor_beta)\n",
    "        data_table['Delta_Cor_LowGamma'].append(delta_cor_lowgamma)\n",
    "        data_table['Delta_Cor_HighGamma'].append(delta_cor_highgamma)\n",
    "\n",
    "        data_table['ZNodeStr_AlphaTheta'].append(zns_alphatheta)\n",
    "        data_table['ZNodeStr_Beta'].append(zns_beta)\n",
    "        data_table['ZNodeStr_LowGamma'].append(zns_lowgamma)\n",
    "        data_table['ZNodeStr_HighGamma'].append(zns_highgamma)    \n",
    "\n",
    "    # Save Data Tables for R-stats\n",
    "    df_base_topo = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    df_base_topo.to_pickle('{}/baseline_topology.pkl'.format(path_ExpData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}/stim_topology.pkl'.format(path_ExpData)) :\n",
    "    df_stim_topo = pd.read_pickle('{}/stim_topology.pkl'.format(path_ExpData))\n",
    "else:\n",
    "    data_table = {'Subject_ID': [],\n",
    "                  'Trial_ID': [],\n",
    "                  'Stim_Freq': [],\n",
    "                  'Stim_Amp': [],\n",
    "                  'Stim_Anode': [],\n",
    "                  'Stim_Cathode': [],\n",
    "\n",
    "                  'Pre_MeanConnStr_AlphaTheta': [],\n",
    "                  'Pre_MeanConnStr_Beta': [],\n",
    "                  'Pre_MeanConnStr_LowGamma': [],\n",
    "                  'Pre_MeanConnStr_HighGamma': [],\n",
    "\n",
    "                  'Post_MeanConnStr_AlphaTheta': [],\n",
    "                  'Post_MeanConnStr_Beta': [],\n",
    "                  'Post_MeanConnStr_LowGamma': [],\n",
    "                  'Post_MeanConnStr_HighGamma': [],\n",
    "\n",
    "                  'Pre_VarConnStr_AlphaTheta': [],\n",
    "                  'Pre_VarConnStr_Beta': [],\n",
    "                  'Pre_VarConnStr_LowGamma': [],\n",
    "                  'Pre_VarConnStr_HighGamma': [],\n",
    "\n",
    "                  'Post_VarConnStr_AlphaTheta': [],\n",
    "                  'Post_VarConnStr_Beta': [],\n",
    "                  'Post_VarConnStr_LowGamma': [],\n",
    "                  'Post_VarConnStr_HighGamma': [],\n",
    "\n",
    "                  'Delta_MeanConnStr_AlphaTheta': [],\n",
    "                  'Delta_MeanConnStr_Beta': [],\n",
    "                  'Delta_MeanConnStr_LowGamma': [],\n",
    "                  'Delta_MeanConnStr_HighGamma': [],\n",
    "\n",
    "                  'Delta_VarConnStr_AlphaTheta': [],\n",
    "                  'Delta_VarConnStr_Beta': [],\n",
    "                  'Delta_VarConnStr_LowGamma': [],\n",
    "                  'Delta_VarConnStr_HighGamma': [],\n",
    "\n",
    "                  'Delta_Cor_AlphaTheta': [],\n",
    "                  'Delta_Cor_Beta': [],\n",
    "                  'Delta_Cor_LowGamma': [],                \n",
    "                  'Delta_Cor_HighGamma': [],\n",
    "\n",
    "                  'Pre_NodeStr_AlphaTheta': [],\n",
    "                  'Pre_NodeStr_Beta': [],\n",
    "                  'Pre_NodeStr_LowGamma': [],\n",
    "                  'Pre_NodeStr_HighGamma': [],\n",
    "\n",
    "                  'Post_NodeStr_AlphaTheta': [],\n",
    "                  'Post_NodeStr_Beta': [],\n",
    "                  'Post_NodeStr_LowGamma': [],\n",
    "                  'Post_NodeStr_HighGamma': [],\n",
    "    \n",
    "                  'Delta_NodeStr_AlphaTheta': [],\n",
    "                  'Delta_NodeStr_Beta': [],\n",
    "                  'Delta_NodeStr_LowGamma': [],\n",
    "                  'Delta_NodeStr_HighGamma': []}\n",
    "\n",
    "    for subj_id in np.unique(df_trial['Subject_ID']):\n",
    "        sel_subj = df_trial[df_trial['Subject_ID'] == subj_id]\n",
    "\n",
    "        for trial_ix, trial_data in sel_subj.iterrows():\n",
    "            if (trial_ix % 1000) == 0:\n",
    "                print(trial_ix)\n",
    "\n",
    "            # Load Adjacency\n",
    "            df_adj = np.load(trial_data['Adj_Path'])\n",
    "            adj = df_adj['adj'].item()   \n",
    "            df_adj.close()\n",
    "\n",
    "            # Grab adjacency matrices\n",
    "            adj_pre_alphatheta = adj['Pre_Stim']['AlphaTheta']\n",
    "            adj_pre_beta = adj['Pre_Stim']['Beta']\n",
    "            adj_pre_lowgamma = adj['Pre_Stim']['LowGamma']\n",
    "            adj_pre_highgamma = adj['Pre_Stim']['HighGamma']   \n",
    "\n",
    "            adj_post_alphatheta = adj['Post_Stim']['AlphaTheta']\n",
    "            adj_post_beta = adj['Post_Stim']['Beta']\n",
    "            adj_post_lowgamma = adj['Post_Stim']['LowGamma']\n",
    "            adj_post_highgamma = adj['Post_Stim']['HighGamma']\n",
    "            \n",
    "            adj_delta_alphatheta = (adj_post_alphatheta - adj_pre_alphatheta)\n",
    "            adj_delta_beta = (adj_post_beta - adj_pre_beta)\n",
    "            adj_delta_lowgamma = (adj_post_lowgamma - adj_pre_lowgamma)\n",
    "            adj_delta_highgamma = (adj_post_highgamma - adj_pre_highgamma)\n",
    "            \n",
    "            adj_delta_alphatheta[np.isnan(adj_delta_alphatheta)] = 0\n",
    "            adj_delta_beta[np.isnan(adj_delta_beta)] = 0\n",
    "            adj_delta_lowgamma[np.isnan(adj_delta_lowgamma)] = 0\n",
    "            adj_delta_highgamma[np.isnan(adj_delta_highgamma)] = 0\n",
    "\n",
    "            # Compute Pre/Post/Delta Configuration vectors\n",
    "            cfg_pre_alphatheta = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre_alphatheta, axis=0)).reshape(-1)\n",
    "            cfg_pre_beta = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre_beta, axis=0)).reshape(-1)\n",
    "            cfg_pre_lowgamma = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre_lowgamma, axis=0)).reshape(-1)\n",
    "            cfg_pre_highgamma = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_pre_highgamma, axis=0)).reshape(-1)    \n",
    "\n",
    "            cfg_post_alphatheta = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post_alphatheta, axis=0)).reshape(-1)\n",
    "            cfg_post_beta = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post_beta, axis=0)).reshape(-1)\n",
    "            cfg_post_lowgamma = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post_lowgamma, axis=0)).reshape(-1)\n",
    "            cfg_post_highgamma = convert_adj_matr_to_cfg_matr(np.expand_dims(adj_post_highgamma, axis=0)).reshape(-1)   \n",
    "\n",
    "            cfg_delta_alphatheta = (cfg_post_alphatheta - cfg_pre_alphatheta)\n",
    "            cfg_delta_beta = (cfg_post_beta - cfg_pre_beta)\n",
    "            cfg_delta_lowgamma = (cfg_post_lowgamma - cfg_pre_lowgamma)\n",
    "            cfg_delta_highgamma = (cfg_post_highgamma - cfg_pre_highgamma)\n",
    "\n",
    "            cfg_delta_alphatheta[np.isnan(cfg_delta_alphatheta)] = 0\n",
    "            cfg_delta_beta[np.isnan(cfg_delta_beta)] = 0\n",
    "            cfg_delta_lowgamma[np.isnan(cfg_delta_lowgamma)] = 0\n",
    "            cfg_delta_highgamma[np.isnan(cfg_delta_highgamma)] = 0            \n",
    "            \n",
    "            # Compute pre/post connection stats (mean / variance)\n",
    "            pre_mcs_alphatheta = np.mean(cfg_pre_alphatheta)\n",
    "            pre_mcs_beta = np.mean(cfg_pre_beta)\n",
    "            pre_mcs_lowgamma = np.mean(cfg_pre_lowgamma)\n",
    "            pre_mcs_highgamma = np.mean(cfg_pre_highgamma)\n",
    "\n",
    "            post_mcs_alphatheta = np.mean(cfg_post_alphatheta)\n",
    "            post_mcs_beta = np.mean(cfg_post_beta)\n",
    "            post_mcs_lowgamma = np.mean(cfg_post_lowgamma)\n",
    "            post_mcs_highgamma = np.mean(cfg_post_highgamma)\n",
    "\n",
    "            pre_vcs_alphatheta = np.var(cfg_pre_alphatheta)\n",
    "            pre_vcs_beta = np.var(cfg_pre_beta)\n",
    "            pre_vcs_lowgamma = np.var(cfg_pre_lowgamma)\n",
    "            pre_vcs_highgamma = np.var(cfg_pre_highgamma)\n",
    "\n",
    "            post_vcs_alphatheta = np.var(cfg_post_alphatheta)\n",
    "            post_vcs_beta = np.var(cfg_post_beta)\n",
    "            post_vcs_lowgamma = np.var(cfg_post_lowgamma)\n",
    "            post_vcs_highgamma = np.var(cfg_post_highgamma)\n",
    "\n",
    "            # Compare delta statistics (mean, variance, topological similarity)\n",
    "            delta_mcs_alphatheta = np.mean(cfg_delta_alphatheta)\n",
    "            delta_mcs_beta = np.mean(cfg_delta_beta)\n",
    "            delta_mcs_lowgamma = np.mean(cfg_delta_lowgamma)\n",
    "            delta_mcs_highgamma = np.mean(cfg_delta_highgamma)\n",
    "\n",
    "            delta_vcs_alphatheta = np.var(cfg_delta_alphatheta)\n",
    "            delta_vcs_beta = np.var(cfg_delta_beta)\n",
    "            delta_vcs_lowgamma = np.var(cfg_delta_lowgamma)\n",
    "            delta_vcs_highgamma = np.var(cfg_delta_highgamma)\n",
    "\n",
    "            delta_cor_alphatheta = stats.pearsonr(cfg_pre_alphatheta, cfg_post_alphatheta)[0]\n",
    "            delta_cor_beta = stats.pearsonr(cfg_pre_beta, cfg_post_beta)[0]\n",
    "            delta_cor_lowgamma = stats.pearsonr(cfg_pre_lowgamma, cfg_post_lowgamma)[0]\n",
    "            delta_cor_highgamma = stats.pearsonr(cfg_pre_highgamma, cfg_post_highgamma)[0]   \n",
    "\n",
    "            # Change in node strength (Post - Pre)\n",
    "            pre_ns_alphatheta = np.mean(adj_pre_alphatheta, axis=0)\n",
    "            pre_ns_beta = np.mean(adj_pre_beta, axis=0)\n",
    "            pre_ns_lowgamma = np.mean(adj_pre_lowgamma, axis=0)\n",
    "            pre_ns_highgamma = np.mean(adj_pre_highgamma, axis=0)  \n",
    "            \n",
    "            post_ns_alphatheta = np.mean(adj_post_alphatheta, axis=0)\n",
    "            post_ns_beta = np.mean(adj_post_beta, axis=0)\n",
    "            post_ns_lowgamma = np.mean(adj_post_lowgamma, axis=0)\n",
    "            post_ns_highgamma = np.mean(adj_post_highgamma, axis=0)        \n",
    "            \n",
    "            delta_ns_alphatheta = np.mean(adj_delta_alphatheta, axis=0)\n",
    "            delta_ns_beta = np.mean(adj_delta_beta, axis=0)\n",
    "            delta_ns_lowgamma = np.mean(adj_delta_lowgamma, axis=0)\n",
    "            delta_ns_highgamma = np.mean(adj_delta_highgamma, axis=0)        \n",
    "\n",
    "            # Add to Data Table 1\n",
    "            data_table['Subject_ID'].append(trial_data['Subject_ID'])\n",
    "            data_table['Trial_ID'].append(trial_data['Trial_ID'])    \n",
    "            data_table['Stim_Freq'].append(trial_data['Stim_Freq'])\n",
    "            data_table['Stim_Amp'].append(trial_data['Stim_Amp'])\n",
    "            data_table['Stim_Anode'].append(trial_data['Stim_Anode'])\n",
    "            data_table['Stim_Cathode'].append(trial_data['Stim_Cathode'])\n",
    "\n",
    "            data_table['Pre_MeanConnStr_AlphaTheta'].append(pre_mcs_alphatheta)\n",
    "            data_table['Pre_MeanConnStr_Beta'].append(pre_mcs_beta)\n",
    "            data_table['Pre_MeanConnStr_LowGamma'].append(pre_mcs_lowgamma)\n",
    "            data_table['Pre_MeanConnStr_HighGamma'].append(pre_mcs_highgamma)\n",
    "\n",
    "            data_table['Post_MeanConnStr_AlphaTheta'].append(post_mcs_alphatheta)\n",
    "            data_table['Post_MeanConnStr_Beta'].append(post_mcs_beta)\n",
    "            data_table['Post_MeanConnStr_LowGamma'].append(post_mcs_lowgamma)\n",
    "            data_table['Post_MeanConnStr_HighGamma'].append(post_mcs_highgamma)\n",
    "\n",
    "            data_table['Pre_VarConnStr_AlphaTheta'].append(pre_vcs_alphatheta)\n",
    "            data_table['Pre_VarConnStr_Beta'].append(pre_vcs_beta)\n",
    "            data_table['Pre_VarConnStr_LowGamma'].append(pre_vcs_lowgamma)\n",
    "            data_table['Pre_VarConnStr_HighGamma'].append(pre_vcs_highgamma)\n",
    "\n",
    "            data_table['Post_VarConnStr_AlphaTheta'].append(post_vcs_alphatheta)\n",
    "            data_table['Post_VarConnStr_Beta'].append(post_vcs_beta)\n",
    "            data_table['Post_VarConnStr_LowGamma'].append(post_vcs_lowgamma)\n",
    "            data_table['Post_VarConnStr_HighGamma'].append(post_vcs_highgamma)\n",
    "\n",
    "            data_table['Delta_MeanConnStr_AlphaTheta'].append(delta_mcs_alphatheta)\n",
    "            data_table['Delta_MeanConnStr_Beta'].append(delta_mcs_beta)\n",
    "            data_table['Delta_MeanConnStr_LowGamma'].append(delta_mcs_lowgamma)\n",
    "            data_table['Delta_MeanConnStr_HighGamma'].append(delta_mcs_highgamma)\n",
    "\n",
    "            data_table['Delta_VarConnStr_AlphaTheta'].append(delta_vcs_alphatheta)\n",
    "            data_table['Delta_VarConnStr_Beta'].append(delta_vcs_beta)\n",
    "            data_table['Delta_VarConnStr_LowGamma'].append(delta_vcs_lowgamma)\n",
    "            data_table['Delta_VarConnStr_HighGamma'].append(delta_vcs_highgamma)\n",
    "\n",
    "            data_table['Delta_Cor_AlphaTheta'].append(delta_cor_alphatheta)\n",
    "            data_table['Delta_Cor_Beta'].append(delta_cor_beta)\n",
    "            data_table['Delta_Cor_LowGamma'].append(delta_cor_lowgamma)\n",
    "            data_table['Delta_Cor_HighGamma'].append(delta_cor_highgamma)        \n",
    "\n",
    "            data_table['Pre_NodeStr_AlphaTheta'].append(pre_ns_alphatheta)\n",
    "            data_table['Pre_NodeStr_Beta'].append(pre_ns_beta)\n",
    "            data_table['Pre_NodeStr_LowGamma'].append(pre_ns_lowgamma)\n",
    "            data_table['Pre_NodeStr_HighGamma'].append(pre_ns_highgamma)        \n",
    "\n",
    "            data_table['Post_NodeStr_AlphaTheta'].append(post_ns_alphatheta)\n",
    "            data_table['Post_NodeStr_Beta'].append(post_ns_beta)\n",
    "            data_table['Post_NodeStr_LowGamma'].append(post_ns_lowgamma)\n",
    "            data_table['Post_NodeStr_HighGamma'].append(post_ns_highgamma)        \n",
    "            \n",
    "            data_table['Delta_NodeStr_AlphaTheta'].append(delta_ns_alphatheta)\n",
    "            data_table['Delta_NodeStr_Beta'].append(delta_ns_beta)\n",
    "            data_table['Delta_NodeStr_LowGamma'].append(delta_ns_lowgamma)\n",
    "            data_table['Delta_NodeStr_HighGamma'].append(delta_ns_highgamma)        \n",
    "        \n",
    "    # Save Data Tables for R-stats\n",
    "    df_stim_topo = pd.DataFrame(data_table, columns=data_table.keys())\n",
    "    df_stim_topo.to_pickle('{}/stim_topology.pkl'.format(path_ExpData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Alterations in Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Connection Strength\n",
    "The average node strength before stimulation predicts the average node strength after. There is a \"conservation of connectivity\" for Alpha/Theta, Beta, Low Gamma and High Gamma coherence networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Pre_MeanConnStr_AlphaTheta', 'Post_MeanConnStr_AlphaTheta'),\n",
    "             ('Pre_MeanConnStr_Beta', 'Post_MeanConnStr_Beta'),\n",
    "             ('Pre_MeanConnStr_LowGamma', 'Post_MeanConnStr_LowGamma'),\n",
    "             ('Pre_MeanConnStr_HighGamma', 'Post_MeanConnStr_HighGamma')]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    \n",
    "    subj_pre_trial = []\n",
    "    subj_post_trial = []\n",
    "    for subj_id in np.unique(df_stim_topo['Subject_ID']):\n",
    "        sel_subj = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "    \n",
    "        # Get Trial Data\n",
    "        pre_trial = sel_subj[afreq[0]]\n",
    "        post_trial = sel_subj[afreq[1]]\n",
    "        \n",
    "        # Add to subject level data\n",
    "        subj_pre_trial.append(pre_trial.mean())\n",
    "        subj_post_trial.append(post_trial.mean())        \n",
    "        \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_pre_trial, subj_post_trial)\n",
    "    ax.plot([0.0, 1.0], slope*np.array([0.0, 1.0])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(subj_pre_trial, subj_post_trial, s=1.0,\n",
    "               color='r', lw=0)\n",
    "    ax.text(0.5, 0.75, ' slope=%0.3f\\n rho=%0.3f\\n pv=%0.3f' % (slope, rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Post-Stim\\nMean Conn Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Pre-Stim\\nMean Conn Strength')      \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[2])\n",
    "\n",
    "plt.savefig('./e02-Figures/Pre_MeanConnStrength-Post_MeanConnStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Connection Strength\n",
    "The average node strength before stimulation predicts the average node strength after. There is a \"conservation of connectivity\" for Alpha/Theta, Beta, Low Gamma and High Gamma coherence networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Pre_VarConnStr_AlphaTheta', 'Post_VarConnStr_AlphaTheta'),\n",
    "             ('Pre_VarConnStr_Beta', 'Post_VarConnStr_Beta'),\n",
    "             ('Pre_VarConnStr_LowGamma', 'Post_VarConnStr_LowGamma'),\n",
    "             ('Pre_VarConnStr_HighGamma', 'Post_VarConnStr_HighGamma')]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    \n",
    "    subj_pre_trial = []\n",
    "    subj_post_trial = []\n",
    "    for subj_id in np.unique(df_stim_topo['Subject_ID']):\n",
    "        sel_subj = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "    \n",
    "        # Get Trial Data\n",
    "        pre_trial = sel_subj[afreq[0]]\n",
    "        post_trial = sel_subj[afreq[1]]\n",
    "        \n",
    "        # Add to subject level data\n",
    "        subj_pre_trial.append(pre_trial.mean())\n",
    "        subj_post_trial.append(post_trial.mean())        \n",
    "        \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_pre_trial, subj_post_trial)\n",
    "    ax.plot([0.0, 1.0], slope*np.array([0.0, 1.0])+yint, 'k', alpha=0.5)    \n",
    "    ax.scatter(subj_pre_trial, subj_post_trial, s=1.0,\n",
    "               color='r', lw=0)\n",
    "    ax.text(0.05, 0.075, ' slope=%0.3f\\n rho=%0.3f\\n pv=%0.3f' % (slope, rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([0, 0.1])\n",
    "    ax.set_ylim([0, 0.1])\n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Post-Stim\\nVariance Conn Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Pre-Stim\\nVariance Conn Strength')      \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[2])\n",
    "\n",
    "plt.savefig('./e02-Figures/Pre_VarConnStrength-Post_VarConnStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topological Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['Delta_Cor_AlphaTheta',\n",
    "             'Delta_Cor_Beta',\n",
    "             'Delta_Cor_LowGamma',\n",
    "             'Delta_Cor_HighGamma']\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "ax = plt.subplot(111)\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    \n",
    "    subj_base_cor = []\n",
    "    subj_stim_cor = []\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID'],):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        # Get Data\n",
    "        base_cor = 1-np.abs(sel_subj_base[afreq])\n",
    "        stim_cor = 1-np.abs(sel_subj_stim[afreq])\n",
    "        \n",
    "        # Add to subject level data\n",
    "        subj_base_cor.append(base_cor.mean())\n",
    "        subj_stim_cor.append(stim_cor.mean())        \n",
    "\n",
    "    bp1 = ax.boxplot([subj_stim_cor], positions=[ii], patch_artist=True)\n",
    "    Echobase.Plotting.fig_format.set_box_color(bp1, 'k', [[0.00, 0.37, 1.00]])\n",
    "    \n",
    "    bp2 = ax.boxplot([subj_base_cor], positions=[ii+0.2], patch_artist=True)\n",
    "    Echobase.Plotting.fig_format.set_box_color(bp2, 'k', [[0.25, 0.25, 0.25]])\n",
    "    \n",
    "    print(stats.ttest_rel(subj_base_cor, subj_stim_cor))\n",
    "\n",
    "ax.set_xlim([-0.5, 4])\n",
    "ax.set_xticks(np.arange(len(adj_freqs))+0.1)\n",
    "ax.set_xticklabels([afreq.split('_')[-1] for afreq in adj_freqs])\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_ylabel('Reorganization of Network Topology')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.savefig('./e02-Figures/Topological_Similarity-Pre_Post.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which nodes are altered most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Pre_NodeStr_AlphaTheta', 'Delta_NodeStr_AlphaTheta'),\n",
    "             ('Pre_NodeStr_Beta', 'Delta_NodeStr_Beta'),\n",
    "             ('Pre_NodeStr_LowGamma', 'Delta_NodeStr_LowGamma'),\n",
    "             ('Pre_NodeStr_HighGamma', 'Delta_NodeStr_HighGamma')]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    \n",
    "    subj_pre_trial = []\n",
    "    subj_delta_trial = []\n",
    "    for subj_id in np.unique(df_stim_topo['Subject_ID']):\n",
    "        sel_subj = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "    \n",
    "        # Get Trial Data\n",
    "        pre_trial = sel_subj[afreq[0]]\n",
    "        delta_trial = sel_subj[afreq[1]]\n",
    "        \n",
    "        for pre_t, delta_t in zip(pre_trial, delta_trial):\n",
    "            z_pre_t = (pre_t - pre_t.mean()) / pre_t.std()\n",
    "            for pre_ns, delta_ns in zip(z_pre_t, delta_t):\n",
    "                subj_pre_trial.append(pre_ns)\n",
    "                subj_delta_trial.append(delta_ns) \n",
    "    subj_pre_trial = np.array(subj_pre_trial)            \n",
    "    subj_delta_trial = np.array(subj_delta_trial)                \n",
    "    \n",
    "    # Plot Regression\n",
    "    ax = plt.subplot(2, 2, ii+1)    \n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_pre_trial, subj_delta_trial)\n",
    "    ax.plot([-3.0, 3.0], slope*np.array([-3.0, 3.0])+yint, 'k', alpha=0.5)    \n",
    "    rnd_ix = np.random.permutation(len(subj_pre_trial))[:10000]\n",
    "    ax.scatter(subj_pre_trial[rnd_ix], subj_delta_trial[rnd_ix], s=1.0,\n",
    "               color='r', alpha=0.5, lw=0)\n",
    "    ax.text(-2.9, -0.9, ' slope=%0.3f\\n rho=%0.3f\\n pv=%0.3f' % (slope, rho, pv), fontsize=3.0)\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([-1, 1])\n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Delta Node Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Pre-Stim Node Strength\\n(Z-score)')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[2])\n",
    "\n",
    "plt.savefig('./e02-Figures/Pre_NodeStrength-Post_NodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Input Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the Mean of Evoked Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['Delta_MeanConnStr_AlphaTheta',\n",
    "             'Delta_MeanConnStr_Beta',\n",
    "             'Delta_MeanConnStr_LowGamma',\n",
    "             'Delta_MeanConnStr_HighGamma']\n",
    "\n",
    "stim_freqs = np.unique(df_stim_topo['Stim_Freq'])\n",
    "stim_amps = np.unique(df_stim_topo['Stim_Amp'])\n",
    "n_freq = len(stim_freqs)\n",
    "n_amp = len(stim_amps)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):        \n",
    "\n",
    "    ### For the ANOVA\n",
    "    pop_stim_freq = {}\n",
    "    for sfreq in stim_freqs:\n",
    "        pop_stim_freq[sfreq] = df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq][afreq].as_matrix()\n",
    "    print(afreq.split('_')[-1], 'Stim Freq: ', stats.f_oneway(*pop_stim_freq.values()))\n",
    "        \n",
    "    pop_stim_amp = {}\n",
    "    for samp in stim_amps:\n",
    "        pop_stim_amp[samp] = df_stim_topo[df_stim_topo['Stim_Amp'] == samp][afreq].as_matrix()  \n",
    "    print(afreq.split('_')[-1], 'Stim Amp: ', stats.f_oneway(*pop_stim_amp.values()))\n",
    "    print\n",
    "    \n",
    "    ### For the heatmap\n",
    "    mean_evoke_map = np.nan*np.zeros((n_freq, n_amp))\n",
    "    err_evoke_map = np.nan*np.zeros((n_freq, n_amp))    \n",
    "    for sfreq_i, sfreq in enumerate(stim_freqs):\n",
    "        for samp_i, samp in enumerate(stim_amps):\n",
    "            \n",
    "            sel_freq = df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq]\n",
    "            sel_amp = sel_freq[sel_freq['Stim_Amp'] == samp]\n",
    "            \n",
    "            mean_evoke_map[sfreq_i, samp_i] = np.mean(sel_amp[afreq])\n",
    "            err_evoke_map[sfreq_i, samp_i] = np.std(sel_amp[afreq]) / np.sqrt(sel_amp[afreq].count())\n",
    "            \n",
    "    # Plot input energy landscape\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    mat = ax.matshow(mean_evoke_map, aspect=n_amp/float(n_freq), cmap='viridis')\n",
    "    plt.colorbar(mat, ax=ax)\n",
    "    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Stim Frequency (Hz)')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Amplitude (mA)')\n",
    "\n",
    "    ax.set_yticks(np.arange(0, n_freq))\n",
    "    ax.set_yticklabels(stim_freqs)\n",
    "    \n",
    "    ax.set_xticks(np.arange(0, n_amp, 3))\n",
    "    ax.set_xticklabels(stim_amps[::3])\n",
    "    \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq.split('_')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the Variance of Evoked Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['Delta_VarConnStr_AlphaTheta',\n",
    "             'Delta_VarConnStr_Beta',\n",
    "             'Delta_VarConnStr_LowGamma',\n",
    "             'Delta_VarConnStr_HighGamma']\n",
    "\n",
    "stim_freqs = np.unique(df_stim_topo['Stim_Freq'])\n",
    "stim_amps = np.unique(df_stim_topo['Stim_Amp'])\n",
    "n_freq = len(stim_freqs)\n",
    "n_amp = len(stim_amps)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):        \n",
    "\n",
    "    ### For the ANOVA\n",
    "    pop_stim_freq = {}\n",
    "    for sfreq in stim_freqs:\n",
    "        pop_stim_freq[sfreq] = df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq][afreq].as_matrix()\n",
    "    print(afreq.split('_')[-1], 'Stim Freq: ', stats.f_oneway(*pop_stim_freq.values()))\n",
    "        \n",
    "    pop_stim_amp = {}\n",
    "    for samp in stim_amps:\n",
    "        pop_stim_amp[samp] = df_stim_topo[df_stim_topo['Stim_Amp'] == samp][afreq].as_matrix()\n",
    "    print(afreq.split('_')[-1], 'Stim Amp: ', stats.f_oneway(*pop_stim_amp.values()))\n",
    "    print\n",
    "    \n",
    "    ### For the heatmap\n",
    "    mean_evoke_map = np.nan*np.zeros((n_freq, n_amp))\n",
    "    err_evoke_map = np.nan*np.zeros((n_freq, n_amp))    \n",
    "    for sfreq_i, sfreq in enumerate(stim_freqs):\n",
    "        for samp_i, samp in enumerate(stim_amps):\n",
    "            \n",
    "            sel_freq = df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq]\n",
    "            sel_amp = sel_freq[sel_freq['Stim_Amp'] == samp]\n",
    "            \n",
    "            mean_evoke_map[sfreq_i, samp_i] = np.mean(sel_amp[afreq])\n",
    "            err_evoke_map[sfreq_i, samp_i] = np.std(sel_amp[afreq]) / np.sqrt(sel_amp[afreq].count())\n",
    "            \n",
    "    # Plot input energy landscape\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    mat = ax.matshow(mean_evoke_map, aspect=n_amp/float(n_freq), cmap='viridis')\n",
    "    plt.colorbar(mat, ax=ax)\n",
    "    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Stim Frequency (Hz)')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Amplitude (mA)')\n",
    "\n",
    "    ax.set_yticks(np.arange(0, n_freq))\n",
    "    ax.set_yticklabels(stim_freqs)\n",
    "    \n",
    "    ax.set_xticks(np.arange(0, n_amp, 3))\n",
    "    ax.set_xticklabels(stim_amps[::3])\n",
    "    \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq.split('_')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the Topological Similarity of Evoked Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['Delta_Cor_AlphaTheta',\n",
    "             'Delta_Cor_Beta',\n",
    "             'Delta_Cor_LowGamma',\n",
    "             'Delta_Cor_HighGamma']\n",
    "\n",
    "stim_freqs = np.unique(df_stim_topo['Stim_Freq'])\n",
    "stim_amps = np.unique(df_stim_topo['Stim_Amp'])\n",
    "n_freq = len(stim_freqs)\n",
    "n_amp = len(stim_amps)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):        \n",
    "\n",
    "    ### For the ANOVA\n",
    "    pop_stim_freq = {}\n",
    "    for sfreq in stim_freqs:\n",
    "        pop_stim_freq[sfreq] = 1-np.abs(df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq][afreq].as_matrix())\n",
    "    print(afreq.split('_')[-1], 'Stim Freq: ', stats.f_oneway(*pop_stim_freq.values()))\n",
    "        \n",
    "    pop_stim_amp = {}\n",
    "    for samp in stim_amps:\n",
    "        pop_stim_amp[samp] = 1-np.abs(df_stim_topo[df_stim_topo['Stim_Amp'] == samp][afreq].as_matrix())\n",
    "    print(afreq.split('_')[-1], 'Stim Amp: ', stats.f_oneway(*pop_stim_amp.values()))\n",
    "    print\n",
    "    \n",
    "    ### For the heatmap\n",
    "    mean_evoke_map = np.nan*np.zeros((n_freq, n_amp))\n",
    "    err_evoke_map = np.nan*np.zeros((n_freq, n_amp))    \n",
    "    for sfreq_i, sfreq in enumerate(stim_freqs):\n",
    "        for samp_i, samp in enumerate(stim_amps):\n",
    "            \n",
    "            sel_freq = df_stim_topo[df_stim_topo['Stim_Freq'] == sfreq]\n",
    "            sel_amp = sel_freq[sel_freq['Stim_Amp'] == samp]\n",
    "            \n",
    "            mean_evoke_map[sfreq_i, samp_i] = np.mean(1-np.abs(sel_amp[afreq]))\n",
    "            err_evoke_map[sfreq_i, samp_i] = np.std(1-np.abs(sel_amp[afreq])) / np.sqrt(sel_amp[afreq].count())\n",
    "            \n",
    "    # Plot input energy landscape\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    mat = ax.matshow(mean_evoke_map, aspect=n_amp/float(n_freq), cmap='viridis')\n",
    "    plt.colorbar(mat, ax=ax)\n",
    "    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Stim Frequency (Hz)')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Amplitude (mA)')\n",
    "\n",
    "    ax.set_yticks(np.arange(0, n_freq))\n",
    "    ax.set_yticklabels(stim_freqs)\n",
    "    \n",
    "    ax.set_xticks(np.arange(0, n_amp, 3))\n",
    "    ax.set_xticklabels(stim_amps[::3])\n",
    "    \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq.split('_')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Stimulation Location (Functional Hubness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Mean Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_MeanConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_MeanConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_MeanConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_MeanConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_stim_mcs = []\n",
    "    subj_base_zns = []    \n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_zns = sel_subj_base[afreq[1]].mean()\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            base_zns_stim = 0.5*(base_zns[a_ix] + base_zns[c_ix])\n",
    "            subj_base_zns.append(base_zns_stim)            \n",
    "            \n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            subj_stim_mcs.append(sel_stim[afreq[0]].mean())\n",
    "            \n",
    "    subj_base_zns = np.array(subj_base_zns)\n",
    "    subj_stim_mcs = np.array(subj_stim_mcs)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_base_zns, subj_stim_mcs)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_base_zns, subj_stim_mcs, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_base_zns, subj_stim_mcs)\n",
    "    print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(1.0, 0.06, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([-0.08, 0.08])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Mean Evoked\\nConnection Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Variance of Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_VarConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_VarConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_VarConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_VarConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_stim_mcs = []\n",
    "    subj_base_zns = []    \n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_zns = sel_subj_base[afreq[1]].mean()\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            base_zns_stim = 0.5*(base_zns[a_ix] + base_zns[c_ix])\n",
    "            subj_base_zns.append(base_zns_stim)            \n",
    "            \n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            subj_stim_mcs.append(sel_stim[afreq[0]].mean())\n",
    "            \n",
    "    subj_base_zns = np.array(subj_base_zns)\n",
    "    subj_stim_mcs = np.array(subj_stim_mcs)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_base_zns, subj_stim_mcs)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_base_zns, subj_stim_mcs, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_base_zns, subj_stim_mcs)\n",
    "    print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(-3.0, 0.12, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([0.0, 0.15])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Variance Evoked\\nConnection Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect on Strongest of Changes in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_NodeStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_NodeStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_NodeStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_NodeStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    for func, clr, coord in zip([lambda y: np.percentile(y, 97.5),\n",
    "                                 lambda y: np.percentile(y, 2.5)],\n",
    "                                ('r', 'b'), ((-3.75, 0.25), (2.0, -0.35))):\n",
    "        subj_base_zns = []\n",
    "        subj_delta_ns = []    \n",
    "        for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                      df_stim_topo['Subject_ID']):\n",
    "            sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]                    \n",
    "            sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]  \n",
    "            \n",
    "            base_zns = sel_subj_base[afreq[1]].mean()            \n",
    "\n",
    "            # Get stim anode/cathode pairs\n",
    "            stim_ix = []\n",
    "            for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                                sel_subj_stim['Stim_Cathode']):\n",
    "                anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "                cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "                stim_ix.append((anode_ix, cathode_ix))\n",
    "            stim_ix = list(set(stim_ix))\n",
    "\n",
    "            # Iterate over all stim pairs\n",
    "            for a_ix, c_ix in stim_ix:\n",
    "                base_zns_stim = 0.5*(base_zns[a_ix] + base_zns[c_ix])\n",
    "                subj_base_zns.append(base_zns_stim)            \n",
    "\n",
    "                a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "                c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "                sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "                sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "                arr = []\n",
    "                for trial in sel_stim[afreq[0]]:\n",
    "                    arr.append(func(trial))\n",
    "                subj_delta_ns.append(np.mean(arr))\n",
    "\n",
    "        subj_base_zns = np.array(subj_base_zns)\n",
    "        subj_delta_ns = np.array(subj_delta_ns)\n",
    "\n",
    "        # Regression\n",
    "        slope, yint, rho, pv, stderr = stats.linregress(subj_base_zns, subj_delta_ns)\n",
    "        ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color=clr, alpha=0.5, lw=1.0)    \n",
    "        ax.scatter(subj_base_zns, subj_delta_ns, s=1.0,\n",
    "                   color=clr, lw=0)\n",
    "\n",
    "        rho, pv = stats.spearmanr(subj_base_zns, subj_delta_ns)\n",
    "        print('%s:  -- Pearsonr: (rho=%0.4f, pv=%0.4f)' % (afreq[0], rho, pv))            \n",
    "        #ax.text(coord[0], coord[1], 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color=clr)\n",
    "    \n",
    "\n",
    "    ax.set_xlim([-4, 4])\n",
    "    #ax.set_ylim([-0.4, 0.4])\n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Evoked Node Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity of Evoked Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_Cor_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_Cor_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_Cor_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_Cor_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_stim_mcs = []\n",
    "    subj_base_zns = []    \n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_zns = sel_subj_base[afreq[1]].mean()\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            base_zns_stim = 0.5*(base_zns[a_ix] + base_zns[c_ix])\n",
    "            subj_base_zns.append(base_zns_stim)            \n",
    "            \n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            #subj_stim_mcs.append(sel_stim[afreq[0]].mean())\n",
    "            \n",
    "            arr = []\n",
    "            for trial in sel_stim[afreq[0]]:\n",
    "                arr.append(1-np.abs(trial))\n",
    "            subj_stim_mcs.append(np.mean(arr))    \n",
    "            \n",
    "    subj_base_zns = np.array(subj_base_zns)\n",
    "    subj_stim_mcs = np.array(subj_stim_mcs)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_base_zns, subj_stim_mcs)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_base_zns, subj_stim_mcs, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_base_zns, subj_stim_mcs)\n",
    "    print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(1.0, 0.25, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([0.0, 1.0])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Evoked Reorg. of\\nNetwork Topology')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Stim Node Strength')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Stimulation Location (Functional Region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Node Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['ZNodeStr_AlphaTheta',\n",
    "             'ZNodeStr_Beta',\n",
    "             'ZNodeStr_LowGamma',\n",
    "             'ZNodeStr_HighGamma']\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "\n",
    "        base_zns = sel_subj_base[afreq].mean()\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(base_zns[a_ix])\n",
    "            \n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            c_loc = c_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(base_zns[c_ix])\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    #ax.set_xlim([-0.5, len(lbl)-0.5])\n",
    "    ax.set_ylim([-1.25, 1.25])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Baseline\\nFunctional Connectivity of\\nStimulated Electrode')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq.split('_')[-1], Fv, Pv))\n",
    "    \n",
    "    \n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Mean Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_MeanConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_MeanConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_MeanConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_MeanConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "            \n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            c_loc = c_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    ax.set_ylim([-0.004, 0.015])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Mean of Evoked\\nConnection Strength')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq[0].split('_')[-1], Fv, Pv))\n",
    "    \n",
    "    \n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Variance of Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_VarConnStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_VarConnStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_VarConnStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_VarConnStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "            \n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            c_loc = c_loc.split('_')[1]                \n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(np.mean(sel_stim[afreq[0]]))\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    ax.set_ylim([0.015, 0.05])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Variance of Evoked\\nConnection Strength')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq[0].split('_')[-1], Fv, Pv))\n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity of Evoked Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_Cor_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_Cor_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_Cor_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_Cor_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale250'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    subj_stim_loc = {}\n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "\n",
    "            arr = []\n",
    "            for trial in sel_stim[afreq[0]]:\n",
    "                arr.append(1-np.abs(trial))            \n",
    "            \n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            #if len(a_loc.split('_')) == 3:\n",
    "            #    a_loc = '_'.join(a_loc.split('_')[0:2])\n",
    "            a_loc = a_loc.split('_')[1]\n",
    "            try:\n",
    "                subj_stim_loc[a_loc]\n",
    "            except:\n",
    "                subj_stim_loc[a_loc] = []\n",
    "            subj_stim_loc[a_loc].append(np.mean(arr))\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            #if len(c_loc.split('_')) == 3:\n",
    "            #    c_loc = '_'.join(c_loc.split('_')[0:2])     \n",
    "            c_loc = c_loc.split('_')[1]            \n",
    "            try:\n",
    "                subj_stim_loc[c_loc]\n",
    "            except:\n",
    "                subj_stim_loc[c_loc] = []\n",
    "            subj_stim_loc[c_loc].append(np.mean(arr))\n",
    "            \n",
    "    # Filter out undersampled areas\n",
    "    filt_subj_stim_loc = {}\n",
    "    for loc in subj_stim_loc.keys():\n",
    "        if len(subj_stim_loc[loc]) > 5:\n",
    "            filt_subj_stim_loc[loc] = subj_stim_loc[loc]\n",
    "            \n",
    "    Fv, Pv = stats.f_oneway(*filt_subj_stim_loc.values())\n",
    "\n",
    "    # Sort by mean and error\n",
    "    pop_loc_lbl = []\n",
    "    pop_loc_mean = []\n",
    "    pop_loc_err = []\n",
    "    for loc_ii, (loc, dist) in enumerate(filt_subj_stim_loc.iteritems()):\n",
    "        pop_loc_lbl.append(loc)\n",
    "        pop_loc_mean.append(np.mean(dist))\n",
    "        pop_loc_err.append(np.std(dist) / np.sqrt(len(dist)))\n",
    "    srt_ix = np.argsort(pop_loc_mean)[::-1]\n",
    "    pop_loc_lbl = np.array(pop_loc_lbl)[srt_ix]\n",
    "    pop_loc_mean = np.array(pop_loc_mean)[srt_ix]\n",
    "    pop_loc_err = np.array(pop_loc_err)[srt_ix]    \n",
    "    \n",
    "    # Plot ROI-based stim effects    \n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    for loc_ii, (loc_lbl, loc_mean, loc_err) in enumerate(zip(pop_loc_lbl,\n",
    "                                                              pop_loc_mean,\n",
    "                                                              pop_loc_err)):\n",
    "        \n",
    "        if 'temporal' in loc_lbl:\n",
    "            clr = [0.8, 0.2, 0.2]\n",
    "        else:\n",
    "            clr = [0, 0, 0]\n",
    "        eclr = [0.5, 0.5, 1.0]\n",
    "        \n",
    "        ax.bar(loc_ii-0.25, width=0.5, color=clr, ecolor=eclr, lw=0,\n",
    "               height=loc_mean, yerr=loc_err)\n",
    "    \n",
    "    ax.set_ylim([0.4, 1.0])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Evoked Reorg. of\\nNetwork Topology')\n",
    "    ax.set_xticks(np.arange(len(pop_loc_lbl)))\n",
    "    ax.set_xticklabels(pop_loc_lbl, rotation=-90, fontsize=3.0)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}\\nF={:2.2f}, p={:0.3f}'.format(afreq[0].split('_')[-1], Fv, Pv))\n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Reorganization at Individual Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = [('Delta_NodeStr_AlphaTheta', 'ZNodeStr_AlphaTheta'),\n",
    "             ('Delta_NodeStr_Beta', 'ZNodeStr_Beta'),\n",
    "             ('Delta_NodeStr_LowGamma', 'ZNodeStr_LowGamma'),\n",
    "             ('Delta_NodeStr_HighGamma', 'ZNodeStr_HighGamma')]\n",
    "scale = 'scale60'\n",
    "\n",
    "#roi_lbl = np.unique([roi.split('_')[1] \n",
    "#                    for roi in struct_dict['Atlas'][scale].keys()])\n",
    "roi_lbl = np.sort(np.array(struct_dict['Atlas'][scale].keys()))\n",
    "n_roi = len(roi_lbl)\n",
    "\n",
    "%matplotlib inline\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    evoke_all = np.zeros((n_roi, n_roi))\n",
    "    evoke_cnt = np.zeros((n_roi, n_roi))    \n",
    "        \n",
    "    evoke_arr = []\n",
    "    struct_arr = []\n",
    "    \n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "       \n",
    "        evoke_all_subj = np.zeros((n_roi, n_roi))\n",
    "        evoke_cnt_subj = np.zeros((n_roi, n_roi))    \n",
    "\n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]            \n",
    "\n",
    "            \n",
    "            # Get stim location\n",
    "            a_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            #a_loc = a_loc.split('_')[1]            \n",
    "            a_roi_ix = np.flatnonzero(roi_lbl == a_loc)[0]\n",
    "\n",
    "            c_loc = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "            #c_loc = c_loc.split('_')[1]\n",
    "            c_roi_ix = np.flatnonzero(roi_lbl == c_loc)[0]   \n",
    "            \n",
    "            # Get max pos and max neg evoke\n",
    "            #atlas_lbl = np.array([roi.split('_')[1]\n",
    "            #                      for roi in channel_dict['Subject'][subj_id]['Atlas_Label'][scale]])\n",
    "            atlas_lbl = np.array(channel_dict['Subject'][subj_id]['Atlas_Label'][scale])\n",
    "            atlas_lbl_nostim = atlas_lbl[np.setdiff1d(np.arange(len(atlas_lbl)), [a_ix, c_ix])]\n",
    "            \n",
    "            for trial in sel_stim[afreq[0]]:\n",
    "                z_trial = np.abs(trial)\n",
    "                for chan_ix in xrange(len(atlas_lbl_nostim)):\n",
    "                    roi_lbl_ix = np.flatnonzero(roi_lbl == atlas_lbl_nostim[chan_ix])[0]\n",
    "                    evoke_all[a_roi_ix, roi_lbl_ix] += z_trial[chan_ix]\n",
    "                    evoke_all[c_roi_ix, roi_lbl_ix] += z_trial[chan_ix]\n",
    "                    evoke_cnt[a_roi_ix, roi_lbl_ix] += 1\n",
    "                    evoke_cnt[c_roi_ix, roi_lbl_ix] += 1                    \n",
    "                    evoke_all_subj[a_roi_ix, roi_lbl_ix] += z_trial[chan_ix]\n",
    "                    evoke_all_subj[c_roi_ix, roi_lbl_ix] += z_trial[chan_ix]\n",
    "                    evoke_cnt_subj[a_roi_ix, roi_lbl_ix] += 1\n",
    "                    evoke_cnt_subj[c_roi_ix, roi_lbl_ix] += 1   \n",
    "                    \n",
    "        # Correlate to subject's connectivity matrix if possible\n",
    "        if subj_id in struct_dict['Subject'].keys():\n",
    "            evoke_pos_subj = evoke_all_subj / evoke_cnt_subj\n",
    "            evoke_pos_subj[np.isnan(evoke_pos_subj)] = 0\n",
    "            \n",
    "            for ixx, iyy in zip(np.nonzero(evoke_pos_subj)[0],\n",
    "                                np.nonzero(evoke_pos_subj)[1]):\n",
    "                if ixx == iyy:\n",
    "                    continue\n",
    "                s_conn = struct_dict['Subject'][subj_id][scale]['QA']['adj'][ixx, iyy]\n",
    "                if s_conn == 0:\n",
    "                    continue\n",
    "                    \n",
    "                evoke_arr.append(evoke_pos_subj[ixx, iyy])\n",
    "                struct_arr.append(s_conn)\n",
    "    evoke_arr = np.array(evoke_arr)\n",
    "    struct_arr = np.array(struct_arr)\n",
    "\n",
    "    # Plot ROI-based stim effects\n",
    "    evoke_pos = evoke_all / evoke_cnt\n",
    "    evoke_pos[np.isnan(evoke_pos)] = 0\n",
    "    \n",
    "    plt.figure(figsize=(2,2))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    mat = ax.matshow(evoke_pos, vmax=0.1, cmap='RdBu_r')\n",
    "    mat = plt.colorbar(mat, ax=ax)\n",
    "\n",
    "    ax.set_yticks([])\n",
    "    #ax.set_yticklabels(roi_lbl, fontsize=2.0)\n",
    "    ax.set_ylabel('Stim Target')\n",
    "    ax.set_xticks([])\n",
    "    #ax.set_xticklabels(roi_lbl, fontsize=2.0, rotation=-90)\n",
    "    ax.set_xlabel('Location of Network Reorganization')\n",
    "\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title('{}'.format(afreq[0].split('_')[-1]))\n",
    "\n",
    "    plt.savefig('./e02-Figures/StimROI-Delta_NodeStrength.{}.png'.format(afreq[0].split('_')[-1]))\n",
    "    plt.show()\n",
    "\n",
    "    # Plot relationship between structural connectivity between stim site and target vs. the functional effect of stim\n",
    "    plt.figure(figsize=(2,2))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(struct_arr, evoke_arr)\n",
    "    ax.plot([0.01, 0.20], slope*np.array([0.01, 0.20])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(struct_arr, evoke_arr, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    ax.text(0.01, 0.01, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([0, 0.21])\n",
    "    ax.set_ylim([0.00, np.max(evoke_arr)*1.1])    \n",
    "    ax.set_ylabel('Downstream Functional Effect')\n",
    "    ax.set_xlabel('Structural Connectivity\\n(Stim Target --> Downstream)')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq[0].split('_')[-1])            \n",
    "\n",
    "    plt.savefig('./e02-Figures/StructuralConn-DSFunctionalEffect.{}.png'.format(afreq[0].split('_')[-1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulation Location (Structural Control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect on Mean Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['Delta_MeanConnStr_AlphaTheta',\n",
    "             'Delta_MeanConnStr_Beta',\n",
    "             'Delta_MeanConnStr_LowGamma',\n",
    "             'Delta_MeanConnStr_HighGamma']\n",
    "scale = 'scale250'\n",
    "trk = 'QA'\n",
    "atlas_lbl = np.array(struct_dict['Atlas'][scale].keys())\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_stim_mcs = []\n",
    "    subj_strc_avg_ctl = []    \n",
    "    subj_strc_mod_ctl = []        \n",
    "    for subj_id in np.unique(df_stim_topo['Subject_ID']):\n",
    "        try:\n",
    "            avg_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['avg_ctl'])\n",
    "            mod_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['mod_ctl'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        avg_ctl = (avg_ctl-avg_ctl.mean()) / avg_ctl.std()\n",
    "        mod_ctl = (mod_ctl-mod_ctl.mean()) / mod_ctl.std()            \n",
    "        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "     \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            c_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "\n",
    "            a_roi_ix = np.flatnonzero(atlas_lbl == a_roi)[0]\n",
    "            c_roi_ix = np.flatnonzero(atlas_lbl == c_roi)[0]        \n",
    "            \n",
    "            subj_strc_avg_ctl.append(0.5*(avg_ctl[a_roi_ix] + avg_ctl[c_roi_ix]))\n",
    "            subj_strc_mod_ctl.append(0.5*(mod_ctl[a_roi_ix] + mod_ctl[c_roi_ix]))            \n",
    "            \n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            subj_stim_mcs.append(sel_stim[afreq].mean())\n",
    "            \n",
    "    subj_stim_mcs = np.array(subj_stim_mcs)\n",
    "    subj_strc_avg_ctl = np.array(subj_strc_avg_ctl)  \n",
    "    subj_strc_mod_ctl = np.array(subj_strc_mod_ctl)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_strc_avg_ctl, subj_stim_mcs)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_strc_avg_ctl, subj_stim_mcs, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_strc_avg_ctl, subj_stim_mcs)\n",
    "    #print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(1.0, 0.01, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([-0.02, 0.02])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Mean of Evoked\\nConnection Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Average Controllability of\\nStimulated ROI')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq.split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect on Variance Change in Connection Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['Delta_VarConnStr_AlphaTheta',\n",
    "             'Delta_VarConnStr_Beta',\n",
    "             'Delta_VarConnStr_LowGamma',\n",
    "             'Delta_VarConnStr_HighGamma']\n",
    "scale = 'scale250'\n",
    "trk = 'QA'\n",
    "atlas_lbl = np.array(struct_dict['Atlas'][scale].keys())\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_stim_mcs = []\n",
    "    subj_strc_avg_ctl = []    \n",
    "    subj_strc_mod_ctl = []        \n",
    "    for subj_id in np.unique(df_stim_topo['Subject_ID']):\n",
    "        try:\n",
    "            avg_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['avg_ctl'])\n",
    "            mod_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['mod_ctl'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        avg_ctl = (avg_ctl-avg_ctl.mean()) / avg_ctl.std()\n",
    "        mod_ctl = (mod_ctl-mod_ctl.mean()) / mod_ctl.std()            \n",
    "        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "     \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            c_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "\n",
    "            a_roi_ix = np.flatnonzero(atlas_lbl == a_roi)[0]\n",
    "            c_roi_ix = np.flatnonzero(atlas_lbl == c_roi)[0]        \n",
    "            \n",
    "            subj_strc_avg_ctl.append(0.5*(avg_ctl[a_roi_ix] + avg_ctl[c_roi_ix]))\n",
    "            subj_strc_mod_ctl.append(0.5*(mod_ctl[a_roi_ix] + mod_ctl[c_roi_ix]))            \n",
    "            \n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            subj_stim_mcs.append(sel_stim[afreq].mean())\n",
    "            \n",
    "    subj_stim_mcs = np.array(subj_stim_mcs)\n",
    "    subj_strc_avg_ctl = np.array(subj_strc_avg_ctl)  \n",
    "    subj_strc_mod_ctl = np.array(subj_strc_mod_ctl)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_strc_avg_ctl, subj_stim_mcs)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_strc_avg_ctl, subj_stim_mcs, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_strc_avg_ctl, subj_stim_mcs)\n",
    "    #print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(-3.0, 0.04, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([0.01, 0.05])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Variance of Evoked\\nConnection Strength')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Average Controllability of\\nStimulated ROI')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq.split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Topological Similarity of Evoked Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['Delta_Cor_AlphaTheta',\n",
    "             'Delta_Cor_Beta',\n",
    "             'Delta_Cor_LowGamma',\n",
    "             'Delta_Cor_HighGamma']\n",
    "scale = 'scale250'\n",
    "trk = 'QA'\n",
    "atlas_lbl = np.array(struct_dict['Atlas'][scale].keys())\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_stim_mcs = []\n",
    "    subj_strc_avg_ctl = []    \n",
    "    subj_strc_mod_ctl = []        \n",
    "    for subj_id in np.unique(df_stim_topo['Subject_ID']):\n",
    "        try:\n",
    "            avg_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['avg_ctl'])\n",
    "            mod_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['mod_ctl'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        avg_ctl = (avg_ctl-avg_ctl.mean()) / avg_ctl.std()\n",
    "        mod_ctl = (mod_ctl-mod_ctl.mean()) / mod_ctl.std()            \n",
    "        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "     \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            c_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "\n",
    "            a_roi_ix = np.flatnonzero(atlas_lbl == a_roi)[0]\n",
    "            c_roi_ix = np.flatnonzero(atlas_lbl == c_roi)[0]        \n",
    "            \n",
    "            subj_strc_avg_ctl.append(0.5*(avg_ctl[a_roi_ix] + avg_ctl[c_roi_ix]))\n",
    "            subj_strc_mod_ctl.append(0.5*(mod_ctl[a_roi_ix] + mod_ctl[c_roi_ix]))            \n",
    "            \n",
    "            a_jack = channel_dict['Subject'][subj_id]['Jacksheet'][a_ix]\n",
    "            c_jack = channel_dict['Subject'][subj_id]['Jacksheet'][c_ix]            \n",
    "            sel_stim = sel_subj_stim[sel_subj_stim['Stim_Anode'] == a_jack]\n",
    "            sel_stim = sel_stim[sel_stim['Stim_Cathode'] == c_jack]\n",
    "            subj_stim_mcs.append(sel_stim[afreq].mean())\n",
    "            \n",
    "    subj_stim_mcs = np.array(subj_stim_mcs)\n",
    "    subj_strc_avg_ctl = np.array(subj_strc_avg_ctl)  \n",
    "    subj_strc_mod_ctl = np.array(subj_strc_mod_ctl)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_strc_avg_ctl, subj_stim_mcs)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_strc_avg_ctl, subj_stim_mcs, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_strc_avg_ctl, subj_stim_mcs)\n",
    "    #print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(1.0, 0.75, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([0.0, 1.0])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Evoked Reorg. of\\nNetwork Topology')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Average Controllability of\\nStimulated ROI')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq.split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Baseline and Structural Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_freqs = ['ZNodeStr_AlphaTheta',\n",
    "             'ZNodeStr_Beta',\n",
    "             'ZNodeStr_LowGamma',\n",
    "             'ZNodeStr_HighGamma']\n",
    "scale = 'scale250'\n",
    "trk = 'GFA'\n",
    "atlas_lbl = np.array(struct_dict['Atlas'][scale].keys())\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(3,3))\n",
    "for ii, afreq in enumerate(adj_freqs):\n",
    "    ax = plt.subplot(2, 2, ii+1)\n",
    "    \n",
    "    subj_base_zns = []\n",
    "    subj_strc_avg_ctl = []    \n",
    "    subj_strc_mod_ctl = []        \n",
    "    for subj_id in np.intersect1d(df_base_topo['Subject_ID'],\n",
    "                                  df_stim_topo['Subject_ID']):\n",
    "        try:\n",
    "            avg_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['avg_ctl'])\n",
    "            mod_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['mod_ctl'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        avg_ctl = (avg_ctl-avg_ctl.mean()) / avg_ctl.std()\n",
    "        mod_ctl = (mod_ctl-mod_ctl.mean()) / mod_ctl.std()            \n",
    "        \n",
    "        sel_subj_stim = df_stim_topo[df_stim_topo['Subject_ID'] == subj_id]\n",
    "        sel_subj_base = df_base_topo[df_base_topo['Subject_ID'] == subj_id]\n",
    "        base_zns = sel_subj_base[afreq].mean()\n",
    "     \n",
    "        # Get stim anode/cathode pairs\n",
    "        stim_ix = []\n",
    "        for anode_jack, cathode_jack in zip(sel_subj_stim['Stim_Anode'],\n",
    "                                            sel_subj_stim['Stim_Cathode']):\n",
    "            anode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == anode_jack)[0]\n",
    "            cathode_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Jacksheet'] == cathode_jack)[0]\n",
    "            stim_ix.append((anode_ix, cathode_ix))\n",
    "        stim_ix = list(set(stim_ix))\n",
    "        \n",
    "        # Iterate over all stim pairs\n",
    "        for a_ix, c_ix in stim_ix:\n",
    "            a_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "            c_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "\n",
    "            a_roi_ix = np.flatnonzero(atlas_lbl == a_roi)[0]\n",
    "            c_roi_ix = np.flatnonzero(atlas_lbl == c_roi)[0]        \n",
    "            \n",
    "            subj_strc_avg_ctl.append(0.5*(avg_ctl[a_roi_ix] + avg_ctl[c_roi_ix]))\n",
    "            subj_strc_mod_ctl.append(0.5*(mod_ctl[a_roi_ix] + mod_ctl[c_roi_ix]))            \n",
    "            \n",
    "            subj_base_zns.append(0.5*(base_zns[a_ix] + base_zns[c_ix]))\n",
    "            \n",
    "    subj_base_zns = np.array(subj_base_zns)\n",
    "    subj_strc_avg_ctl = np.array(subj_strc_avg_ctl)  \n",
    "    subj_strc_mod_ctl = np.array(subj_strc_mod_ctl)\n",
    "        \n",
    "    # Regression\n",
    "    slope, yint, rho, pv, stderr = stats.linregress(subj_strc_avg_ctl, subj_base_zns)\n",
    "    ax.plot([-3, 3], slope*np.array([-3, 3])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "    ax.scatter(subj_strc_avg_ctl, subj_base_zns, s=1.0,\n",
    "               color='k', lw=0)\n",
    "    \n",
    "    rho, pv = stats.spearmanr(subj_strc_avg_ctl, subj_base_zns)\n",
    "    #print(afreq[0].split('_')[-1], rho, pv)\n",
    "    ax.text(-3.0, -3.0, 'rho=%0.3f\\npv=%0.3f' % (rho, pv), fontsize=4.0, color='k')\n",
    "    \n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.set_ylim([-4, 4])    \n",
    "    if ii in [0, 2]:\n",
    "        ax.set_ylabel('Baseline\\nFunctional Connectivity of\\nStimulated Electrode')\n",
    "    if ii in [2, 3]:\n",
    "        ax.set_xlabel('Average Controllability of\\nStimulated ROI')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(afreq.split('_')[-1])            \n",
    "\n",
    "#plt.savefig('./e02-Figures/ZNodeStr-Delta_TopNodeStrength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize stim locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Echobase.Plotting import render_brain_connectivity\n",
    "\n",
    "cmap = plt.cm.get_cmap('RdBu')\n",
    "norm = plt.Normalize(vmin=-1.5, vmax=1.5)\n",
    "\n",
    "df_base_topo = pd.read_pickle('{}/baseline_topology.pkl'.format(path_ExpData))\n",
    "\n",
    "adj_freqs = ['ZNodeStr_AlphaTheta', 'ZNodeStr_Beta',\n",
    "             'ZNodeStr_LowGamma', 'ZNodeStr_HighGamma']\n",
    "for afreq in adj_freqs:\n",
    "    \n",
    "    # Grab Z-Score node strength for stim channel and the stim channel location\n",
    "    stim_loc = []\n",
    "    stim_zns = []\n",
    "    for subj_id in overlap_subj_ids:\n",
    "        zns = np.array(df_base_topo[df_base_topo['Subject_ID'] == subj_id][afreq])[0]\n",
    "        \n",
    "        sel_trial = df_trial[df_trial['Subject_ID'] == subj_id]\n",
    "        stim_ix = np.unique(sel_trial['Stim_Anode'])\n",
    "        for ix in stim_ix:\n",
    "            stim_loc.append(list(np.array(sel_trial[sel_trial['Stim_Anode'] == ix]['Stim_Anode_Loc'])[0]))\n",
    "            stim_zns.append(cmap(norm(zns[ix])))\n",
    "    stim_loc = np.array(stim_loc)\n",
    "\n",
    "    # Plot the stim node strength\n",
    "    view_angle = {'Axial_LR': [0.0, 0.0],\n",
    "                  'Axial_RL': [0.0, 180.0],\n",
    "                  'Sag_PA': [0.0, 90.0],\n",
    "                  'Sag_AP': [180.0, 90.0]}\n",
    "\n",
    "    Echobase.Plotting.render_brain_connectivity.draw(vtk_files=['{}/fsl/MNI/rh.pial.vtk'.format(path_AtlasData),\n",
    "                                                                '{}/fsl/MNI/lh.pial.vtk'.format(path_AtlasData)],\n",
    "                                                     brain_rgba=(0.5, 0.5, 0.5, 0.05), conn_cmap='inferno',\n",
    "                                                     node_coords=stim_loc, node_rgba=stim_zns, node_rad=5.0,\n",
    "                                                     conn_thr=[0.975, 1.0], conn_list=None)\n",
    "    for ang in view_angle.keys():\n",
    "        Echobase.Plotting.render_brain_connectivity.mlab.view(azimuth=view_angle[ang][0],\n",
    "                                                              elevation=view_angle[ang][1])\n",
    "        Echobase.Plotting.render_brain_connectivity.mlab.savefig('./e02-Figures/StimLocs-{}-{}.png'.format(afreq, ang))\n",
    "    Echobase.Plotting.render_brain_connectivity.mlab.close(all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional and Structural Controllability and Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_delta_beh = np.load('{}/Delta_Behavior/delta_behav_stim_3-13-17.npy'.format(path_CoreData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scale = 'scale250'\n",
    "trk = 'QA'\n",
    "atlas_lbl = np.array(struct_dict['Atlas'][scale].keys())\n",
    "n_null = 10001\n",
    "\n",
    "avg_ctl_rho_null = []\n",
    "mod_ctl_rho_null = []\n",
    "for n_i in xrange(n_null):\n",
    "    \n",
    "    delta_behavior = []\n",
    "    stim_loc_avg_ctl = []\n",
    "    stim_loc_mod_ctl = []\n",
    "    roi_a = []\n",
    "    roi_c = []    \n",
    "    for val in df_delta_beh:\n",
    "        subj_id = val[0]\n",
    "        stim_anode, stim_cathode = val[1].split('-')\n",
    "        del_b = val[2]\n",
    "\n",
    "        if np.isnan(del_b):\n",
    "            continue\n",
    "        if del_b < -50:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            avg_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['avg_ctl'])\n",
    "            mod_ctl = np.array(struct_dict['Subject'][subj_id][scale][trk]['mod_ctl'])\n",
    "            \n",
    "            avg_ctl = (avg_ctl-avg_ctl.mean()) / avg_ctl.std()\n",
    "            mod_ctl = (mod_ctl-mod_ctl.mean()) / mod_ctl.std()            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            a_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Channel_Label'] == stim_anode)[0]\n",
    "            c_ix = np.flatnonzero(channel_dict['Subject'][subj_id]['Channel_Label'] == stim_cathode)[0]  \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if n_i > 0:\n",
    "                a_roi = np.random.permutation(channel_dict['Subject'][subj_id]['Atlas_Label'][scale])[a_ix]\n",
    "                c_roi = np.random.permutation(channel_dict['Subject'][subj_id]['Atlas_Label'][scale])[c_ix]\n",
    "            else:\n",
    "                a_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][a_ix]\n",
    "                c_roi = channel_dict['Subject'][subj_id]['Atlas_Label'][scale][c_ix]\n",
    "\n",
    "            a_roi_ix = np.flatnonzero(atlas_lbl == a_roi)[0]\n",
    "            c_roi_ix = np.flatnonzero(atlas_lbl == c_roi)[0]        \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            stim_loc_avg_ctl.append(0.5*(avg_ctl[a_roi_ix] + avg_ctl[c_roi_ix]))\n",
    "            stim_loc_mod_ctl.append(0.5*(mod_ctl[a_roi_ix] + mod_ctl[c_roi_ix]))\n",
    "            delta_behavior.append(del_b)\n",
    "            roi_a.append(a_roi)\n",
    "            roi_c.append(c_roi)            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    if n_i == 0:\n",
    "        avg_ctl_rho = stats.spearmanr(stim_loc_avg_ctl, delta_behavior)[0]\n",
    "        mod_ctl_rho = stats.spearmanr(stim_loc_mod_ctl, delta_behavior)[0]\n",
    "        \n",
    "        a_roi_dist = roi_a\n",
    "        c_roi_dist = roi_c\n",
    "        avg_ctl_dist = stim_loc_avg_ctl\n",
    "        mod_ctl_dist = stim_loc_mod_ctl\n",
    "        delta_beh_dist = delta_behavior\n",
    "    else:\n",
    "        avg_ctl_rho_null.append(stats.spearmanr(stim_loc_avg_ctl, delta_behavior)[0])\n",
    "        mod_ctl_rho_null.append(stats.spearmanr(stim_loc_mod_ctl, delta_behavior)[0])\n",
    "        \n",
    "## Generate plots        \n",
    "plt.figure(figsize=(4,4))\n",
    "ax = plt.subplot(121)\n",
    "\n",
    "slope, yint, _, _, _ = stats.linregress(avg_ctl_dist, delta_beh_dist)\n",
    "ax.plot([-1.5, 1.5], slope*np.array([-1.5, 1.5])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "ax.scatter(avg_ctl_dist, delta_beh_dist, lw=0, s=3.0, color='k')\n",
    "\n",
    "ax.text(0.5, -12, 'rho={:1.3f}\\npv={:0.3f}'.format(avg_ctl_rho, np.mean(np.array(avg_ctl_rho_null) > avg_ctl_rho)), fontsize=4.0)\n",
    "ax.set_ylabel('Delta Behavior')\n",
    "ax.set_xlabel('Average Controllability of\\nStimulated ROI')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_aspect((ax.get_xlim()[1]-ax.get_xlim()[0])/(ax.get_ylim()[1]-ax.get_ylim()[0]))\n",
    "\n",
    "\n",
    "ax = plt.subplot(122)\n",
    "\n",
    "slope, yint, _, _, _ = stats.linregress(mod_ctl_dist, delta_beh_dist)\n",
    "ax.plot([-1.5, 1.5], slope*np.array([-1.5, 1.5])+yint, color='r', alpha=0.5, lw=1.0)    \n",
    "ax.scatter(mod_ctl_dist, delta_beh_dist, lw=0, s=3.0, color='k')\n",
    "\n",
    "ax.text(-1.0, -12, 'rho={:1.3f}\\npv={:0.3f}'.format(mod_ctl_rho, np.mean(np.array(mod_ctl_rho_null) < mod_ctl_rho)), fontsize=4.0)\n",
    "ax.set_ylabel('Delta Behavior')\n",
    "ax.set_xlabel('Modal Controllability of\\nStimulated ROI')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_aspect((ax.get_xlim()[1]-ax.get_xlim()[0])/(ax.get_ylim()[1]-ax.get_ylim()[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "336px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "897px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "432px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "655px",
   "left": "1562.08px",
   "right": "20px",
   "top": "129px",
   "width": "340px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
