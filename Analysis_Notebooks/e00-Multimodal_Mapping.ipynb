{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev1 toc-item\"><a href=\"#Gather-all-data-sets\" data-toc-modified-id=\"Gather-all-data-sets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Gather all data sets</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-a-full-subject-list\" data-toc-modified-id=\"Get-a-full-subject-list-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Get a full subject list</a></div><div class=\"lev2 toc-item\"><a href=\"#Tabulate-Atlas-Data\" data-toc-modified-id=\"Tabulate-Atlas-Data-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Tabulate Atlas Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-structural-connectivity-data\" data-toc-modified-id=\"Get-structural-connectivity-data-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Get structural connectivity data</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-Channel-information\" data-toc-modified-id=\"Get-Channel-information-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Get Channel information</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-Baseline-data\" data-toc-modified-id=\"Get-Baseline-data-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Get Baseline data</a></div><div class=\"lev2 toc-item\"><a href=\"#Stim-data\" data-toc-modified-id=\"Stim-data-26\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Stim data</a></div><div class=\"lev2 toc-item\"><a href=\"#Memory-State-data\" data-toc-modified-id=\"Memory-State-data-27\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Memory State data</a></div><div class=\"lev1 toc-item\"><a href=\"#Save-all-meta-data-for-downstream-experiments\" data-toc-modified-id=\"Save-all-meta-data-for-downstream-experiments-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Save all meta data for downstream experiments</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import scipy.linalg as scialg\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "rcParams.update(rcParams)\n",
    "\n",
    "path_AtlasData = '/Users/akhambhati/Remotes/CORE.MRI_Atlases'\n",
    "path_ImagingData = '/Users/akhambhati/Remotes/CORE.RAM_Imaging'\n",
    "path_CoreData = '/Users/akhambhati/Remotes/CORE.PS_Stim'\n",
    "path_PeriphData = '/Users/akhambhati/Remotes/RSRCH.PS_Stim'\n",
    "path_ExpData = path_PeriphData + '/e00-Multimodal_Mapping'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)\n",
    "        \n",
    "from sklearn.externals.joblib import Memory\n",
    "memory = Memory(cachedir=path_ExpData, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather all data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a full subject list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_subj_list():\n",
    "    path_list = glob.glob('{}/Electrode_Info/*.mat'.format(path_CoreData))\n",
    "    \n",
    "    subj_list = [path.split('/')[-1].split('.')[0]\n",
    "                 for path in path_list]\n",
    "    subj_list = np.array(subj_list)\n",
    "    \n",
    "    return subj_list\n",
    "subj_list = get_subj_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabulate Atlas Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_lausanne_label_mni():\n",
    "    lausanne_label_mni = {'scale33': {},\n",
    "                          'scale60': {},\n",
    "                          'scale125': {},\n",
    "                          'scale250': {},\n",
    "                          'scale500': {}}\n",
    "    \n",
    "    for scale in lausanne_label_mni.keys():    \n",
    "        lausanne_labels = pd.read_csv('{}/Lausanne/{}.csv'.format(path_AtlasData, scale))\n",
    "        atlas = nib.load('{}/Lausanne/lausanne/ROIv_{}_dilated.nii.gz'.format(path_AtlasData, scale))\n",
    "        atlas_data = atlas.get_data()\n",
    "\n",
    "        for roi_id in np.unique(atlas_data)[1:]:        \n",
    "            i,j,k = np.nonzero(atlas_data == roi_id)\n",
    "\n",
    "            roi_coords = []\n",
    "            for ii, jj, kk in zip(i, j, k):\n",
    "                xx, yy, zz = atlas.affine[:3, :3].dot([ii, jj, kk]) + atlas.affine[:3, 3]\n",
    "                roi_coords.append((xx, yy, zz))\n",
    "            roi_coords = np.array(roi_coords)\n",
    "\n",
    "            # Add to coords for ROI label to dict\n",
    "            sel_lbl = (lausanne_labels['Label_ID'] == roi_id)\n",
    "            roi_lbl = (lausanne_labels[sel_lbl]['Hemisphere'] + '_' + lausanne_labels[sel_lbl]['ROI']).as_matrix()[0]\n",
    "            \n",
    "            lausanne_label_mni[scale][roi_lbl] = roi_coords\n",
    "            \n",
    "    return lausanne_label_mni\n",
    "lausanne_label_mni = get_lausanne_label_mni()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get structural connectivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_subj_structadj(subj_list):\n",
    "    \n",
    "    structadj_dict = {}\n",
    "    for subj_id in subj_list:\n",
    "        subj_id_abbr = subj_id.split('_')[0]\n",
    "        adj_dir = '{}/Adjacency_Matrices/Epilepsy_Subjects/lausanne/{}'.format(path_ImagingData, subj_id_abbr)\n",
    "        if not os.path.exists(adj_dir):\n",
    "            continue\n",
    "        \n",
    "        structadj_dict[subj_id] = {}\n",
    "        for scale in lausanne_label_mni.keys():\n",
    "\n",
    "            for stream_type in ['QA', 'GFA']:\n",
    "                adj_path = '{}/*ROIv_{}*{}*.mat'.format(adj_dir, scale, stream_type.lower())\n",
    "                adj_path = glob.glob(adj_path)[0]\n",
    "                adj = io.loadmat(adj_path)['connectivity']\n",
    "\n",
    "                # Compute communicability\n",
    "                D_adj = np.diag(1.0 / np.sqrt(np.sum(adj, axis=0)))\n",
    "                adj_comm = scialg.expm(np.dot(np.dot(D_adj, adj), D_adj))\n",
    "\n",
    "                # Populate the subject dict\n",
    "                structadj_dict[subj_id][scale] = {}            \n",
    "                structadj_dict[subj_id][scale][stream_type] = {}\n",
    "                structadj_dict[subj_id][scale][stream_type]['adj'] = adj\n",
    "                structadj_dict[subj_id][scale][stream_type]['adj_comm'] = adj_comm\n",
    "                \n",
    "    return structadj_dict\n",
    "structadj_dict = get_subj_structadj(subj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Channel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "contains:  \n",
    "    - Jacksheet #: int\n",
    "    - Label: (good_channels x 1)\n",
    "    - Atlas_Label: {'scale': (good_channels x 1)}    \n",
    "    - MNI_Coord: (good_channels x 3)\n",
    "    - Dist_Matrix: spatial distances between electrodes\n",
    "    - Struct_Adj: scale and track_type, electrode adjacency matrix\n",
    "\"\"\"\n",
    "@memory.cache\n",
    "def get_subj_channel_info(subj_list):\n",
    "\n",
    "    channel_dict = {}\n",
    "    for subj_id in subj_list:\n",
    "        print(subj_id)\n",
    "        channel_path = '{}/Electrode_Info/{}.mat'.format(path_CoreData, subj_id)\n",
    "        df_chan = io.loadmat(channel_path)\n",
    "            \n",
    "        channel_dict[subj_id] = {}\n",
    "        for ecog_reref in ['Bipolar', 'CommonAverage']:    \n",
    "            \n",
    "            ### Reorder bipolar electrode id\n",
    "            electrode_id = df_chan['electrode_id']\n",
    "            electrode_label = np.array([lbl[0][0] for lbl in df_chan['electrode_label']])       \n",
    "            electrode_id_reref = np.array(sorted(df_chan['electrode_id_bp'].tolist(),\n",
    "                                              key=lambda x: (x[0], x[1])))\n",
    "            if ecog_reref == 'CommonAverage':\n",
    "                electrode_id_reref = np.unique(electrode_id_reref.reshape(-1))\n",
    "            n_node = electrode_id_reref.shape[0]\n",
    "\n",
    "            ### Regenerate re-referenced electrode labels\n",
    "            electrode_label_reref = []\n",
    "            try:\n",
    "                for reref_id in electrode_id_reref:\n",
    "                    if ecog_reref == 'Bipolar':\n",
    "                        anode_ix = np.flatnonzero(df_chan['electrode_id'][0, :] == reref_id[0])\n",
    "                        cathode_ix = np.flatnonzero(df_chan['electrode_id'][0, :] == reref_id[1])\n",
    "\n",
    "                        electrode_label_reref.append([df_chan['electrode_label'][anode_ix[0], 0][0],\n",
    "                                                   df_chan['electrode_label'][cathode_ix[0], 0][0]])\n",
    "                    else:\n",
    "                        monopolar_ix = np.flatnonzero(df_chan['electrode_id'][0, :] == reref_id)\n",
    "                        electrode_label_reref.append(df_chan['electrode_label'][monopolar_ix[0], 0][0])\n",
    "            except:\n",
    "                print(subj_id + ' -- no channel labels')\n",
    "            electrode_label_reref = np.array(electrode_label_reref)\n",
    "\n",
    "            ### MNI Coords\n",
    "            mni_coords = []\n",
    "            for reref_id in electrode_id_reref:\n",
    "                if ecog_reref == 'Bipolar':\n",
    "                    anode_ix = np.flatnonzero(df_chan['electrode_coords'][:, 0] == reref_id[0])\n",
    "                    cathode_ix = np.flatnonzero(df_chan['electrode_coords'][:, 0] == reref_id[1])\n",
    "\n",
    "                    if (len(anode_ix) == 0) or (len(cathode_ix) == 0):\n",
    "                        mni_coords.append(tuple([np.nan, np.nan, np.nan]))\n",
    "                    else:\n",
    "                        mni_coords.append(tuple(0.5*(df_chan['electrode_coords'][anode_ix[0], 1:] +\n",
    "                                                     df_chan['electrode_coords'][cathode_ix[0], 1:])))            \n",
    "                else:\n",
    "                    monopolar_ix = np.flatnonzero(df_chan['electrode_coords'][:, 0] == reref_id)\n",
    "                    if len(monopolar_ix) == 0:\n",
    "                        mni_coords.append(tuple([np.nan, np.nan, np.nan]))\n",
    "                    else:\n",
    "                        mni_coords.append(tuple((df_chan['electrode_coords'][monopolar_ix[0], 1:])))\n",
    "            mni_coords = np.array(mni_coords)\n",
    "            \n",
    "            ### Check MNI Coordinates are valid\n",
    "            if len(np.flatnonzero(np.isnan(mni_coords))) > 0:\n",
    "                print(subj_id + ' -- contains unlocalized channels')\n",
    "\n",
    "            ### Compute Inter-Channel Distances\n",
    "            dist_matr = np.zeros((n_node, n_node))\n",
    "            triu_ix, triu_iy = np.triu_indices(n_node, k=1)\n",
    "            for ix, iy in zip(triu_ix, triu_iy):\n",
    "                ix_chan_loc = mni_coords[ix, :]\n",
    "                iy_chan_loc = mni_coords[iy, :]            \n",
    "                dist_matr[ix, iy] = np.sqrt(np.sum((ix_chan_loc-iy_chan_loc)**2))            \n",
    "            dist_matr += dist_matr.T\n",
    "\n",
    "            ### Assign channel to an ROI using greedy approach\n",
    "            atlas_label = {}\n",
    "            atlas_index = {}        \n",
    "            for scale in lausanne_label_mni.keys():\n",
    "                roi_names = lausanne_label_mni[scale].keys()\n",
    "                chan_assign = []\n",
    "                chan_index = []\n",
    "                for ch_crd in mni_coords:\n",
    "                    roi_voxel_dist = []\n",
    "                    for roi in roi_names:\n",
    "                        roi_crd = lausanne_label_mni[scale][roi]\n",
    "                        nearest_voxel = np.min(np.sqrt(np.sum((ch_crd - roi_crd)**2, axis=1)))\n",
    "                        roi_voxel_dist.append(nearest_voxel)\n",
    "                    roi_ix = np.argmin(roi_voxel_dist)\n",
    "                    chan_assign.append(roi_names[roi_ix])\n",
    "                    chan_index.append(roi_ix) \n",
    "                atlas_label[scale] = np.array(chan_assign)\n",
    "                atlas_index[scale] = np.array(chan_index)            \n",
    "\n",
    "            ### Populate dict\n",
    "            channel_dict[subj_id][ecog_reref] = {}\n",
    "            channel_dict[subj_id][ecog_reref]['Jacksheet'] = electrode_id_reref\n",
    "            channel_dict[subj_id][ecog_reref]['Jacksheet_Label'] = electrode_label_reref\n",
    "            channel_dict[subj_id][ecog_reref]['Atlas_Label'] = atlas_label\n",
    "            channel_dict[subj_id][ecog_reref]['Atlas_Index'] = atlas_index\n",
    "            channel_dict[subj_id][ecog_reref]['MNI_Coord'] = mni_coords\n",
    "            channel_dict[subj_id][ecog_reref]['Dist_Matr'] = dist_matr\n",
    "        \n",
    "    return channel_dict\n",
    "channel_info = get_subj_channel_info(subj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_subj_baseline_info(subj_list):\n",
    "    \n",
    "    base_dict = {'Subject_ID': [],\n",
    "                 'Base_ID': [],\n",
    "                 'Raw_Path': []}\n",
    "    \n",
    "    for subj_id in subj_list:\n",
    "        print(subj_id)\n",
    "        \n",
    "        base_paths = glob.glob('{}/Base_Trials/{}.Base_Event.*.mat'.format(path_CoreData, subj_id))\n",
    "        \n",
    "        for path in base_paths:\n",
    "            base_id = int(path.split('/')[-1].split('.')[-2])\n",
    "            \n",
    "            ### Populate the dictionary\n",
    "            base_dict['Subject_ID'].append(subj_id)\n",
    "            base_dict['Base_ID'].append(base_id)    \n",
    "            base_dict['Raw_Path'].append(path)\n",
    "            \n",
    "    df_baseline = pd.DataFrame(base_dict, columns=base_dict.keys())   \n",
    "    \n",
    "    return df_baseline\n",
    "baseline_info = get_subj_baseline_info(subj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_subj_stim_info(subj_list):\n",
    "\n",
    "    stim_dict = {'Subject_ID': [],\n",
    "                 'Event_ID': [],                  \n",
    "                 'Experiment_ID': [],\n",
    "                 'Stim_Type': [],\n",
    "                 'Stim_Freq': [],\n",
    "                 'Stim_Amp': [],\n",
    "                 'Stim_Dur': [],\n",
    "                 'Stim_Anode': [],\n",
    "                 'Stim_Cathode': [],           \n",
    "                 'Raw_Path': []}\n",
    "\n",
    "    for subj_id in subj_list:\n",
    "        print(subj_id)\n",
    "\n",
    "        ### Get event table for subject\n",
    "        event_path = '{}/Event_Table/{}_events.mat'.format(path_CoreData, subj_id)\n",
    "        if not os.path.exists(event_path):\n",
    "            continue\n",
    "        df_event = io.loadmat(event_path)\n",
    "        \n",
    "        stim_paths = glob.glob('{}/Stim_Trials/{}.Stim_Event.*.mat'.format(path_CoreData, subj_id))\n",
    "\n",
    "        ### Iterate over all trials for the subject\n",
    "        for path in stim_paths:\n",
    "            event_id = int(path.split('/')[-1].split('.')[-2])\n",
    "\n",
    "            ### Get Trial Parameters\n",
    "            sel_event = df_event['events'][0, event_id-1]\n",
    "            stim_type = sel_event['type'][0].lower()\n",
    "            if not ((stim_type == 'stimulating') or (stim_type == 'sham')):\n",
    "                continue        \n",
    "\n",
    "            stim_exp = sel_event['experiment'][0]        \n",
    "            stim_amp = sel_event['amplitude'][0, 0]\n",
    "            stim_freq = sel_event['pulse_frequency'][0, 0]\n",
    "            stim_dur = sel_event['pulse_duration'][0, 0]            \n",
    "\n",
    "            stim_anode_jack = sel_event['stimAnode'][0, 0]\n",
    "            stim_cathode_jack = sel_event['stimCathode'][0, 0]                \n",
    "\n",
    "            ### Populate the dictionary\n",
    "            stim_dict['Subject_ID'].append(subj_id)\n",
    "            stim_dict['Event_ID'].append(event_id)            \n",
    "            stim_dict['Experiment_ID'].append(stim_exp)\n",
    "            stim_dict['Stim_Type'].append(stim_type)  \n",
    "            stim_dict['Stim_Freq'].append(stim_freq)\n",
    "            stim_dict['Stim_Amp'].append(stim_amp)\n",
    "            stim_dict['Stim_Dur'].append(stim_dur)            \n",
    "            stim_dict['Stim_Anode'].append(stim_anode_jack)\n",
    "            stim_dict['Stim_Cathode'].append(stim_cathode_jack)\n",
    "            stim_dict['Raw_Path'].append(path)\n",
    "    \n",
    "    df_stim = pd.DataFrame(stim_dict, columns=stim_dict.keys())    \n",
    "    \n",
    "    return df_stim\n",
    "stim_info = get_subj_stim_info(subj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_subj_memory_info(subj_list):\n",
    "    \n",
    "    memory_dict = {'Subject_ID': [],\n",
    "                   'Event_ID': [],\n",
    "                   'Experiment_ID': [],                   \n",
    "                   'Pre_Stim_Prob': [],\n",
    "                   'Post_Stim_Prob': [],                   \n",
    "                   'Stim_Type': [],\n",
    "                   'Stim_Freq': [],\n",
    "                   'Stim_Amp': [],\n",
    "                   'Stim_Dur': [],\n",
    "                   'Stim_Anode': [],\n",
    "                   'Stim_Cathode': [],\n",
    "                   'Raw_Path': []}\n",
    "    \n",
    "    for subj_id in subj_list:\n",
    "        print(subj_id)\n",
    "\n",
    "        ### Get event table for subject\n",
    "        try:\n",
    "            df_stim_event = io.loadmat('{}/Event_Table/{}_events.mat'.format(path_CoreData, subj_id))\n",
    "            ev_mstime = np.array([event['mstime'][0,0]\n",
    "                                  for event in df_stim_event['events'][0, :]])\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        memory_paths = glob.glob('{}/Memory_States_bPolar/{}.*.memory_states.mat'.format(path_CoreData, subj_id))\n",
    "\n",
    "        ### Iterate over all trials for the subject        \n",
    "        for path in memory_paths:\n",
    "\n",
    "            ### Get memory state table for subject\n",
    "            df_mem_event = io.loadmat(path)\n",
    "            n_mem_event = df_mem_event['eegoffset'].shape[1]\n",
    "\n",
    "            ### Iterate over all memory trials for the subject\n",
    "            for ix in xrange(n_mem_event):\n",
    "                mem_mstime = df_mem_event['mstime'][0, ix]            \n",
    "                mem_event_ix = np.flatnonzero(ev_mstime == mem_mstime) \n",
    "\n",
    "                if not (len(mem_event_ix) == 1):\n",
    "                    continue\n",
    "                mem_event_id = mem_event_ix[0] + 1\n",
    "\n",
    "                ## Get the event parameter\n",
    "                sel_event = df_stim_event['events'][0, mem_event_ix[0]]\n",
    "                stim_type = sel_event['type'][0].lower()\n",
    "\n",
    "                stim_exp = sel_event['experiment'][0]        \n",
    "                stim_amp = sel_event['amplitude'][0, 0]\n",
    "                stim_freq = sel_event['pulse_frequency'][0, 0]\n",
    "                stim_dur = sel_event['pulse_duration'][0, 0]            \n",
    "\n",
    "                stim_anode_jack = sel_event['stimAnode'][0, 0]\n",
    "                stim_cathode_jack = sel_event['stimCathode'][0, 0]\n",
    "\n",
    "\n",
    "                ### Populate the dictionary\n",
    "                memory_dict['Subject_ID'].append(subj_id)\n",
    "                memory_dict['Event_ID'].append(mem_event_id)\n",
    "                memory_dict['Experiment_ID'].append(stim_exp) \n",
    "                memory_dict['Pre_Stim_Prob'].append(df_mem_event['pre_stim_mem_prob'][0, ix])\n",
    "                memory_dict['Post_Stim_Prob'].append(df_mem_event['post_stim_mem_prob'][0, ix])            \n",
    "                memory_dict['Stim_Type'].append(stim_type)     \n",
    "                memory_dict['Stim_Freq'].append(stim_freq)\n",
    "                memory_dict['Stim_Amp'].append(stim_amp) \n",
    "                memory_dict['Stim_Dur'].append(stim_dur)  \n",
    "                memory_dict['Stim_Anode'].append(stim_anode_jack)\n",
    "                memory_dict['Stim_Cathode'].append(stim_cathode_jack)\n",
    "                memory_dict['Raw_Path'].append(path)\n",
    "\n",
    "    df_memory = pd.DataFrame(memory_dict, columns=memory_dict.keys())    \n",
    "    \n",
    "    return df_memory\n",
    "memory_info = get_subj_memory_info(subj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all meta data for downstream experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('{}/Meta.Electrode_Loc.npz'.format(path_ExpData),\n",
    "         subj_list=subj_list,\n",
    "         channel_info=channel_info,\n",
    "         lausanne_label_mni=lausanne_label_mni,\n",
    "         structadj_dict=structadj_dict)\n",
    "\n",
    "memory_info.to_pickle('{}/Meta.Memory_Info.pkl'.format(path_ExpData))\n",
    "baseline_info.to_pickle('{}/Meta.Baseline_Info.pkl'.format(path_ExpData))\n",
    "stim_info.to_pickle('{}/Meta.Stim_Info.pkl'.format(path_ExpData))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "336px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "889px",
    "left": "0px",
    "right": "1707px",
    "top": "106px",
    "width": "256px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "655px",
   "left": "1562.08px",
   "right": "20px",
   "top": "129px",
   "width": "340px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
